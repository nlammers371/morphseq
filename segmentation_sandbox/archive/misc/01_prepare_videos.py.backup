#!/usr/bin/env python
"""
01_prepare_videos.py

Refactored for simplicity and robustness. This script processes raw stitched 
images from one or more experiments, organizes them by well (video_id), creates 
clean JPEG image sequences, and generates a single downscaled video with 
frame number overlays for each well.

This script is designed to be incremental and reproducible. It maintains a single,
cumulative JSON metadata file, tracking all processed experiments, videos, and 
images. Already-processed images are skipped on subsequent runs unless the 
--overwrite flag is specified.

Expected Input Structure:
    directory_with_experiments/
    â”œâ”€â”€ 20240411/
    â”‚   â”œâ”€â”€ A01_t0000_ch00_stitch.png
    â”‚   â””â”€â”€ ...
    â””â”€â”€ 20240412/
        â””â”€â”€ ...

Output Structure:
    output_parent_dir/
    â””â”€â”€ raw_data_organized/
        â”œâ”€â”€ experiment_metadata.json  (Cumulative metadata for all runs)
        â””â”€â”€ 20240411/
            â”œâ”€â”€ vids/
            â”‚   â””â”€â”€ 20240411_A01.mp4
            â””â”€â”€ images/
                â””â”€â”€ 20240411_A01/
                    â””â”€â”€ 20240411_A01_0000.jpg

Usage:
    # Process specific experiments, creating/updating the metadata
    python scripts/01_prepare_videos.py \
        --directory_with_experiments /path/to/stitched_images \
        --output_parent_dir /path/to/top_level_output \
        --experiments_to_process 20240411,20240412

    # Process all new experiments found in the source directory
    python scripts/01_prepare_videos.py \
        --directory_with_experiments /path/to/stitched_images \
        --output_parent_dir /path/to/top_level_output
"""

import os
import re
import sys
import json
import argparse
import cv2
import numpy as np
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from collections import defaultdict
from datetime import datetime
from typing import Union, Tuple, List, Optional, Dict
import shutil

# Add the project root to the path so we can import our utilities
SANDBOX_ROOT = Path(__file__).parent.parent
if str(SANDBOX_ROOT) not in sys.path:
    sys.path.append(str(SANDBOX_ROOT))

# Import our enhanced metadata manager
from scripts.utils.experiment_metadata_utils import ExperimentMetadata

# Try to import pyvips for faster image I/O
try:
    import pyvips
    PYVIPS_AVAILABLE = True
except ImportError:
    PYVIPS_AVAILABLE = False
    print("Warning: pyvips not available, falling back to OpenCV (slower). Install with: pip install pyvips")

# --- Configuration for Image and Video Processing ---
MAX_DIMENSION = 512  # Max width or height for both JPEGs and video
JPEG_QUALITY = 90
VIDEO_FPS = 5
VIDEO_CODEC = 'mp4v' # More compatible than H264, use 'avc1' for H264

# Frame overlay settings
ADD_FRAME_NUMBERS = True
FONT = cv2.FONT_HERSHEY_SIMPLEX
FONT_SCALE = 1.0  # Increased for readability
FONT_COLOR = (255, 255, 255)  # White text
FONT_THICKNESS = 3  # Increased thickness for visibility

def parse_filename(filename: str) -> Tuple[Union[str, None], Union[str, None]]:
    """
    Extracts well ID and timepoint string from a filename.
    Example: 'A01_t0000_ch00_stitch.png' -> ('A01', '0000')
    """
    name, _ = os.path.splitext(filename)
    parts = name.split("_")
    if len(parts) < 2:
        return None, None
    well_id, time_str = parts[0], parts[1]
    if re.match(r'^[A-H][0-9]{2}$', well_id) and time_str.startswith('t'):
        return well_id, time_str[1:]
    return None, None

def get_image_files(directory: Path) -> List[Path]:
    """Find all supported image files in a directory, searching recursively."""
    extensions = ['.png', '.tif', '.tiff', '.jpg', '.jpeg']
    return [p for p in directory.rglob('*') if p.suffix.lower() in extensions]

def process_and_save_jpeg(
    image_path: Path, 
    output_path: Path,
    target_size: Tuple[int, int] = None,
    overwrite: bool = False,
    show_warnings: bool = True
):
    """
    Reads an image and saves it as a clean JPEG without overlays.
    Only resizes if target_size is provided and different from current size.
    Returns the dimensions of the saved JPEG.
    Uses pyvips when available for faster I/O, falls back to OpenCV.
    """
    if output_path.exists() and not overwrite:
        # Get dimensions from existing file
        if PYVIPS_AVAILABLE:
            try:
                img = pyvips.Image.new_from_file(str(output_path), access='sequential')
                return img.width, img.height
            except Exception:
                pass
        # Fallback to OpenCV
        existing_image = cv2.imread(str(output_path))
        if existing_image is not None:
            return existing_image.shape[1], existing_image.shape[0]
    
    # Use pyvips for faster processing when available
    if PYVIPS_AVAILABLE:
        try:
            # Load image with pyvips
            img = pyvips.Image.new_from_file(str(image_path), access='sequential')
            
            # Convert to RGB if needed (pyvips handles this automatically)
            if img.bands == 4:  # RGBA
                img = img[:3]  # Take only RGB channels
            
            # Resize if needed
            if target_size and (img.width, img.height) != target_size:
                target_width, target_height = target_size
                # Ensure dimensions are even for video codec compatibility
                target_width = target_width - (target_width % 2)
                target_height = target_height - (target_height % 2)
                img = img.resize(target_width / img.width, vscale=target_height / img.height)
            
            # Save as JPEG with specified quality
            img.write_to_file(str(output_path), Q=JPEG_QUALITY)
            return img.width, img.height
            
        except Exception as e:
            if show_warnings:
                print(f"Warning: pyvips failed for {image_path}, falling back to OpenCV: {e}")
    
    # Fallback to OpenCV (original implementation)
    image = cv2.imread(str(image_path))
    if image is None:
        if show_warnings:
            print(f"Warning: Could not read image {image_path}, skipping.")
        return None

    if image.shape[2] == 4:
        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)

    height, width = image.shape[:2]
    
    # Only resize if target_size is provided and different from current size
    if target_size and (width, height) != target_size:
        target_width, target_height = target_size
        # Ensure dimensions are even for video codec compatibility
        target_width = target_width - (target_width % 2)
        target_height = target_height - (target_height % 2)
        image = cv2.resize(image, (target_width, target_height), interpolation=cv2.INTER_AREA)

    cv2.imwrite(str(output_path), image, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return image.shape[1], image.shape[0] # width, height

def create_video_from_jpegs(
    jpeg_paths: List[Path],
    video_path: Path,
    video_size: Tuple[int, int],
    overwrite: bool = False,
    verbose: bool = True
):
    """
    Creates an MP4 video from a list of JPEG images, adding frame number overlays.
    """
    if video_path.exists() and not overwrite:
        return

    fourcc = cv2.VideoWriter_fourcc(*VIDEO_CODEC)
    video_writer = cv2.VideoWriter(str(video_path), fourcc, VIDEO_FPS, video_size)

    if not video_writer.isOpened():
        if verbose:
            print(f"Error: Could not open video writer for {video_path}")
        return

    frames_written = 0
    for jpeg_path in sorted(jpeg_paths):
        frame = cv2.imread(str(jpeg_path))
        if frame is None:
            continue

        # Overlay full image ID for each frame
        image_id = jpeg_path.stem
        frame_text = image_id

        (text_width, text_height), _ = cv2.getTextSize(frame_text, FONT, FONT_SCALE, FONT_THICKNESS)
        # Position text at top right, 10% down from the top
        height, width = frame.shape[:2]
        margin_px = 10
        text_x = width - text_width - margin_px
        text_y = int(0.1 * height)

        # Add a dark, semi-transparent background for the text
        overlay = frame.copy()
        cv2.rectangle(overlay, (text_x - 5, text_y - text_height - 5), (text_x + text_width + 5, text_y + 5), (0, 0, 0), -1)
        alpha = 0.4
        frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)
        
        cv2.putText(frame, frame_text, (text_x, text_y), FONT, FONT_SCALE, FONT_COLOR, FONT_THICKNESS)
        
        video_writer.write(frame)
        frames_written += 1
        
    video_writer.release()
    if verbose:
        print(f"Created video: {video_path.name} ({frames_written} frames)")

def process_experiment(
    experiment_dir: Path,
    output_dir: Path,
    metadata: ExperimentMetadata,
    overwrite: bool = False,
    verbose: bool = True,
    workers: int = 4
) -> bool:
    """
    Processes a single experiment directory, updating the metadata object.
    Returns True if processing was successful, False otherwise.
    """
    if not experiment_dir.is_dir():
        print(f"Error: Experiment directory not found: {experiment_dir}")
        return False

    experiment_id = experiment_dir.name
    if verbose:
        print(f"\n{'='*20}")
        print(f"Processing experiment: {experiment_id}")
        print(f"{'='*20}")

    # Add experiment to metadata
    metadata.add_experiment(experiment_id)
    
    experiment_output_dir = output_dir / experiment_id
    
    # Create dedicated folders for videos and image frames
    vids_dir = experiment_output_dir / "vids"
    images_dir = experiment_output_dir / "images"
    vids_dir.mkdir(parents=True, exist_ok=True)
    images_dir.mkdir(parents=True, exist_ok=True)

    if verbose:
        print(f"Output videos will be in: {vids_dir}")
        print(f"Output images will be in: {images_dir}")

    if verbose:
        print("Step 1: Discovering image files...")
    all_images = get_image_files(experiment_dir)
    if not all_images:
        print(f"Warning: No image files found in {experiment_dir}. Skipping.")
        return False
    if verbose:
        print(f"Found {len(all_images)} total image files")

    if verbose:
        print("Step 2: Grouping images by well ID...")
    well_groups = defaultdict(list)
    for img_path in all_images:
        well_id, _ = parse_filename(img_path.name)
        if well_id:
            well_groups[well_id].append(img_path)
    
    if not well_groups:
        print(f"Warning: No images with valid well IDs found in {experiment_dir}. Skipping.")
        return False
        
    if verbose:
        print(f"Successfully grouped into {len(well_groups)} wells.")

    # Process only first 5 wells for testing (remove this limit for production)
    wells_to_process = list(well_groups.items()) #[:5]
    if verbose and len(wells_to_process) > 5:
         print(f"Step 3: Processing all {len(wells_to_process)} wells.")
    # if verbose:
    #     print(f"Step 3: Testing on the first 5 wells: {[i[0] for i in wells_to_process]}")

    # Track warnings to limit verbosity
    warning_count = 0
    max_warnings = 5

    if verbose:
        print("Step 4: Processing wells...")
    
    for well_id, image_paths in tqdm(wells_to_process, desc=f"Processing {experiment_id}", disable=not verbose):
        if verbose:
            print(f"\n  Processing well: {well_id} ({len(image_paths)} images)")
        
        video_id = f"{experiment_id}_{well_id}"
        if verbose:
            print(f"  Video ID: {video_id}")
        
        # Skip well if already processed (only skip video creation when not overwriting)
        if not overwrite and video_id in metadata['video_ids']:
            if verbose:
                print(f"  Skipping already-processed well/video: {video_id}")
            continue

        video_frame_dir = images_dir / video_id
        video_frame_dir.mkdir(parents=True, exist_ok=True)
        if verbose:
            print(f"  Created directory: {video_frame_dir}")

        processed_jpeg_paths = []
        image_dimensions = []
        
        # Get existing image IDs for this video, if any
        image_ids = metadata['experiments'][experiment_id].get('videos', {}).get(video_id, {}).get('image_ids', [])

        if verbose:
            print(f"  Converting {len(image_paths)} images to JPEG using {workers} workers...")
        
        # Prepare tasks for parallel conversion
        tasks = []
        for image_path in sorted(image_paths):
            _, time_str = parse_filename(image_path.name)
            if not time_str:
                continue
            image_id = f"{video_id}_{time_str}"
            jpeg_path = video_frame_dir / f"{image_id}.jpg"
            
            # Skip if already processed and not overwriting
            if image_id in metadata['image_ids'] and not overwrite and jpeg_path.exists():
                # Still need to collect existing paths and dimensions
                if PYVIPS_AVAILABLE:
                    try:
                        img = pyvips.Image.new_from_file(str(jpeg_path), access='sequential')
                        processed_jpeg_paths.append(jpeg_path)
                        image_dimensions.append((img.width, img.height))
                        continue
                    except Exception:
                        pass
                # Fallback to OpenCV for existing files
                img = cv2.imread(str(jpeg_path))
                if img is not None:
                    processed_jpeg_paths.append(jpeg_path)
                    image_dimensions.append((img.shape[1], img.shape[0]))
                    continue
            
            tasks.append((image_path, jpeg_path, image_id))
        
        # Execute conversions in parallel using ThreadPoolExecutor
        new_images_processed = 0
        if tasks:
            with ThreadPoolExecutor(max_workers=workers) as executor:
                future_to_info = {
                    executor.submit(process_and_save_jpeg, img_path, jpeg_path, None, overwrite, warning_count < max_warnings): 
                    (jpeg_path, image_id)
                    for img_path, jpeg_path, image_id in tasks
                }
                
                for future in tqdm(as_completed(future_to_info), total=len(future_to_info), 
                                 desc="Converting images", disable=not verbose, leave=False):
                    jpeg_path, image_id = future_to_info[future]
                    try:
                        dims = future.result()
                        if dims is None:
                            if warning_count < max_warnings:
                                warning_count += 1
                        else:
                            new_images_processed += 1
                            processed_jpeg_paths.append(jpeg_path)
                            image_dimensions.append(dims)
                            if image_id not in metadata['image_ids']:
                                metadata['image_ids'].append(image_id)
                            if image_id not in image_ids:
                                image_ids.append(image_id)
                    except Exception as e:
                        if warning_count < max_warnings:
                            print(f"Error processing {jpeg_path}: {e}")
                            warning_count += 1

        if verbose and not overwrite:
            print(f"  Skipped {len(image_paths) - new_images_processed} existing images. Processed {new_images_processed} new images.")

        if image_dimensions:
            unique_dimensions = list(set(image_dimensions))
            
            if len(unique_dimensions) == 1:
                final_video_size = unique_dimensions[0]
                if verbose:
                    print(f"  All images have consistent dimensions: {final_video_size}")
            else:
                if verbose:
                    print(f"  Found {len(unique_dimensions)} different image dimensions: {unique_dimensions}")
                
                dimension_counts = {dim: image_dimensions.count(dim) for dim in unique_dimensions}
                target_size = max(dimension_counts, key=dimension_counts.get)
                
                if verbose:
                    print(f"  Most common dimension: {target_size} ({dimension_counts[target_size]}/{len(image_dimensions)} images)")
                    print(f"  Standardizing all images to: {target_size}")
                
                images_resized = 0
                # We need to find the original source images to resize from scratch
                source_map = {f"{video_id}_{parse_filename(p.name)[1]}": p for p in image_paths if parse_filename(p.name)[1]}

                for i, (jpeg_path, dims) in enumerate(zip(processed_jpeg_paths, image_dimensions)):
                    if dims != target_size:
                        # Find the original source image to re-process
                        base_id = jpeg_path.stem
                        original_path = source_map.get(base_id)
                        
                        if original_path:
                            process_and_save_jpeg(original_path, jpeg_path, target_size, True, False)
                            images_resized += 1
                
                if verbose:
                    print(f"  Resized {images_resized} images to match target dimensions")
                final_video_size = target_size
        else:
            final_video_size = None

        if verbose:
            print(f"  Successfully processed/validated {len(processed_jpeg_paths)} images for this well.")
        
        video_path = None
        if processed_jpeg_paths and final_video_size:
            if verbose:
                print(f"  Creating video from {len(processed_jpeg_paths)} frames...")
            video_path = vids_dir / f"{video_id}.mp4"
            create_video_from_jpegs(
                processed_jpeg_paths,
                video_path,
                final_video_size,
                overwrite,
                verbose
            )
        elif verbose:
            print(f"  Warning: No valid frames for video creation in well {well_id}")

        # Update metadata for the video
        if video_id not in metadata['video_ids']:
            metadata['video_ids'].append(video_id)

        # --- checkpoint logic ---
        global videos_written, METADATA_PATH
        videos_written += 1
        if videos_written % 100 == 0:
            with open(METADATA_PATH, 'w') as f:
                json.dump(metadata, f, indent=2)
            if verbose:
                print(f"[checkpoint] Saved metadata after {videos_written} videos")

        metadata['experiments'][experiment_id]['videos'][video_id] = {
            "video_id": video_id,
            "well_id": well_id,
            "mp4_path": str(video_path) if video_path else None,
            "processed_jpg_images_dir": str(video_frame_dir),
            "image_ids": sorted(image_ids),
            "total_source_images": len(image_paths),
            "valid_frames": len(processed_jpeg_paths),
            "video_resolution": list(final_video_size) if final_video_size else None,
            "last_processed_time": datetime.now().isoformat()
        }

    if warning_count >= max_warnings:
        print(f"\n... and {warning_count - max_warnings} more image reading warnings (suppressed)")
    
    if verbose:
        print(f"\nFinished processing experiment {experiment_id}.")
    
    return True

def main():
    """Main entry point for the script."""
    parser = argparse.ArgumentParser(
        description="Incrementally convert raw stitched images into JPEG sequences and summary videos.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "--directory_with_experiments", type=str, required=True,
        help="Path to the parent directory containing one or more experiment folders (e.g., .../stitched_images)."
    )
    parser.add_argument(
        "--output_parent_dir", type=str, required=True,
        help="Path to the parent output directory. A 'raw_data_organized' subfolder will be created here."
    )
    parser.add_argument(
        "--experiments_to_process", type=str,
        help="Comma-separated list of specific experiment folder names to process. If not provided, script will prompt to process all."
    )
    parser.add_argument(
        "--overwrite", action="store_true",
        help="If set, re-process and overwrite all existing images and videos."
    )
    parser.add_argument(
        '--verbose', dest='verbose', action='store_true',
        help="Enable detailed print statements (default: on)."
    )
    parser.add_argument(
        '--workers', type=int, default=4,
        help="Number of parallel workers for image conversion."
    )
    parser.set_defaults(verbose=True)
    args = parser.parse_args()

    experiments_dir = Path(args.directory_with_experiments)
    # All outputs will go into a 'raw_data_organized' sub-directory
    output_dir = Path(args.output_parent_dir) / "raw_data_organized"
    output_dir.mkdir(parents=True, exist_ok=True)

    if not experiments_dir.is_dir():
        print(f"Error: Directory with experiments not found: {experiments_dir}")
        return 1

    # Initialize metadata manager with auto-save capability
    metadata_path = output_dir / "experiment_metadata.json"
    metadata = ExperimentMetadata(metadata_path, verbose=args.verbose, auto_save_interval=5)
    
    if args.verbose:
        print(f"ðŸ“Š Current metadata status:")
        metadata.print_summary()

    # First, generate a list of all available experiment directories
    all_available_experiments = sorted([d for d in experiments_dir.iterdir() if d.is_dir()])
    if not all_available_experiments:
        print(f"No experiment directories found in {experiments_dir}")
        return 0
    
    available_experiment_names = [exp.name for exp in all_available_experiments]
    
    if args.verbose:
        print(f"Found {len(all_available_experiments)} experiment directories: {available_experiment_names}")

    # Determine which experiments to process
    experiments_to_process = []
    if args.experiments_to_process:
        # Process only specified experiments - filter the master list
        requested_names = [name.strip() for name in args.experiments_to_process.split(',')]
        for name in requested_names:
            if name not in available_experiment_names:
                print(f"Error: Specified experiment '{name}' not found in {experiments_dir}")
                print(f"Available experiments: {available_experiment_names}")
                return 1
            # Find the corresponding Path object
            exp_path = experiments_dir / name
            experiments_to_process.append(exp_path)
        
        if args.verbose:
            print(f"Processing {len(experiments_to_process)} specified experiments: {[p.name for p in experiments_to_process]}")
    else:
        # Prompt user to process all found experiments
        print("Found the following experiment directories:")
        for exp in all_available_experiments:
            print(f"  - {exp.name}")
        
        try:
            answer = input(f"\nDo you want to process all {len(all_available_experiments)} experiments? (y/n): ").lower()
            if answer == 'y':
                experiments_to_process = all_available_experiments
            else:
                print("Aborting.")
                return 0
        except (EOFError, KeyboardInterrupt):
            print("\nAborting.")
            return 0

    if not experiments_to_process:
        print("No experiments selected for processing.")
        return 0

    print(f"\nStarting batch processing for {len(experiments_to_process)} experiment(s).")
    print(f"Output directory: {output_dir}")
    print(f"Metadata file: {metadata_path}")
    
    successful_count = 0
    for exp_dir in experiments_to_process:
        success = process_experiment(
            exp_dir, output_dir, metadata,
            args.overwrite, args.verbose, args.workers
        )
        if success:
            successful_count += 1

    # Save the updated metadata and clean up old backups
    if args.verbose:
        print(f"\nðŸ’¾ Saving final metadata and cleaning up old backups...")
    metadata.save()
    metadata.cleanup_old_backups(keep_count=5)

    # Print final summary
    print(f"\nBatch processing complete. Successfully processed {successful_count}/{len(experiments_to_process)} experiments.")
    
    if args.verbose:
        print(f"\nðŸ“Š Final metadata summary:")
        metadata.print_summary()
    else:
        summary = metadata.get_summary()
        print(f"Total experiments: {summary['total_experiments']}")
        print(f"Total videos: {summary['total_videos']}")
        print(f"Total images: {summary['total_images']}")
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())


