# GroundedDINO Pipeline Test Suite

This comprehensive test suite validates the production readiness of the GroundedDINO detection pipeline.

## Test Structure

```
tests/
â”œâ”€â”€ test_grounded_sam_utils.py         # Unit tests for core utilities
â”œâ”€â”€ test_gdino_integration.py          # Integration tests
â”œâ”€â”€ test_03_initial_gdino_detections.py # Script validation tests
â”œâ”€â”€ run_production_tests.py            # Main test runner
â””â”€â”€ README.md                          # This file
```

## Quick Start

### Run All Tests
```bash
cd /net/trapnell/vol1/home/mdcolon/proj/morphseq/segmentation_sandbox/scripts/tests
python run_production_tests.py
```

### Run Quick Validation (5 Random Tests)
```bash
python run_production_tests.py --quick
```

### Run Specific Test Suites
```bash
# Unit tests only
python run_production_tests.py --unit

# Integration tests only  
python run_production_tests.py --integration

# Script validation tests only
python run_production_tests.py --script

# Performance tests only
python run_production_tests.py --performance
```

### Run Tests on Random Subset
```bash
# Run 10 random tests
python run_production_tests.py --subset 10

# Run 3 random integration tests
python run_production_tests.py --integration --subset 3
```

### Generate Detailed Report
```bash
python run_production_tests.py --report
```

## Test Coverage

### Unit Tests (`test_grounded_sam_utils.py`)
- âœ… IoU calculation accuracy and edge cases
- âœ… Model metadata extraction
- âœ… Annotation management and persistence
- âœ… High-quality annotation filtering
- âœ… Configuration file loading
- âœ… Error handling and validation

### Integration Tests (`test_gdino_integration.py`)
- âœ… End-to-end detection workflow
- âœ… Model loading and inference pipeline
- âœ… Annotation generation and filtering
- âœ… Experiment metadata integration
- âœ… File I/O operations
- âœ… Multi-session persistence

### Script Tests (`test_03_initial_gdino_detections.py`)
- âœ… Command-line argument parsing
- âœ… Required argument validation
- âœ… Help functionality
- âœ… Error handling patterns
- âœ… Documentation completeness
- âœ… Output formatting

### Performance Tests
- âœ… IoU calculation performance
- âœ… Memory usage monitoring
- âœ… File I/O performance
- âœ… Dependency availability

## Individual Test Files

### Running Individual Test Files

```bash
# Unit tests
python test_grounded_sam_utils.py
python test_grounded_sam_utils.py --subset 5 --verbose

# Integration tests
python test_gdino_integration.py
python test_gdino_integration.py --subset 3 --mock-model

# Script tests
python test_03_initial_gdino_detections.py
python test_03_initial_gdino_detections.py --verbose
```

## Mock Testing

For environments without the actual GroundingDINO model, tests include comprehensive mocking:

```bash
# Use mocked model for integration tests
python test_gdino_integration.py --mock-model

# Use mocked inference for script tests
python test_03_initial_gdino_detections.py --mock-inference
```

## Test Features

### ğŸ¯ Subset Testing
- Run tests on random subsets for quick validation
- Useful for CI/CD pipelines
- Configurable subset sizes

### ğŸ”§ Mock Support
- Comprehensive mocking for model-dependent tests
- Test business logic without requiring actual models
- Simulate various scenarios and edge cases

### ğŸ“Š Performance Monitoring
- Memory usage tracking
- Execution time measurements
- I/O performance analysis

### ğŸ“‹ Detailed Reporting
- Comprehensive test reports
- Performance metrics
- Dependency analysis
- Production readiness recommendations

## Expected Output

### Successful Test Run
```
ğŸš€ Starting Production Readiness Tests
Time: 2024-01-01 12:00:00
ğŸ¯ Running complete test suite

ğŸ“¦ Testing Dependencies
==================================================
   âœ… numpy: 1.21.0
   âœ… torch: 1.12.0
   âœ… cv2: 4.5.0
   âœ… matplotlib: 3.5.0
   âœ… yaml: 6.0

ğŸ”¬ Running Unit Tests
==================================================
test_calculate_detection_iou_perfect_overlap ... ok
test_calculate_detection_iou_no_overlap ... ok
test_get_model_metadata_with_annotation_metadata ... ok
test_annotations_initialization_new_file ... ok
...

ğŸ§ª Running Integration Tests
==================================================
test_end_to_end_detection_workflow ... ok
test_high_quality_filtering_integration ... ok
...

ğŸ“œ Running Script Tests
==================================================
test_script_argument_parsing ... ok
test_script_help ... ok
...

âš¡ Running Performance Tests
==================================================
ğŸ” Testing IoU calculation performance...
   âœ… IoU calculation: 10000 operations in 0.123s
ğŸ’¾ Testing memory usage...
   âœ… Memory usage: 45.2 MB for 100 images Ã— 10 detections
...

================================================================================
PRODUCTION READINESS TEST REPORT
================================================================================

SUMMARY:
- Total Tests: 32
- Passed: 32
- Failed: 0
- Errors: 0
- Success Rate: 100.0%

RECOMMENDATIONS:
- âœ… All tests passed - ready for production!
```

## Troubleshooting

### Common Issues

1. **Import Errors**: Ensure you're running from the correct directory
   ```bash
   cd /net/trapnell/vol1/home/mdcolon/proj/morphseq/segmentation_sandbox/scripts/tests
   ```

2. **Missing Dependencies**: Install required packages
   ```bash
   pip install numpy torch opencv-python matplotlib pyyaml psutil
   ```

3. **Permission Errors**: Check file permissions for test directories

4. **Memory Issues**: Use subset testing for resource-constrained environments
   ```bash
   python run_production_tests.py --subset 5
   ```

### Debug Mode
```bash
# Run with verbose output
python run_production_tests.py --verbose

# Run specific failing test
python test_grounded_sam_utils.py --verbose
```

## Production Deployment Checklist

- [ ] All unit tests pass
- [ ] Integration tests pass
- [ ] Script tests pass
- [ ] Performance tests meet requirements
- [ ] All dependencies available
- [ ] Memory usage within limits
- [ ] Error handling validated
- [ ] Documentation complete

## Contributing

When adding new features:
1. Add corresponding unit tests
2. Update integration tests if needed
3. Run full test suite
4. Update documentation

## Contact

For questions or issues with the test suite, please contact the development team.
