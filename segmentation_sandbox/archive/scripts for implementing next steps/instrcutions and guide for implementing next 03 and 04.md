# Implementation Strategy for Embryo Segmentation Pipeline

## Overview

This document outlines the implementation strategy for Blocks 3 and 4 of the embryo segmentation pipeline, which processes GroundedDINO detections and generates SAM2 video segmentation masks. This strategy serves as inspiration for AI agents to solve these problems and should be approached with critical thinking about architectural flow and pipeline logic.

## Block 3: GroundedDINO Annotation Filtering (Continuation)

### Objective
Filter "individual embryo" detections from GroundedDINO to retain only high-quality annotations suitable for SAM2 processing. This block continues the GroundedDINO processing workflow from previous blocks.

### Implementation Steps

1. **Load GroundedDINO Annotations**
   - Read `gdino_annotations.json` containing raw GroundedDINO detections
   - Extract all annotations with prompt "individual embryo"

2. **IoU-based Duplicate Removal**
   - For each image, calculate IoU between all detection pairs
   - Remove overlapping detections (IoU > threshold, default: 0.5)
   - Keep detection with highest confidence score when overlap occurs

3. **Quality Metrics Calculation and Tracking**
   - Track filtering statistics (original vs. filtered counts)
   - Generate quality report showing improvement
   - **Apply quality functions to ALL annotations for overall data quality tracking**
   - Store quality metrics as lists in code for future analysis

4. **Save Filtered Annotations**
   - Export high-quality annotations to `gdino_high_quality_annotations.json`
   - Maintain same JSON structure but with filtered detections

### Key Functions to Implement
**Note: These functions should be applied to ALL annotations to track overall data quality:**
- `filter_annotations_by_confidence()` - Apply to all annotations for quality tracking
- `remove_overlapping_detections()` - Apply to all annotations for duplicate analysis
- `calculate_detection_iou()` - Calculate for all annotation pairs
- `generate_quality_histogram()` - Should be extension to GroundedDinoAnnotations class, not pipeline step

### Quality Tracking Architecture
- Implement as extensions to GroundedDinoAnnotations class
- Store quality metrics as lists for comprehensive data tracking
- Enable future analysis of overall annotation quality patterns

## Block 4: SAM2 Mask Generation

### Objective
Use high-quality annotations to select optimal seed frames for each video and propagate embryo masks across all frames using SAM2 video segmentation.

### Implementation Steps

1. **Video Grouping and Analysis**
   - Load experiment metadata to map image_ids to video_ids
   - Group high-quality annotations by video_id
   - For each video, analyze first 20% of frames

2. **Seed Frame Selection**
   - Calculate mode (most common) number of embryo detections in first 20% of frames
   - Find earliest frame with mode number of detections
   - Flag videos where seed frame is not the first frame

3. **SAM2 Initialization and Propagation**
   - Initialize SAM2 with video directory
   - Add bounding boxes from seed frame as initial prompts
   - Assign unique embryo_ids: `{video_id}_e01`, `{video_id}_e02`, etc.

4. **Bidirectional Propagation (when needed)**
   - **Forward Pass**: Propagate from seed frame to end of video
   - **Backward Pass**: Propagate from seed frame to beginning (if seed ≠ first frame)
   - Stitch masks together ensuring embryo_id consistency

5. **Mask Processing and Validation**
   - Convert SAM2 logits to binary masks
   - Extract bounding boxes from masks
   - Calculate segmentation polygons
   - Validate mask quality and coverage

6. **Result Integration**
   - Add embryo_ids, masks, and metadata to `grounded_sam_annotations.json`
   - Include seed frame information, embryo counts per video
   - Track processing statistics and flags

### Key Functions to Implement
- `group_annotations_by_video()`
- `find_seed_frame()`
- `run_sam2_propagation()`
- `assign_embryo_ids()`
- `stitch_bidirectional_masks()`
- `integrate_sam2_results()`

## Future Work Placeholders

### Block 5: Live vs Dead Embryo Classification (PLACEHOLDER - DO NOT EXECUTE)
**Objective**: Use bbox-embryo_id pairs from images with GroundedDINO-generated bboxes to classify embryo viability status.

This block will:
- Utilize the embryo_id assignments from Block 4
- Apply classification models to determine embryo viability
- Integrate viability status into the annotation framework
- **CRITICAL**: This requires the organization and tracking established in Blocks 3-4

### Block 6: SAM2 Mask Quality Control (PLACEHOLDER - DO NOT EXECUTE)
**Objective**: Perform comprehensive quality control on embryo_id masks generated by SAM2.

This block will:
- Validate mask consistency across video frames
- Detect and flag problematic segmentations
- Implement automated quality scoring
- Provide manual review workflows for edge cases
- **CRITICAL**: This builds on the tracking architecture from Block 4

## Data Flow

```
gdino_annotations.json
        ↓
[Block 3: GroundedDINO Quality Filtering] (add this to the 03 initial gdino detections.py script)
        ↓
gdino_high_quality_annotations.json
        ↓
[Block 4: SAM2 Mask Generation]
        ↓
grounded_sam_annotations.json (updated with SAM2 results + embryo_ids)
        ↓
[Block 5: Live/Dead Classification] (FUTURE)
        ↓
[Block 6: Quality Control] (FUTURE)
```

## Critical Architecture Considerations

### Organization and Tracking Requirements
The implementation must achieve robust organization and tracking capabilities because:

1. **Block 5 Dependency**: Live vs dead embryo classification requires reliable bbox-embryo_id pairs
2. **Block 6 Dependency**: Quality control needs comprehensive mask tracking and metadata
3. **Data Integrity**: Future blocks depend on consistent embryo_id assignment and tracking
4. **Scalability**: The tracking system must handle large-scale video processing efficiently

### Integration with Existing Utilities

#### GroundedDinoAnnotations Class Extensions
- Add methods for quality filtering and tracking
- Implement quality histogram generation as class methods (not pipeline steps)
- Extend with SAM2 result storage capabilities
- Maintain backward compatibility with existing codebase

#### Experiment Metadata Integration
- Use `get_image_id_paths()` for image path resolution
- Leverage video grouping functions
- Ensure proper image ordering for SAM2 processing

## Error Handling and Quality Assurance

### Robustness Measures
- Handle missing images or corrupted annotations
- Validate SAM2 model loading and GPU availability
- Implement fallback strategies for problematic videos
- Comprehensive quality tracking for future analysis

### Quality Flags and Tracking
- Track videos with non-first seed frames
- Flag videos with insufficient high-quality detections
- Monitor SAM2 propagation failures
- **Store all quality metrics as lists for comprehensive tracking**

### Logging and Monitoring
- Detailed progress tracking for long-running processes
- Statistics on filtering effectiveness across ALL annotations
- Performance metrics for SAM2 processing
- Quality trend analysis for future work preparation

## Expected Outputs

### Block 3 Output
- `gdino_high_quality_annotations.json`: Filtered annotations
- Quality metrics stored as lists in code
- Filtering statistics report covering all annotations

### Block 4 Output
- Updated `grounded_sam_annotations.json` with:
  - Embryo IDs for each detection (critical for Block 5)
  - SAM2 segmentation masks (critical for Block 6)
  - Seed frame metadata
  - Video processing statistics
  - Comprehensive tracking metadata
- Processing log with per-video statistics
- Visualization samples of SAM2 results

## Performance Considerations

### Optimization Strategies
- Batch processing for efficiency
- GPU memory management for SAM2
- Parallel processing where possible
- Incremental processing to handle interruptions
- Efficient data structures for quality tracking

### Resource Requirements
- GPU memory for SAM2 model (~2-4GB)
- Storage for mask data and quality tracking
- Processing time: ~1-5 minutes per video depending on length

## Implementation Notes for AI Agents

This strategy serves as inspiration for solving the embryo segmentation pipeline problems. AI agents should:

1. **Think critically** about the architectural flow and ensure each block builds logically on previous work
2. **Consider the interdependencies** between current and future blocks when designing data structures
3. **Prioritize robust solutions** - implement comprehensive error handling and validation to prevent errors from propagating throughout the entire pipeline
4. **Prioritize organization and tracking** as these are fundamental to the success of future classification and quality control work
5. **Implement comprehensive quality metrics** that apply to all annotations, not just filtered ones
6. **Design for scalability** to handle large video datasets efficiently
7. **Maintain data integrity** throughout the pipeline to ensure reliable downstream processing

The success of this pipeline depends on robust implementation of the tracking and organization systems established in Blocks 3 and 4, as they form the foundation for all future work.