#!/usr/bin/env python3
"""
Stage 3: GroundedDINO Detection Generation
=========================================

This script loads the GroundedDINO model and generates detections for embryo images.
It processes all images in the experiment_metadata.json file and saves detections
in a structured format for downstream SAM2 processing.

Features:
- Loads GroundedDINO model from pipeline configuration
- Processes images incrementally (skips already processed ones)
- Saves detections with confidence scores and prompts
- Tracks model checkpoints and processing metadata
"""

import os
import sys
import json
import yaml
import argparse
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import torch
import numpy as np
from tqdm import tqdm

# Suppress warnings
warnings.filterwarnings("ignore")

# Add project root to path
SCRIPT_DIR = Path(__file__).parent
SANDBOX_ROOT = SCRIPT_DIR.parent
sys.path.append(str(SANDBOX_ROOT))

# Import GroundedDINO utilities
from scripts.utils.grounded_sam_utils import load_config, load_groundingdino_model, GroundedDinoAnnotations
from scripts.utils.experiment_metadata_utils import load_experiment_metadata, get_image_id_paths


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate GroundedDINO detections for embryo images")
    parser.add_argument("--config", required=True, help="Path to pipeline config YAML")
    parser.add_argument("--metadata", required=True, help="Path to experiment_metadata.json")
    parser.add_argument("--annotations", required=True, help="Path to output annotations JSON")
    parser.add_argument("--prompts", nargs="+", required=True, help="List of text prompts")
    args = parser.parse_args()

    # Load model
    config = load_config(args.config)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(device)
    model = load_groundingdino_model(config, device=device)
    print("Model loaded successfullyand fixed memory issue ")
    # Load experiment metadata
    metadata = load_experiment_metadata(args.metadata)
    image_ids = metadata.get("image_ids", [])

    # Initialize annotations manager
    annotations = GroundedDinoAnnotations(args.annotations)
    annotations.set_metadata_path(args.metadata)  # Set metadata path for annotations manager


    # Save any new annotations
    annotations.process_missing_annotations(model, args.prompts,auto_save_interval= 100,store_image_source=False )
    annotations.save()  # Persist annotations to disk

The annotations JSON will be structured as follows:
    "20240306_B02_0029": {
      "annotations": [
        {
          "annotation_id": "ann_20250707195457299429",
          "prompt": "individual embryo",
          "model_metadata": {
            "model_config_path": "GroundingDINO_SwinT_OGC.py",
            "model_weights_path": "groundingdino_swint_ogc.pth",
            "loading_timestamp": "2025-07-07T19:54:52.111644",
            "model_architecture": "GroundedDINO"
          },
          "inference_params": {
            "box_threshold": 0.35,
            "text_threshold": 0.25
          },
          "timestamp": "2025-07-07T19:54:57.299451",
          "num_detections": 3,
          "detections": [
            {
              "box_xywh": [
                0.5277758836746216,
                0.37681376934051514,
                0.20135293900966644,
                0.6884884238243103
              ],
              "confidence": 0.7493306994438171,
              "phrase": "individual embryo"
            },
            {
              "box_xywh": [
                0.8907056450843811,
                0.7463158965110779,
                0.21124237775802612,
                0.2111055850982666
              ],
              "confidence": 0.46482208371162415,
              "phrase": "individual embryo"
            },
            {
              "box_xywh": [
                0.21341422200202942,
                0.16383056342601776,
                0.18073125183582306,
                0.17996403574943542
              ],
              "confidence": 0.46125075221061707,
              "phrase": "individual embryo"
            }
          ]
        },


04 script sam2 masks continues from the 03 file (this file) using the annotations generated by the GroundedDINO model i am providing this scrip as context for what was done in step3 and what needs to happen in step 4

however we need to use the embryo metadata to map the image IDs to their video_ids and experiment_ids as layed on in the readme

Block 1 of tasks (obtaining high quality annotations fromg GroundedDINO model initial detections for sam2 processing)

What we will do is first to filter "individual embryo" detections from the GroundedDINO model so that only high quality annotations are left

first look generate a histogram of the confidence scores for the "individual embryo" detections, then filter out any detections with a confidence score below a certain threshold (e.g., 0.5). This will help us retain only the most reliable detections.

Then of course performe iou calculations to ensure that the detections are not overlapping too much, which would indicate that they are likely detecting the same object multiple times.

Then we need to subset only the annotations that pass these filters and save them to a new JSON file gdino_high_quality_annotations.json this will create a cleaner set of annotations that can be used for further processing or training.

----

Block 2 of tasks (use high quality annotations to designate seed frames and annotation for Sam2 video processing)

first we need to look in the first 20% of video frames (image_ids) for each video_id, in these first frames we need to find the mode of individual embryo detections

then find the earliest frame with the mdoe number of detections (ideally this would be the first frame/image_id for the video_id)

we will use this frame as the seed frame and propagate the detections from this seed frame to all other frames in the video_id

when the seed frame is the first frame, we can simply use the detections from the seed frame as the initial detections for all other frames in the video_id.
(as done in the example workflow provided)

for cases when the mode is not the first frame, we will have on the first pass, forward propagate the detections from seed frame and then backward propagate the detections to the first frame, this will ensure that all frames in the video_id have the same number of detections and that the detections are consistent across frames.

then on the second pass you need to give reverse order of seed to first frame (image_id) so [seed_frame_path, seed_frame-1_path, ...., first_image_id]

Note:this is leverage the fact that detections in sam2 depend on the order in which image paths are provided (use the image_id_paths from the metadata.utils to get the correct order)


for N (e.g. 2) detections in the seed frame we will assign embryo_ids to them, it will be video_id_e01, video_id_e02, ..., video_id_e0N (note if >10 it will be video_id_e010, video_id_e11, ...)

Note: this is a very important step as it will ensure that the detections are consistent across frames and that the embryo_ids are unique for each embryo in the video_id as Sam2 will propgate the detections across frames based on the embryo_ids. and note that when doeing forward and backqards pass from the seed frame we "stitch" the masks generated from sam2 to their appropriate embryo_id based on seed frame

At the end of this script we will need to add embryo_ids and their segmentation mask and bboxes and to grounded_sam_annotations.json (also note the seed_frame image_id, how many embryos in video_id, and the video_id) 
------
Block 3 of tasks is to use new bbox-embryo_id parirs in image_ids with bboxes generated by gdino to detect live vs dead embryos to determine dead or status of embryo
DO NOT EXECUTE THIS BLOCK YET, IT IS JUST A PLACEHOLDER FOR FUTURE WORK
-----
Block 4 of tasks is to perform quality controls on the embryo_ids masks that sam2 generated.  
DO NOT EXECUTE THIS BLOCK YET, IT IS JUST A PLACEHOLDER FOR FUTURE WORK
-----



# python3 /net/trapnell/vol1/home/mdcolon/proj/morphseq/segmentation_sandbox/scripts/03_initial_gdino_detections.py --config /net/trapnell/vol1/home/mdcolon/proj/morphseq/segmentation_sandbox/configs/pipeline_config.yaml --metadata /net/trapnell/vol1/home/mdcolon/proj/morphseq/segmentation_sandbox/data/raw_data_organized/experiment_metadata.json --annotations /net/trapnell/vol1/home/mdcolon/proj/morphseq/segmentation_sandbox/data/annotation_and_masks/gdino_annotations/gdino_annotations.json --prompts "individual embryo"