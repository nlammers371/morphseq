{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to make a table to track hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designate parameters to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric loss-related parameters\n",
    "metric_loss_type = [\"NT-Xent\", \"triplet\"] # type of metric loss function. In theory NT-Xent should do better, but in practice it has been triplet\n",
    "margin = [0.1, 1, 2, 5] # sets tolerance for metric loss. The larger it is, the longer the range over which metric loss will be applied\n",
    "                        # operates in z-score units    \n",
    "metric_weight = [0, 10, 25, 50] # weight of metric loss relative to KLD and recon loss scores\n",
    "self_target_prob = [0.25, 0.5, 0.75] # fraction of metric comparisons that are within a single trajectory\n",
    "temperature = [0.1] # scaling param. Only used for NT-Xent\n",
    "time_only_flag = [0, 1] # if 1, use only time info for metric comparisons\n",
    "\n",
    "# general model params\n",
    "learning_rate = [1e-4] #[1e-3, 5e-4, 1e-4]\n",
    "latent_dim = [100] #[10, 25, 50, 100]\n",
    "beta = [0.1, 1, 10] # weight applied to KLD loss\n",
    "# loss = recon_loss (~200) + beta*KLD_loss (~15) + 10*metric_loss (~5)\n",
    "batch_size = [2048]\n",
    "zn_frac = [0.2] # fraction of latent variables that are used to capture non-biological variability\n",
    "\n",
    "holdout_flag = [0, 1] # If 1, hold out selected perturbation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of parameter names and their values\n",
    "param_grid = {\n",
    "    'metric_loss_type': metric_loss_type,\n",
    "    'margin': margin,\n",
    "    'metric_weight': metric_weight,\n",
    "    'self_target_prob': self_target_prob,\n",
    "    'time_only_flag': time_only_flag,\n",
    "    'temperature': temperature,\n",
    "    'learning_rate': learning_rate,\n",
    "    'latent_dim': latent_dim,\n",
    "    'beta': beta,\n",
    "    'batch_size': batch_size,\n",
    "    'zn_frac': zn_frac,\n",
    "    'holdout_flag': holdout_flag\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "all_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "# Convert to a DataFrame\n",
    "hyperparam_df = pd.DataFrame(all_combinations, columns=param_grid.keys())\n",
    "\n",
    "hyperparam_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks great...but we have over 9,200 combinations to test. Given the computational resources available,  this would take something like: (9200 models) x (150 epochs) x (0.025 hr per epoch) / (4 GPUs) = 6624 hours (i.e. about a year!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all but one of the cases with no metric weight (since rest of parameters don't matter)\n",
    "z_indices0 = np.where((hyperparam_df[\"metric_weight\"]==0) & (hyperparam_df[\"holdout_flag\"]==0))[0]\n",
    "z_indices1 = np.where((hyperparam_df[\"metric_weight\"]==0) & (hyperparam_df[\"holdout_flag\"]==1))[0]\n",
    "\n",
    "keep_indices = [i for i in list(hyperparam_df.index) if i not in z_indices0]\n",
    "keep_indices = [i for i in keep_indices if i not in z_indices1]\n",
    "\n",
    "keep_indices.append(z_indices0[0])\n",
    "keep_indices.append(z_indices1[0])\n",
    "\n",
    "keep_indices = np.asarray(keep_indices)\n",
    "hyperparam_df = hyperparam_df.loc[keep_indices, :]\n",
    "hyperparam_df.reset_index(inplace=True, drop=True)\n",
    "hyperparam_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit binary flag to only co-occur with self_target_prob=0.5\n",
    "t0_filter = ~((hyperparam_df[\"time_only_flag\"]==1) & (hyperparam_df[\"self_target_prob\"]!=0.5))\n",
    "t1_filter = ~((hyperparam_df[\"time_only_flag\"]==1) & (hyperparam_df[\"beta\"]!=1))\n",
    "\n",
    "hyperparam_df = hyperparam_df.loc[t0_filter & t1_filter, :]\n",
    "hyperparam_df.reset_index(inplace=True, drop=True)\n",
    "hyperparam_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# add col to save path info\n",
    "hyperparam_df[\"model_path\"] = \"\"\n",
    "hyperparam_df[\"completed\"] = 0\n",
    "\n",
    "# randomly assign processing order\n",
    "df_indices = list(hyperparam_df.index)\n",
    "np.random.seed(301)\n",
    "process_id = np.random.choice(df_indices, len(df_indices), replace=False)\n",
    "hyperparam_df[\"process_id\"] = process_id\n",
    "\n",
    "outdir = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/metadata/\"\n",
    "hyperparam_df.to_csv(os.path.join(outdir, \"hyperparam_sweep01_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
