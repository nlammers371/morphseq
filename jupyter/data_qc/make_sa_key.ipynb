{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/\"\n",
    "embryo_metadata_df = pd.read_csv(os.path.join(root, \"metadata\", \"combined_metadata_files\", \"embryo_metadata_df01.csv\"))\n",
    "embryo_metadata_df[\"experiment_date\"] = embryo_metadata_df[\"experiment_date\"].astype(str)\n",
    "embryo_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Clean up chemical perturbation variable and create a master perturbation variable\n",
    "# Make a master perturbation class\n",
    "embryo_metadata_df[\"chem_perturbation\"] = embryo_metadata_df[\"chem_perturbation\"].astype(str)\n",
    "embryo_metadata_df.loc[np.where(embryo_metadata_df[\"chem_perturbation\"] == 'nan')[0], \"chem_perturbation\"] = \"None\"\n",
    "\n",
    "embryo_metadata_df[\"master_perturbation\"] = embryo_metadata_df[\"chem_perturbation\"].copy()\n",
    "embryo_metadata_df.loc[np.where(embryo_metadata_df[\"master_perturbation\"] == \"None\")[0], \"master_perturbation\"] = \\\n",
    "    embryo_metadata_df[\"genotype\"].iloc[\n",
    "        np.where(embryo_metadata_df[\"master_perturbation\"] == \"None\")[0]].copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join on additional perturbation info\n",
    "pert_name_key = pd.read_csv(os.path.join(root, 'metadata', \"perturbation_name_key.csv\"))\n",
    "embryo_metadata_df = embryo_metadata_df.merge(pert_name_key, how=\"left\", on=\"master_perturbation\", indicator=True)\n",
    "if np.any(embryo_metadata_df[\"_merge\"] != \"both\"):\n",
    "    problem_perts = np.unique(embryo_metadata_df.loc[embryo_metadata_df[\"_merge\"] != \"both\", \"master_perturbation\"])\n",
    "    raise Exception(\"Some perturbations were not found in key: \" + ', '.join(problem_perts.tolist()))\n",
    "embryo_metadata_df.drop(labels=[\"_merge\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Look at embryo length vs. predicted stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_date00 = \"20240626\"\n",
    "ref_date01 = \"20230620\"\n",
    "\n",
    "\n",
    "date_df00 = embryo_metadata_df.loc[embryo_metadata_df[\"experiment_date\"] == ref_date00, [\"snip_id\", \"embryo_id\", \"time_int\", \"Time Rel (s)\", \"short_pert_name\",\n",
    "                        \"phenotype\", \"control_flag\", \"predicted_stage_hpf\", \"surface_area_um\", \"use_embryo_flag\"]].reset_index(drop=True)\n",
    "\n",
    "# calculate length percentiles\n",
    "ref_bool = (date_df00.loc[:, \"phenotype\"].to_numpy() == \"wt\") | (date_df00.loc[:, \"control_flag\"].to_numpy() == 1)\n",
    "ref_bool = ref_bool & date_df00[\"use_embryo_flag\"]\n",
    "date_df_ref00 = date_df00.loc[ref_bool]\n",
    "\n",
    "# date_df[\"length_um\"] = date_df[\"length_um\"]*1.5\n",
    "date_df_ref00[\"stage_group_hpf\"] = np.round(date_df_ref00[\"predicted_stage_hpf\"])   # [\"predicted_stage_hpf\"])\n",
    "date_key_df00 = date_df_ref00.loc[:, [\"stage_group_hpf\", \"surface_area_um\"]].groupby(\n",
    "                                                ['stage_group_hpf']).quantile(.95).reset_index()\n",
    "\n",
    "\n",
    "date_df01 = embryo_metadata_df.loc[embryo_metadata_df[\"experiment_date\"] == ref_date01, [\"snip_id\", \"embryo_id\", \"time_int\", \"Time Rel (s)\", \"short_pert_name\",\n",
    "                        \"phenotype\", \"control_flag\", \"predicted_stage_hpf\", \"surface_area_um\", \"use_embryo_flag\"]].reset_index(drop=True)\n",
    "# calculate length percentiles\n",
    "ref_bool = (date_df01.loc[:, \"phenotype\"].to_numpy() == \"wt\") | (date_df01.loc[:, \"control_flag\"].to_numpy() == 1)\n",
    "ref_bool = ref_bool & date_df01[\"use_embryo_flag\"]\n",
    "date_df_ref01 = date_df01.loc[ref_bool]\n",
    "\n",
    "# date_df[\"length_um\"] = date_df[\"length_um\"]*1.5\n",
    "date_df_ref01[\"stage_group_hpf\"] = np.round(date_df_ref01[\"predicted_stage_hpf\"])   # [\"predicted_stage_hpf\"])\n",
    "date_key_df01 = date_df_ref01.loc[:, [\"stage_group_hpf\", \"surface_area_um\"]].groupby(\n",
    "                                    ['stage_group_hpf']).quantile(.95).reset_index()\n",
    "\n",
    "date_key_df = pd.concat([date_key_df00, date_key_df01.loc[date_key_df01[\"stage_group_hpf\"] <=14, :]], axis=0, ignore_index=True)\n",
    "\n",
    "px.scatter(x=date_key_df[\"stage_group_hpf\"], y=date_key_df[\"surface_area_um\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Fit a sigmoidal function to generate an SA-based staging key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "\n",
    "t_vec_full = np.linspace(0, 72)\n",
    "t_vec = date_key_df[\"stage_group_hpf\"]\n",
    "sa_vec = date_key_df[\"surface_area_um\"]\n",
    "\n",
    "def sigmoid(params, t_vec=t_vec):\n",
    "    sa_pd = params[0] + params[1] * np.divide(t_vec**params[2], params[3]**params[2] + t_vec**params[2])\n",
    "    return sa_pd\n",
    "\n",
    "def loss_fun(params, sa_vec=sa_vec):\n",
    "    sa_pd = sigmoid(params)\n",
    "    return sa_pd-sa_vec\n",
    "\n",
    "\n",
    "x0 = [4e5, 1e6, 2, 24]\n",
    "lb = (0, 0, 0, 0)\n",
    "ub = (np.inf, np.inf, np.inf, np.inf)\n",
    "params_fit = scipy.optimize.least_squares(loss_fun, x0, bounds=[lb, ub])\n",
    "\n",
    "sa_pd_full = sigmoid(params_fit.x, t_vec=t_vec_full)\n",
    "\n",
    "fig = px.scatter(x=date_key_df[\"stage_group_hpf\"], y=date_key_df[\"surface_area_um\"])\n",
    "fig.add_trace(go.Scatter(x=t_vec_full, y=sa_pd_full, mode=\"lines\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_key_df = pd.DataFrame(t_vec_full, columns=[\"stage_hpf\"])\n",
    "stage_key_df[\"sa_um\"] = sa_pd_full\n",
    "stage_key_df.to_csv(os.path.join(root, \"metadata\", \"stage_ref_df01.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_key_prev = pd.read_csv(os.path.join(root, \"metadata\", \"stage_ref_df.csv\"), index_col=0)\n",
    "stage_key_prev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=stage_key_df[\"stage_hpf\"], y=stage_key_df[\"sa_um\"])\n",
    "fig.add_trace(go.Scatter(x=stage_key_prev[\"stage_hpf\"], y=stage_key_prev[\"sa_um\"]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
