{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "from src.functions.utilities import path_leaf\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of unet training directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob2 import glob\n",
    "\n",
    "root = \"/media/nick/hdd02/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/\"\n",
    "unet_root = os.path.join(root, \"built_image_data\", \"unet_training\", \"*\")\n",
    "unet_dirs = sorted(glob(unet_root))\n",
    "unet_dirs = [u for u in unet_dirs if os.path.isdir(u)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterate through each one and compile list of unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "image_root = os.path.join(root, \"built_image_data\", \"stitched_FF_images\")\n",
    "\n",
    "for u, udir in enumerate(tqdm(unet_dirs)):\n",
    "    # initialize list  to store label files\n",
    "    label_path_list = []\n",
    "    label_name_list = []\n",
    "    # get list of subdirectories\n",
    "    subdir_list = sorted(glob(os.path.join(udir, \"*\")))\n",
    "    subdir_list = [s for s in subdir_list if os.path.isdir(s)]\n",
    "    subdir_list = [s for s in subdir_list if \"training\" not in path_leaf(s)]\n",
    "    for s, sdir in enumerate(subdir_list):\n",
    "        a_dir = os.path.join(sdir, \"annotations\",\"\")\n",
    "        if os.path.isdir(a_dir):\n",
    "            lb_files = glob(a_dir + \"*.tif\") + glob(a_dir + \"*.jpg\")\n",
    "            lb_names = [path_leaf(im) for im in lb_files]\n",
    "            label_path_list += lb_files\n",
    "            label_name_list += lb_names\n",
    "\n",
    "    # make new directory\n",
    "    ann_dir = os.path.join(udir, \"training\", \"annotations\", \"\")\n",
    "    if not os.path.isdir(ann_dir):\n",
    "        os.makedirs(ann_dir)\n",
    "\n",
    "    # get de-duped list of images\n",
    "    lb_names_u, si_u = np.unique(label_name_list, return_index=True) \n",
    "    lb_paths_u = [label_path_list[i] for i in si_u]\n",
    "\n",
    "    # copy over\n",
    "    for i in range(len(lb_names_u)):\n",
    "        shutil.copyfile(lb_paths_u[i], os.path.join(ann_dir, lb_names_u[i]))\n",
    "\n",
    "    # make image directory\n",
    "    im_dir = os.path.join(udir, \"training\", \"images\", \"\")\n",
    "    if not os.path.isdir(im_dir):\n",
    "        os.makedirs(im_dir)\n",
    "\n",
    "    # copy images\n",
    "    for i in range(len(lb_names_u)):\n",
    "        date_folder = lb_names_u[i][0:8]\n",
    "        im_stub = lb_names_u[i][9:18]\n",
    "        im_path_from = glob(os.path.join(image_root, date_folder, im_stub + \"*\"))[0]\n",
    "        new_name = path_leaf(im_path_from)\n",
    "        im_path_to = os.path.join(im_dir, date_folder + \"_\" + new_name)\n",
    "        shutil.copyfile(im_path_from, im_path_to)\n",
    "    \n",
    "    \n",
    "print(label_path_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the live and dead labels into seperate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "emb_dir = os.path.join(unet_root[:-1], \"UNET_training_emb\", \"training\") \n",
    "via_dir_lb = os.path.join(unet_root[:-1], \"UNET_training_via\", \"training\", \"annotations\") \n",
    "via_dir_im = os.path.join(unet_root[:-1], \"UNET_training_via\", \"training\", \"images\") \n",
    "if not os.path.isdir(os.path.join(via_dir_im)):\n",
    "    os.makedirs(via_dir_lb)\n",
    "    os.makedirs(via_dir_im)\n",
    "    \n",
    "mask_dir_lb = os.path.join(unet_root[:-1], \"UNET_training_mask\", \"training\", \"annotations\")\n",
    "mask_dir_im = os.path.join(unet_root[:-1], \"UNET_training_mask\", \"training\", \"images\")\n",
    "if not os.path.isdir(os.path.join(mask_dir_im)):\n",
    "    os.makedirs(mask_dir_lb)\n",
    "    os.makedirs(mask_dir_im)\n",
    "\n",
    "label_list = sorted(glob(os.path.join(emb_dir, \"annotations\", \"*\")))\n",
    "image_list = sorted(glob(os.path.join(emb_dir, \"images\", \"*\")))\n",
    "\n",
    "for i in tqdm(range(len(image_list))):\n",
    "\n",
    "    image_name = path_leaf(image_list[i])\n",
    "    anno_path = glob(os.path.join(emb_dir, \"annotations\", image_name[0:19] + \"*\"))\n",
    "    # loa\n",
    "    im = io.imread(image_list[i])\n",
    "\n",
    "    if len(anno_path) >0:\n",
    "        lb = io.imread(anno_path[0])\n",
    "         # make alternative labels\n",
    "        lb_mask = lb.copy()\n",
    "        lb_mask[lb_mask==2] = 1\n",
    "    \n",
    "        lb_via = lb.copy()\n",
    "        lb_via[lb_via==1] = 0\n",
    "        lb_via[lb_via==2] = 1\n",
    "\n",
    "        io.imsave(os.path.join(mask_dir_lb, image_name), lb_mask, check_contrast=False)\n",
    "        io.imsave(os.path.join(via_dir_lb, image_name), lb_via, check_contrast=False)\n",
    "        \n",
    "    # save\n",
    "    io.imsave(os.path.join(mask_dir_im, image_name), im, check_contrast=False)\n",
    "    io.imsave(os.path.join(via_dir_im, image_name), im, check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/media/nick/hdd02/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/built_image_data/unet_training/UNET_training_emb/training/annotations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_rotating_figure(fig, angle_vec, frame_dir, marker_opacity=0.5, marker_size=6, color_var=None):\n",
    "\n",
    "    if color_var is None:\n",
    "        color_var = \"predicted_stage_hpf\"\n",
    "        \n",
    "    for iter_i, a in enumerate(tqdm(angle_vec)):\n",
    "        angle = a\n",
    "        za = 0.2\n",
    "        vec = np.asarray([math.cos(angle), math.sin(angle), za])\n",
    "        vec = vec*2\n",
    "        camera = dict(\n",
    "            eye=dict(x=vec[0], y=vec[1], z=vec[2]))\n",
    "        \n",
    "        # fig = px.scatter_3d(plot_df, x=\"UMAP_00_bio_3\", y=\"UMAP_01_bio_3\", z=\"UMAP_02_bio_3\",\n",
    "        #                     color=color_var, opacity=marker_opacity,\n",
    "        #                     labels={'predicted_stage_hpf': \"age (hpf)\",\n",
    "        #                             'master_perturbation': \"genotype\"})\n",
    "        \n",
    "        # fig.update_traces(marker={'size': marker_size})\n",
    "        \n",
    "        fig.update_layout(template=\"plotly\")\n",
    "\n",
    "        fig.update_layout(scene_camera=camera, scene_dragmode='orbit')\n",
    "\n",
    "        fig.update_layout(scene = dict(\n",
    "                        # xaxis_title='UMAP 1',\n",
    "                        # yaxis_title='UMAP 2',\n",
    "                        # zaxis_title='UMAP 3',\n",
    "                        xaxis = dict(showticklabels=False),\n",
    "                        yaxis = dict(showticklabels=False),\n",
    "                        zaxis = dict(showticklabels=False)))\n",
    "\n",
    "#         fig.update_layout(coloraxis_showscale=False)\n",
    "        \n",
    "#         fig.update_layout(\n",
    "#                 scene=dict(aspectratio=dict(x=1, y=1, z=1))\n",
    "#         )\n",
    "\n",
    "        fig.write_image(os.path.join(frame_dir, \"umap_scatter\" + \"_\" + color_var + f\"_{iter_i:03}\" + \".png\"), scale=2)\n",
    "            \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate morphological velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# calculate per-point velocity for each embryo\n",
    "snip_vec = np.asarray([umap_df.loc[i, \"snip_id\"][:-10] for i in range(umap_df.shape[0])])\n",
    "umap_df[\"embryo_id\"] = snip_vec\n",
    "snip_index = np.unique(snip_vec)\n",
    "\n",
    "umap_df.loc[:, \"UMAP_00_3_vel\"] = np.nan\n",
    "umap_df.loc[:, \"UMAP_01_3_vel\"] = np.nan\n",
    "umap_df.loc[:, \"UMAP_02_3_vel\"] = np.nan\n",
    "\n",
    "for s, snip in enumerate(tqdm(snip_index, \"Extracting embryo velocities...\")):\n",
    "    s_indices = np.where(snip_vec==snip)[0]\n",
    "    \n",
    "    u0 = umap_df.loc[s_indices, \"umap0\"].to_numpy()\n",
    "    u1 = umap_df.loc[s_indices, \"umap1\"].to_numpy()\n",
    "    u2 = umap_df.loc[s_indices, \"umap2\"].to_numpy()\n",
    "\n",
    "    if len(u0) > 5:\n",
    "    \n",
    "        t = umap_df.loc[s_indices, \"inferred_stage_hpf_reg\"].to_numpy()\n",
    "        \n",
    "        du0 = np.divide(np.diff(u0), np.diff(t))\n",
    "        du1 = np.divide(np.diff(u1), np.diff(t))\n",
    "        du2 = np.divide(np.diff(u2), np.diff(t))\n",
    "        \n",
    "        umap_df.loc[s_indices[:-1], \"UMAP_00_3_vel\"] = du0\n",
    "        umap_df.loc[s_indices[:-1], \"UMAP_01_3_vel\"] = du1\n",
    "        umap_df.loc[s_indices[:-1], \"UMAP_02_3_vel\"] = du2\n",
    "    \n",
    "        umap_df.loc[s_indices[-1], \"UMAP_00_3_vel\"] = du0[-1]\n",
    "        umap_df.loc[s_indices[-1], \"UMAP_01_3_vel\"] = du1[-1]\n",
    "        umap_df.loc[s_indices[-1], \"UMAP_02_3_vel\"] = du2[-1]\n",
    "\n",
    "# remove frames with not velocity\n",
    "print(umap_df.shape[0])\n",
    "umap_df = umap_df.loc[~np.isnan(umap_df[\"UMAP_00_3_vel\"])]\n",
    "print(umap_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "pert_vec = umap_df.loc[:, \"master_perturbation\"].to_numpy()\n",
    "pert_index = np.unique(umap_df[\"master_perturbation\"])\n",
    "cluster_size = 25\n",
    "max_pert_clusters = 500\n",
    "min_pert_clusters = 10\n",
    "train_filter = True#umap_df[\"train_cat\"]==\"train\"\n",
    "cluster_df_list = []\n",
    "\n",
    "for p, pert in enumerate(tqdm(pert_index, \"Clustering perturbation data...\")):\n",
    "\n",
    "    # pull out raw umap coordinates\n",
    "    df_filter = (pert_vec == pert) & train_filter\n",
    "    umap_array = umap_df.loc[df_filter, [\"umap0\", \"umap1\", \"umap2\"]].to_numpy()\n",
    "    umap_v_array = umap_df.loc[df_filter, [\"UMAP_00_3_vel\", \"UMAP_01_3_vel\", \"UMAP_02_3_vel\"]].to_numpy()\n",
    "    age_vec = umap_df.loc[df_filter, \"inferred_stage_hpf_reg\"].to_numpy()\n",
    "    n_points = umap_array.shape[0]\n",
    "    \n",
    "    n_clusters = np.min([int(np.round(n_points/cluster_size)), max_pert_clusters])\n",
    "    if n_clusters > min_pert_clusters:\n",
    "    \n",
    "        # cluster\n",
    "        kmeans_out = KMeans(n_clusters=n_clusters, random_state=0, n_init=\"auto\").fit(umap_array)\n",
    "        label_vec = kmeans_out.labels_\n",
    "\n",
    "        label_index, ia, label_counts = np.unique(label_vec, return_counts=True, return_inverse=True)\n",
    "        \n",
    "        umap_df.loc[df_filter, \"kmeans_label\"] = label_vec\n",
    "        umap_df.loc[df_filter, \"cluster_counts\"] = label_counts[ia]\n",
    "    \n",
    "        \n",
    "        if pert==\"wik\":\n",
    "            label_index = label_index[label_counts>35]\n",
    "            label_counts = label_counts[label_counts>35]\n",
    "        else:\n",
    "            label_index = label_index[label_counts>15]\n",
    "            label_counts = label_counts[label_counts>15]\n",
    "        \n",
    "        k_df = pd.DataFrame(label_index, columns=[\"kmeans_label\"])\n",
    "        k_df[\"cluster_counts\"] = label_counts\n",
    "        k_df[\"master_perturbation\"] = pert\n",
    "        k_df[\"n_clusters\"] = n_clusters\n",
    "        for l, lb in enumerate(label_index):\n",
    "            \n",
    "            k_df.loc[l, \"X\"] = np.mean(umap_array[label_vec==lb, 0])\n",
    "            k_df.loc[l, \"Y\"] = np.mean(umap_array[label_vec==lb, 1])\n",
    "            k_df.loc[l, \"Z\"] = np.mean(umap_array[label_vec==lb, 2])\n",
    "    \n",
    "            k_df.loc[l, \"dX\"] = np.mean(umap_v_array[label_vec==lb, 0])\n",
    "            k_df.loc[l, \"dY\"] = np.mean(umap_v_array[label_vec==lb, 1])\n",
    "            k_df.loc[l, \"dZ\"] = np.mean(umap_v_array[label_vec==lb, 2])\n",
    "\n",
    "            k_df.loc[l, \"stage_hpf\"] = np.mean(age_vec[label_vec==lb])\n",
    "    \n",
    "        cluster_df_list.append(k_df)\n",
    "\n",
    "\n",
    "cluster_df = pd.concat(cluster_df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_stage = np.min(cluster_df[\"stage_hpf\"])\n",
    "max_stage = np.max(cluster_df[\"stage_hpf\"])\n",
    "stage_range = max_stage - min_stage\n",
    "cluster_df[\"stage_norm\"] = (cluster_df[\"stage_hpf\"] - min_stage) / stage_range  / 0.5\n",
    "offset_factor = 1\n",
    "\n",
    "cluster_df[\"vel_norm\"] = np.sqrt(cluster_df[\"dX\"]**2 + cluster_df[\"dY\"]**2 + cluster_df[\"dZ\"]**2)\n",
    "\n",
    "# age scaling\n",
    "cluster_df[\"dX_norm\"] = np.multiply(np.divide(cluster_df[\"dX\"], cluster_df[\"vel_norm\"]), cluster_df[\"stage_norm\"]) + \\\n",
    "                            np.multiply(np.divide(cluster_df[\"dX\"], cluster_df[\"vel_norm\"]), offset_factor) \n",
    "cluster_df[\"dY_norm\"] = np.multiply(np.divide(cluster_df[\"dY\"], cluster_df[\"vel_norm\"]), cluster_df[\"stage_norm\"]) + \\\n",
    "                            np.multiply(np.divide(cluster_df[\"dY\"], cluster_df[\"vel_norm\"]), offset_factor) \n",
    "cluster_df[\"dZ_norm\"] = np.multiply(np.divide(cluster_df[\"dZ\"], cluster_df[\"vel_norm\"]), cluster_df[\"stage_norm\"]) + \\\n",
    "                            np.multiply(np.divide(cluster_df[\"dZ\"], cluster_df[\"vel_norm\"]), offset_factor) \n",
    "\n",
    "# adjust outlier velocities\n",
    "# norm_vec = cluster_df[\"vel_norm\"] / max_v \n",
    "# norm_vec[norm_vec<1] = 1\n",
    "# density_norm = cluster_df[\"n_clusters\"] / np.max(cluster_df[\"n_clusters\"])\n",
    "\n",
    "# cluster_df[\"dX_norm2\"] = np.divide(np.divide(cluster_df[\"dX\"], norm_vec), density_norm)\n",
    "# cluster_df[\"dY_norm2\"] = np.divide(np.divide(cluster_df[\"dY\"], norm_vec), density_norm)\n",
    "# cluster_df[\"dZ_norm2\"] = np.divide(np.divide(cluster_df[\"dZ\"], norm_vec), density_norm)\n",
    "\n",
    "# cluster_df[\"dX_norm\"] = np.divide(cluster_df[\"dX_norm\"], local_density)\n",
    "# cluster_df[\"dY_norm\"] = np.divide(cluster_df[\"dY_norm\"], local_density)\n",
    "# cluster_df[\"dZ_norm\"] = np.divide(cluster_df[\"dZ_norm\"], local_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make 3D scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.express.colors import sample_colorscale\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make cone plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "c = sample_colorscale('magma', list(x))\n",
    "\n",
    "pert = \"wik\"#, \"gdf3\", 'TGFB-i', \"tbxta\"]\n",
    "# c = \"magma\"#, \"Reds\", \"Purples\", \"Greens\"]\n",
    "\n",
    "# size_ref_vec = np.linspace(1, 4.5, 50).tolist() + 40*[4.5]\n",
    "# cmax = 9\n",
    "angle_vec = np.linspace(5.51, 2*np.pi + 5.51, 50)\n",
    "cone_path = os.path.join(figure_path, \"cone_frames_wt_magma\", \"\")\n",
    "if not os.path.isdir(cone_path):\n",
    "    os.makedirs(cone_path)\n",
    "\n",
    "# times_to_plot = np.linspace(18, 56, 50)\n",
    "# times_to_plot[-1] = 72\n",
    "\n",
    "\n",
    "# for t, time in enumerate(tqdm(times_to_plot, \"Generating cone plots....\")):\n",
    "df = cluster_df.copy()#.loc[cluster_df[\"master_perturbation\"]==pert,:]\n",
    "\n",
    "df.loc[cluster_df[\"master_perturbation\"]!=pert,[\"dZ_norm\"]] = 0\n",
    "df.loc[cluster_df[\"master_perturbation\"]!=pert,[\"dY_norm\"]] = 0\n",
    "df.loc[cluster_df[\"master_perturbation\"]!=pert,[\"dX_norm\"]] = 0\n",
    "\n",
    "# n=10\n",
    "# dist_mat = sklearn.metrics.pairwise_distances(df.loc[:, [\"X\", \"Y\", \"Z\"]].to_numpy())\n",
    "# dist_mat_sorted = np.sort(dist_mat, axis=1)\n",
    "# local_density = np.mean(dist_mat_sorted[:, 1:n+1], axis=1)\n",
    "\n",
    "# df[\"dX_norm2\"] = np.divide(df[\"dX_norm\"], local_density)\n",
    "# df[\"dY_norm2\"] = np.divide(df[\"dY_norm\"], local_density)\n",
    "# df[\"dZ_norm2\"] = np.divide(df[\"dZ_norm\"], local_density)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "                xaxis_title='',\n",
    "                yaxis_title='',\n",
    "                zaxis_title='',\n",
    "                xaxis = dict(showticklabels=False),\n",
    "                yaxis = dict(showticklabels=False),\n",
    "                zaxis = dict(showticklabels=False)))\n",
    "\n",
    "angle = angle_vec[0]\n",
    "za = 0.2\n",
    "vec = np.asarray([math.cos(angle), math.sin(angle), za])\n",
    "vec = vec*2\n",
    "camera = dict(\n",
    "eye=dict(x=vec[0], y=vec[1], z=vec[2]))\n",
    "    \n",
    "lim_scene =  dict(\n",
    "                xaxis = dict(nticks=4, range=[-2, 12],),\n",
    "                yaxis = dict(nticks=4, range=[-10, 12],),\n",
    "                zaxis = dict(nticks=4, range=[-7.5, 10],),)\n",
    "\n",
    "fig.update_layout(scene_camera=camera, scene_dragmode='orbit')\n",
    "    #define the trace for triangle sides\n",
    "cones = go.Cone(\n",
    "    x=df[\"Z\"],\n",
    "    y=df[\"X\"],\n",
    "    z=df[\"Y\"],\n",
    "    u=df[\"dZ_norm\"],\n",
    "    v=df[\"dX_norm\"],\n",
    "    w=df[\"dY_norm\"],\n",
    "    colorscale=\"magma\",\n",
    "    sizemode=\"absolute\",\n",
    "    sizeref=4.5, \n",
    "    # cauto=True,\n",
    "    cmin=0.8,\n",
    "    cmax=2,\n",
    "    # anchor=\"tip\",\n",
    "    showscale=False,\n",
    "lighting_specular=2)\n",
    "    \n",
    "fig.add_trace(cones)\n",
    "# fig.update_layout(\n",
    "# autosize=False,\n",
    "# width=1500,\n",
    "# height=1500)\n",
    "fig.update_layout(scene=lim_scene)\n",
    "\n",
    "fig = make_rotating_figure(fig, angle_vec[:2], cone_path)\n",
    "# fig.write_image(os.path.join(figure_path, \"cone_cb.png\"), scale=3)\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert = \"wik\"#, \"gdf3\", 'TGFB-i', \"tbxta\"]\n",
    "# c = \"magma\"#, \"Reds\", \"Purples\", \"Greens\"]\n",
    "\n",
    "# size_ref_vec = np.linspace(1, 4.5, 50).tolist() + 40*[4.5]\n",
    "# cmax = 9\n",
    "cone_path = os.path.join(figure_path, \"cone_frames_wt_magma\", \"\")\n",
    "if not os.path.isdir(cone_path):\n",
    "    os.makedirs(cone_path)\n",
    "\n",
    "# times_to_plot = np.linspace(18, 56, 50)\n",
    "# times_to_plot[-1] = 72\n",
    "\n",
    "\n",
    "# for t, time in enumerate(tqdm(times_to_plot, \"Generating cone plots....\")):\n",
    "df = cluster_df.copy()#.loc[cluster_df[\"master_perturbation\"]==pert,:]\n",
    "\n",
    "df.loc[cluster_df[\"master_perturbation\"]!=pert,[\"dZ_norm\"]] = 0\n",
    "df.loc[cluster_df[\"master_perturbation\"]!=pert,[\"dY_norm\"]] = 0\n",
    "df.loc[cluster_df[\"master_perturbation\"]!=pert,[\"dX_norm\"]] = 0\n",
    "\n",
    "# n=10\n",
    "# dist_mat = sklearn.metrics.pairwise_distances(df.loc[:, [\"X\", \"Y\", \"Z\"]].to_numpy())\n",
    "# dist_mat_sorted = np.sort(dist_mat, axis=1)\n",
    "# local_density = np.mean(dist_mat_sorted[:, 1:n+1], axis=1)\n",
    "\n",
    "# df[\"dX_norm2\"] = np.divide(df[\"dX_norm\"], local_density)\n",
    "# df[\"dY_norm2\"] = np.divide(df[\"dY_norm\"], local_density)\n",
    "# df[\"dZ_norm2\"] = np.divide(df[\"dZ_norm\"], local_density)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "                xaxis_title='',\n",
    "                yaxis_title='',\n",
    "                zaxis_title='',\n",
    "                xaxis = dict(showticklabels=False),\n",
    "                yaxis = dict(showticklabels=False),\n",
    "                zaxis = dict(showticklabels=False)))\n",
    "\n",
    "angle = angle_vec[0]\n",
    "za = 0.25\n",
    "vec = np.asarray([math.cos(angle), math.sin(angle), za])\n",
    "vec = vec*2\n",
    "camera = dict(\n",
    "eye=dict(x=vec[0], y=vec[1], z=vec[2]))\n",
    "    \n",
    "lim_scene =  dict(\n",
    "                xaxis = dict(nticks=4, range=[-2, 12],),\n",
    "                yaxis = dict(nticks=4, range=[-10, 12],),\n",
    "                zaxis = dict(nticks=4, range=[-7.5, 10],),)\n",
    "\n",
    "fig.update_layout(scene_camera=camera, scene_dragmode='orbit')\n",
    "    #define the trace for triangle sides\n",
    "cones = go.Cone(\n",
    "    x=df[\"Z\"],\n",
    "    y=df[\"X\"],\n",
    "    z=df[\"Y\"],\n",
    "    u=df[\"dZ_norm\"],\n",
    "    v=df[\"dX_norm\"],\n",
    "    w=df[\"dY_norm\"],\n",
    "    colorscale=\"Blues\",\n",
    "    sizemode=\"absolute\",\n",
    "    sizeref=4.5, \n",
    "    # cauto=True,\n",
    "    cmin=0.2,\n",
    "    cmax=2,\n",
    "    # anchor=\"tip\",\n",
    "    showscale=True,\n",
    "lighting_specular=2)\n",
    "    \n",
    "fig.add_trace(cones)\n",
    "# fig.update_layout(\n",
    "# autosize=False,\n",
    "# width=1500,\n",
    "# height=1500)\n",
    "fig.update_layout(scene=lim_scene)\n",
    "\n",
    "# fig = make_rotating_figure(fig, angle_vec, cone_path)\n",
    "fig.write_image(os.path.join(figure_path, \"cone_plot_blue.png\"), scale=3)\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_to_plot = [\"wik\", \"TGFB-i\"] #, 'gdf3'] #'TGFB-i', \"tbxta\"]\n",
    "c_vec = [\"Blues\", \"Reds\"] #, \"Reds\"]# \"Greens\"]\n",
    "size_ref_vec = np.asarray([4.5/2.5, .6, 0.95, 5])*2.5\n",
    "c_max_vec = np.asarray([2, 2, 2, 1.5])*1\n",
    "c_min_vec = np.asarray([0.2, 0, 0.1, 1.5])\n",
    "fig = go.Figure()\n",
    "\n",
    "for p, pert in enumerate(pert_to_plot):\n",
    "\n",
    "    df = cluster_df.copy()#.loc[cluster_df[\"master_perturbation\"]==pert,:]\n",
    "    \n",
    "    df.loc[cluster_df[\"master_perturbation\"]!=pert,[\"dZ_norm\"]] = 0\n",
    "    df.loc[cluster_df[\"master_perturbation\"]!=pert,[\"dY_norm\"]] = 0\n",
    "    df.loc[cluster_df[\"master_perturbation\"]!=pert,[\"dX_norm\"]] = 0\n",
    "    \n",
    "    #define the trace for triangle sides\n",
    "    cones = go.Cone(\n",
    "        x=df[\"Z\"],\n",
    "        y=df[\"X\"],\n",
    "        z=df[\"Y\"],\n",
    "        u=df[\"dZ_norm\"],\n",
    "        v=df[\"dX_norm\"],\n",
    "        w=df[\"dY_norm\"],\n",
    "        colorscale=c_vec[p],\n",
    "        cmin=c_min_vec[p],\n",
    "        cmax=c_max_vec[p],\n",
    "        sizemode=\"absolute\",\n",
    "        sizeref=size_ref_vec[p], \n",
    "        showscale=False,\n",
    "        anchor=\"tip\",\n",
    "    lighting_specular=2)\n",
    "        \n",
    "    fig.add_trace(cones)\n",
    "\n",
    "    # fig.update_layout(\n",
    "    # autosize=False,\n",
    "    # width=500,\n",
    "    # height=500)\n",
    "    \n",
    "    angle = angle_vec[0]\n",
    "    za = 0.2\n",
    "    vec = np.asarray([math.cos(angle), math.sin(angle), za])\n",
    "    vec = vec*2\n",
    "    camera = dict(\n",
    "        eye=dict(x=vec[0], y=vec[1], z=vec[2]))\n",
    "        \n",
    "\n",
    "    fig.update_layout(scene_camera=camera, scene_dragmode='orbit')\n",
    "    \n",
    "    \n",
    "    fig.update_layout(scene=lim_scene)\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='',\n",
    "                    yaxis_title='',\n",
    "                    zaxis_title='',\n",
    "                xaxis = dict(showticklabels=False),\n",
    "                yaxis = dict(showticklabels=False),\n",
    "                zaxis = dict(showticklabels=False)))\n",
    "\n",
    "    fig.write_image(os.path.join(figure_path, f\"pert_plot_iter{p:02}.png\"), scale=3)\n",
    "    \n",
    "\n",
    "pert_path = os.path.join(figure_path, \"cone_frames_pert2\", \"\")\n",
    "if not os.path.isdir(pert_path):\n",
    "    os.makedirs(pert_path)\n",
    "\n",
    "fig = make_rotating_figure(fig, angle_vec[:2], pert_path)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for p, pert in enumerate(pert_to_plot):\n",
    "\n",
    "    df = cluster_df.loc[cluster_df[\"master_perturbation\"]==pert,:] \n",
    "    \n",
    "    #define the trace for triangle sides\n",
    "    cones = go.Cone(\n",
    "        x=df[\"Z\"],\n",
    "        y=df[\"X\"],\n",
    "        z=df[\"Y\"],\n",
    "        u=df[\"dZ_norm\"],\n",
    "        v=df[\"dX_norm\"],\n",
    "        w=df[\"dY_norm\"],\n",
    "        colorscale=c_vec[p],\n",
    "        cmin=c_min_vec[p],\n",
    "        cmax=c_max_vec[p],\n",
    "        sizemode=\"absolute\",\n",
    "        sizeref=size_ref_vec[p], \n",
    "        showscale=False,\n",
    "        opacity=0.2,\n",
    "        anchor=\"tip\",\n",
    "    lighting_specular=2)\n",
    "        \n",
    "    fig.add_trace(cones)\n",
    "\n",
    "    fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=500,\n",
    "    height=500)\n",
    "    \n",
    "    angle = angle_vec[0]\n",
    "    za = 0.2\n",
    "    vec = np.asarray([math.cos(angle), math.sin(angle), za])\n",
    "    vec = vec*2\n",
    "    camera = dict(\n",
    "        eye=dict(x=vec[0], y=vec[1], z=vec[2]))\n",
    "        \n",
    "\n",
    "    fig.update_layout(scene_camera=camera, scene_dragmode='orbit')\n",
    "    \n",
    "    \n",
    "    fig.update_layout(scene=lim_scene)\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='UMAP 1',\n",
    "                    yaxis_title='UMAP 2',\n",
    "                    zaxis_title='UMAP 3',\n",
    "                xaxis = dict(showticklabels=False),\n",
    "                yaxis = dict(showticklabels=False),\n",
    "                zaxis = dict(showticklabels=False)))\n",
    "\n",
    "\n",
    "fig.write_image(os.path.join(figure_path, f\"pert_plot_scatter_iter{0:02}.png\"), scale=3)\n",
    "\n",
    "for p, pert in enumerate(pert_to_plot):\n",
    "\n",
    "    df = umap_df.loc[(umap_df[\"master_perturbation\"]==pert) & (umap_df[\"train_cat\"]!=\"train\"),:] \n",
    "    df=df.loc[df[\"cluster_counts\"]>25, :]\n",
    "    #define the trace for triangle sides\n",
    "    scatter = go.Scatter3d(\n",
    "        x=df[\"umap2\"],\n",
    "        y=df[\"umap0\"],\n",
    "        z=df[\"umap1\"],\n",
    "        # u=df[\"dZ_norm\"],\n",
    "        # v=df[\"dX_norm\"],\n",
    "        # w=df[\"dY_norm\"],\n",
    "        # colorscale=c_vec[p],\n",
    "        # cmin=c_min_vec[p],\n",
    "        # cmax=c_max_vec[p],\n",
    "        # sizemode=\"absolute\",\n",
    "        # sizeref=size_ref_vec[p], \n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=df[\"inferred_stage_hpf_reg\"], opacity=0.5, size=4, colorscale=c_vec[p]), showlegend=False)\n",
    "\n",
    "    fig.add_trace(scatter)\n",
    "\n",
    "\n",
    "    fig.write_image(os.path.join(figure_path, f\"pert_plot_scatter_iter{p+1:02}.png\"), scale=3)\n",
    "    # lighting_specular=2)\n",
    "\n",
    "val_path = os.path.join(figure_path, \"cone_frames_validation\", \"\")\n",
    "if not os.path.isdir(val_path):\n",
    "    os.makedirs(val_path)\n",
    "\n",
    "fig = make_rotating_figure(fig, angle_vec, val_path)\n",
    "\n",
    "fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morphseq-env",
   "language": "python",
   "name": "morphseq-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
