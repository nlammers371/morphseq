{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook adds gene expression information to the previously built gene-phenotype table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap.umap_ as umap\n",
    "import plotly.express as px\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to raw data\n",
    "raw_data_root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/zfin/raw_data/\"\n",
    "access_date = \"20240326\"\n",
    "\n",
    "gene_expression_df = pd.read_csv(os.path.join(raw_data_root, access_date, \"wildtype-expression_fish_2024.04.08.txt\"), \n",
    "                                sep='\\t', header=1)\n",
    "stage_df = pd.read_csv(os.path.join(raw_data_root, access_date, \"stage_ontology.txt\"), sep='\\t', header=1)\n",
    "\n",
    "# load built tables\n",
    "built_data_dir = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/zfin/built_data/20240326/\"\n",
    "if not os.path.isdir(built_data_dir):\n",
    "    os.makedirs(built_data_dir)\n",
    "    \n",
    "pheno_df = pd.read_csv(os.path.join(built_data_dir, \"condensed_gene_phenotypes.csv\"))\n",
    "KO_df = pd.read_csv(os.path.join(built_data_dir, \"zfin_gene_KO_candidates.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Clean up the gene expression info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up names\n",
    "gene_df_clean = gene_expression_df.loc[:, [\"Gene ID\", \"Gene Symbol\", \"Super Structure ID\", \"Super Structure Name\",\n",
    "                                          \"Assay\", \"Start Stage\", \"End Stage\"]].rename(columns={\n",
    "                                \"Gene Symbol\" : \"gene\",\n",
    "                                \"Gene ID\": \"gene_ID\",\n",
    "                                \"Super Structure ID\": \"structure_ID\",\n",
    "                                \"Super Structure Name\": \"structure\", \"Assay\": \"assay\"}).drop_duplicates()\n",
    "\n",
    "# add hpf staging info\n",
    "gene_df_clean = gene_df_clean.merge(stage_df.loc[:, [\"Stage Name\", \"Begin Hours\"]], how=\"left\", \n",
    "                                    left_on=\"Start Stage\", right_on=\"Stage Name\").drop(columns=\"Stage Name\")\n",
    "\n",
    "gene_df_clean = gene_df_clean.rename(columns={\"Begin Hours\":\"start_hpf\"})\n",
    "\n",
    "gene_df_clean = gene_df_clean.merge(stage_df.loc[:, [\"Stage Name\", \"End Hours\"]], how=\"left\", \n",
    "                                    left_on=\"End Stage\", right_on=\"Stage Name\").drop(columns=\"Stage Name\")\n",
    "\n",
    "gene_df_clean = gene_df_clean.rename(columns={\"End Hours\":\"end_hpf\"}).drop(columns=[\"Start Stage\", \"End Stage\"])\n",
    "\n",
    "# filter for expression during relevant time period\n",
    "print(gene_df_clean.shape)\n",
    "gene_df_clean = gene_df_clean.loc[gene_df_clean[\"start_hpf\"]<=72, :]\n",
    "print(gene_df_clean.shape)\n",
    "\n",
    "# remove entries with non-specific region tags\n",
    "gene_df_clean = gene_df_clean.loc[gene_df_clean[\"structure\"] != 'whole organism', :]\n",
    "gene_df_clean = gene_df_clean.loc[gene_df_clean[\"structure\"] != 'unspecified', :]\n",
    "w_flags = np.asarray([1 if \"WITHDRAWN\" in gene else 0 for gene in list(gene_df_clean[\"gene\"])])\n",
    "print(gene_df_clean.shape)\n",
    "gene_df_clean = gene_df_clean.loc[w_flags != 1, :]\n",
    "\n",
    "print(gene_df_clean.shape)\n",
    "# aggregate by gene-structure combination\n",
    "\n",
    "\n",
    "gene_df_clean = gene_df_clean.sort_values(by=[\"gene\", \"structure\"], axis=0, ascending=True)\n",
    "\n",
    "# save\n",
    "gene_df_clean.to_csv(os.path.join(built_data_dir, \"gene_expression_cleaned.csv\"), index=False)\n",
    "gene_df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Join on gene expression info\n",
    "Simplest question to answer is just whether or not a given gene has documented specific expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df_temp = gene_df_clean.copy()\n",
    "gene_df_temp[\"specific_expression_flag\"] = 1\n",
    "spec_df = gene_df_temp.loc[:, [\"gene\", \"specific_expression_flag\"]].drop_duplicates()\n",
    "\n",
    "KO_out = KO_df.copy()\n",
    "KO_out = KO_out.merge(spec_df, how=\"left\", on=\"gene\")\n",
    "KO_out.loc[np.isnan(KO_out[\"specific_expression_flag\"]), \"specific_expression_flag\"] = 0\n",
    "\n",
    "print(np.mean(KO_out[\"specific_expression_flag\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "KO_out2 = KO_out.loc[:, list(KO_df.columns[:5]) + [\"specific_expression_flag\"] + list(KO_df.columns[5:-1])]\n",
    "KO_out2 = KO_out2.sort_values(by=[\"TF_flag\", \"specific_expression_flag\", \"importance_score\"], axis=0, ascending=False)\n",
    "\n",
    "KO_out2.to_csv(os.path.join(built_data_dir, \"zfin_gene_KO_candidates_v2.csv\"))\n",
    "KO_out2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
