{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to compile phenotype information from zfin with the aim of identifying interesting potential KO targets. I use zfin's anatomy graph to identify genes that impact important developmental processes and structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap.umap_ as umap\n",
    "import plotly.express as px\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load zfin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to raw data\n",
    "raw_data_root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/zfin/raw_data/\"\n",
    "access_date = \"20240326\"\n",
    "anatomy_nodes_df = pd.read_csv(os.path.join(raw_data_root, access_date, \"anatomy_item.txt\"), sep='\\t', header=1)\n",
    "anatomy_edges_df = pd.read_csv(os.path.join(raw_data_root, access_date, \"anatomy_relationship.txt\"), sep='\\t', header=1)\n",
    "anatomy_synonyms_df = pd.read_csv(os.path.join(raw_data_root, access_date, \"anatomy_synonyms.txt\"), sep='\\t', header=1)\n",
    "zfin_pheno_df_raw = pd.read_csv(os.path.join(raw_data_root, access_date, \"phenoGeneCleanData_fish.txt\"), sep='\\t', header=1)\n",
    "stage_df = pd.read_csv(os.path.join(raw_data_root, access_date, \"stage_ontology.txt\"), sep='\\t', header=1)\n",
    "\n",
    "# make output directory\n",
    "built_data_dir = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/zfin/built_data/20240326/\"\n",
    "if not os.path.isdir(built_data_dir):\n",
    "    os.makedirs(built_data_dir)\n",
    "    \n",
    "fig_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/zfin/figures/\"\n",
    "if not os.path.isdir(fig_path):\n",
    "    os.makedirs(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gene info dataset\n",
    "gene_info_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/zfin/built_data/20240326/gene_set_mf.csv\"\n",
    "gene_info_df = pd.read_csv(gene_info_path)\n",
    "\n",
    "# load zfin gene descriptions\n",
    "zfin_gene_desc_df = pd.read_csv(os.path.join(raw_data_root, access_date, \n",
    "                        \"GENE-DESCRIPTION-TSV_ZFIN.tsv\"), sep='\\t', header=13,\n",
    "                               names=[\"gene_ID\", \"gene\", \"gene_desc\"])\n",
    "zfin_gene_desc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build cleaned zfin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string searching to flag results that are based on morpholinos. This likely misses quite a bit, but is a good start\n",
    "disp_vec = zfin_pheno_df_raw[\"Fish Display Name\"].tolist()\n",
    "MO_flags = [1 if \"MO\" in disp else 0 for disp in disp_vec]\n",
    "zfin_pheno_df_raw[\"morpholino_flag\"] = MO_flags\n",
    "\n",
    "# clean up column names\n",
    "zfin_pheno_df = zfin_pheno_df_raw.rename(columns={\n",
    "            \"Affected Structure or Process 1 superterm ID\": \"structure_ID\",\n",
    "            \"Affected Structure or Process 1 superterm Name\": \"structure\",\n",
    "            \"Gene Symbol\" : \"gene\",\n",
    "            \"Gene ID\": \"gene_ID\",\n",
    "            \"Phenotype Keyword ID\": \"pheno_ID\",\n",
    "            \"Phenotype Keyword Name\": \"phen_type\",\n",
    "            \"Phenotype Tag\": \"phen_tag\"\n",
    "}).loc[:, [\"gene\", \"gene_ID\", \"structure\", \"structure_ID\", 'phen_tag', 'phen_type',\n",
    "           \"morpholino_flag\", \"pheno_ID\",\n",
    "           \"Start Stage ID\", \"End Stage ID\"]]\n",
    "\n",
    "# add staging info\n",
    "zfin_pheno_df = zfin_pheno_df.merge(stage_df.loc[:, [\"Stage ID\", \"Begin Hours\"]], how=\"left\", \n",
    "                                    left_on=\"Start Stage ID\", right_on=\"Stage ID\").drop(columns=\"Stage ID\")\n",
    "\n",
    "zfin_pheno_df = zfin_pheno_df.rename(columns={\"Begin Hours\":\"start_hpf\"})\n",
    "\n",
    "zfin_pheno_df = zfin_pheno_df.merge(stage_df.loc[:, [\"Stage ID\", \"End Hours\"]], how=\"left\", \n",
    "                                    left_on=\"End Stage ID\", right_on=\"Stage ID\").drop(columns=\"Stage ID\")\n",
    "\n",
    "zfin_pheno_df = zfin_pheno_df.rename(columns={\"End Hours\":\"end_hpf\"}).drop(columns=[\"Start Stage ID\", \"End Stage ID\"])\n",
    "\n",
    "zfin_pheno_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of non-morpholino reports corresponding to each gene-phenotype combo. Keep only those with at least one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove morpholino observations\n",
    "print(zfin_pheno_df.shape)\n",
    "zfin_pheno_clean = zfin_pheno_df.loc[zfin_pheno_df[\"morpholino_flag\"]==0, :].copy()\n",
    "\n",
    "# filter for only abnormal phneotypes (I think this has no effect)\n",
    "print(zfin_pheno_clean.shape)\n",
    "zfin_pheno_clean = zfin_pheno_clean.loc[zfin_pheno_clean[\"phen_tag\"]=='abnormal', :].drop_duplicates()\n",
    "\n",
    "# keep only effects that begin no later than 72hpf\n",
    "print(zfin_pheno_clean.shape)\n",
    "zfin_pheno_clean = zfin_pheno_clean.loc[zfin_pheno_clean[\"start_hpf\"]<=72, :]\n",
    "\n",
    "# remove any remaing phenotypes that do not have a \"ZFA\" code (anatomical effects)\n",
    "print(zfin_pheno_clean.shape)\n",
    "id_vec = zfin_pheno_clean.loc[:, \"structure_ID\"].tolist()\n",
    "keep_flags = np.asarray([\"ZFA\" in i for i in id_vec])\n",
    "zfin_pheno_clean = zfin_pheno_clean.loc[keep_flags]\n",
    "\n",
    "# Keep only structures that are in the anatomy graph (ideally they should all be in there)\n",
    "print(zfin_pheno_clean.shape)\n",
    "zfin_pheno_clean = zfin_pheno_clean.merge(anatomy_nodes_df.loc[:, [\"Anatomy ID\"]].drop_duplicates(), how=\"inner\",\n",
    "                                    left_on=\"structure_ID\", right_on=\"Anatomy ID\")\n",
    "zfin_pheno_clean = zfin_pheno_clean.drop(labels=[\"Anatomy ID\"], axis=1)\n",
    "print(zfin_pheno_clean.shape)\n",
    "\n",
    "# remove 'whole organism' and 'unspecified' instances\n",
    "zfin_pheno_clean = zfin_pheno_clean.loc[zfin_pheno_clean[\"structure_ID\"]!=\"ZFA:0001094\"]\n",
    "zfin_pheno_clean = zfin_pheno_clean.loc[zfin_pheno_clean[\"structure_ID\"]!=\"ZFA:0001093\"]\n",
    "print(zfin_pheno_clean.shape)\n",
    "\n",
    "# Save\n",
    "zfin_pheno_clean = zfin_pheno_clean.loc[:, [\"gene\", \"gene_ID\", \"structure\", \"structure_ID\", \"phen_type\", \"start_hpf\", \"end_hpf\"]]\n",
    "zfin_pheno_clean.to_csv(os.path.join(built_data_dir, \"cleaned_gene_phenotypes.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-dupe phenotypes \n",
    "zfin_pheno_agg1 = zfin_pheno_clean.copy()\n",
    "print(zfin_pheno_agg1.shape)\n",
    "zfin_pheno_agg1[\"report_counts\"] = 1\n",
    "zfin_pheno_agg1 = zfin_pheno_agg1.groupby(\n",
    "                        [\"gene\", \"gene_ID\", \"structure\", \"structure_ID\"]).agg({\n",
    "                    \"phen_type\": lambda x: ', '.join(x), \"start_hpf\": \"min\", \"end_hpf\": \"max\", \n",
    "                    \"report_counts\": \"count\"}).reset_index(drop=False)\n",
    "print(zfin_pheno_agg1.shape)\n",
    "zfin_pheno_agg1.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join on gene ontology info\n",
    "gene_info_clean = gene_info_df.loc[:, [\"gene_symbol\", \"gs_name\", \"gs_description\"]].rename(columns={\"gene_symbol\": \"gene\"})\n",
    "tf_flag_vec = [1 if \"transcription\" in name.lower() else 0 for name in list(gene_info_clean[\"gs_name\"]) ]\n",
    "gene_info_clean[\"TF_flag_g\"] = tf_flag_vec\n",
    "\n",
    "# take max of TF flag\n",
    "gene_info_short = gene_info_clean.loc[:, [\"gene\", \"TF_flag_g\"]].groupby([\"gene\"]).max().reset_index()\n",
    "\n",
    "# now do the same for zfin descriptions\n",
    "tf_flags_z = [1 if \"transcription\" in name.lower() else 0 for name in list(zfin_gene_desc_df[\"gene_desc\"])]\n",
    "chromatin_flags = [1 if \"chromatin\" in name.lower() else 0 for name in list(zfin_gene_desc_df[\"gene_desc\"])]\n",
    "zfin_gene_desc_df[\"TF_flag_z\"] = tf_flags_z\n",
    "zfin_gene_desc_df[\"chromatin_flag\"] = chromatin_flags\n",
    "zfin_tf_df = zfin_gene_desc_df.loc[:, [\"gene\", \"TF_flag_z\", \"chromatin_flag\", \"gene_desc\"]].drop_duplicates()\n",
    "                            \n",
    "# merge onto zfin data\n",
    "# Note, about 15% of genes are not in this reference table and so may be incorrectly labeled as non-TF\n",
    "gene_pheno_df = zfin_pheno_agg1.loc[:, [\"gene\", \"gene_ID\"]].drop_duplicates().merge(\n",
    "    gene_info_short, how=\"left\", on=\"gene\")\n",
    "                            \n",
    "gene_pheno_df = gene_pheno_df.merge(zfin_tf_df, how=\"left\", on=\"gene\")\n",
    "\n",
    "gene_pheno_df.loc[np.isnan(gene_pheno_df[\"TF_flag_g\"]), \"TF_flag_g\"] = 0\n",
    "gene_pheno_df.loc[np.isnan(gene_pheno_df[\"TF_flag_z\"]), \"TF_flag_z\"] = 0\n",
    "\n",
    "gene_pheno_df[\"TF_flag\"] = gene_pheno_df[[\"TF_flag_g\", \"TF_flag_z\"]].max(axis=1)\n",
    "\n",
    "gene_pheno_df = gene_pheno_df.drop(labels=[\"TF_flag_g\", \"TF_flag_z\"], axis=1)\n",
    "gene_pheno_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up anatomy data and build an ontology graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, construct full graph\n",
    "edge_vec = anatomy_edges_df[\"Relationship Type ID\"].to_list()\n",
    "keep_edge_types = [\"part of\", \"is_a\"]\n",
    "keep_flags = np.asarray([e in keep_edge_types for e in edge_vec])\n",
    "\n",
    "# filter for only desired edge types\n",
    "edge_df = anatomy_edges_df.loc[keep_flags, [\"Parent Item ID\", \"Child Item ID\", \"Relationship Type ID\"]]\n",
    "edge_df.reset_index(inplace=True, drop=True)\n",
    "node_df = anatomy_nodes_df.loc[:, [\"Anatomy ID\", \"Anatomy Name\"]].drop_duplicates()\n",
    "node_df.reset_index(inplace=True, drop=True)\n",
    "node_df.loc[:, \"node_id\"] = node_df.index\n",
    "\n",
    "# get num observations in the zfin database\n",
    "node_df_temp = node_df.copy().loc[:, [\"Anatomy ID\", \"node_id\"]]\n",
    "node_df_temp = node_df_temp.merge(zfin_pheno_clean.loc[:, \"structure_ID\"], \n",
    "                                  how=\"left\", left_on=\"Anatomy ID\", right_on=\"structure_ID\").loc[:, \n",
    "                                                                            [\"node_id\", \"structure_ID\"]]\n",
    "count_df = node_df_temp.groupby(\"node_id\").count()\n",
    "count_df.reset_index(inplace=True)\n",
    "\n",
    "node_df = node_df.merge(count_df, how=\"left\", on=\"node_id\")\n",
    "node_df = node_df.rename(columns={\"structure_ID\": \"zfin_counts\"})\n",
    "\n",
    "\n",
    "# construct node dictionary\n",
    "anatomy_nodes_id_vec = node_df[\"Anatomy ID\"].to_numpy()\n",
    "node_container = []\n",
    "for i, a_term in enumerate(node_df[\"Anatomy Name\"]):\n",
    "    node_container.append(tuple([i, {\"name\": a_term, \"id\": anatomy_nodes_id_vec[i]}]))\n",
    "\n",
    "\n",
    "# # join node df to edges to get edge IDs\n",
    "edge_df = edge_df.merge(node_df.loc[:, [\"Anatomy ID\", \"node_id\"]], \n",
    "                        how=\"left\", left_on=\"Parent Item ID\", right_on=\"Anatomy ID\")\n",
    "edge_df = edge_df.rename(columns={\"node_id\":\"from_id\"})\n",
    "\n",
    "edge_df = edge_df.merge(node_df.loc[:, [\"Anatomy ID\", \"node_id\"]], \n",
    "                        how=\"left\", left_on=\"Child Item ID\", right_on=\"Anatomy ID\")\n",
    "edge_df = edge_df.rename(columns={\"node_id\":\"to_id\"})\n",
    "                         \n",
    "edge_df = edge_df.loc[:, [\"Parent Item ID\", \"Child Item ID\", \"Relationship Type ID\", \"from_id\", \"to_id\"]]\n",
    "edge_df = edge_df.dropna(subset=[\"from_id\", \"to_id\"])\n",
    "edge_df.reset_index(inplace=True, drop=True)\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "anatomy_graph = nx.DiGraph()\n",
    "anatomy_graph.add_nodes_from(node_container)\n",
    "\n",
    "edge_container = []\n",
    "for i in range(edge_df.shape[0]):\n",
    "    edge_container.append(tuple([edge_df.loc[i, \"from_id\"], edge_df.loc[i, \"to_id\"]]))\n",
    "    \n",
    "anatomy_graph.add_edges_from(edge_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify nodes with no parent. If a node has no parent and no children, remove it unless it has reported observations in the zfin database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = anatomy_graph.nodes\n",
    "root_node_list = []\n",
    "rm_node_list = []\n",
    "for node in node_list:\n",
    "    n_successors = len(list(anatomy_graph.successors(node)))\n",
    "    n_predecessors = len(list(anatomy_graph.predecessors(node)))\n",
    "    \n",
    "    if (n_predecessors==0) and (n_successors > 0):\n",
    "        root_node_list.append(node)\n",
    "        \n",
    "    elif n_predecessors==0:\n",
    "        if node_df.loc[node_df[\"node_id\"]==node, \"zfin_counts\"].values[0] > 0:\n",
    "            root_node_list.append(node)\n",
    "        else:\n",
    "            rm_node_list.append(node)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parent nodes should all be high-level anatomical categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([node_list[n] for n in root_node_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune unconnected nodes and create one master node that unifies the root nodes\n",
    "a_graph_cleaned = anatomy_graph.copy()\n",
    "\n",
    "# remove flagged nodes\n",
    "for node in rm_node_list:\n",
    "    a_graph_cleaned.remove_node(node)\n",
    "    \n",
    "# add master dummy node to connect the graph\n",
    "root_id = np.max(node_list) + 1\n",
    "a_graph_cleaned.add_node(root_id, name=\"anatomy\", id=\"NA\")\n",
    "\n",
    "# add edges\n",
    "link_edge_container = []\n",
    "for i in root_node_list:\n",
    "    link_edge_container.append(tuple([root_id, i]))\n",
    "    \n",
    "a_graph_cleaned.add_edges_from(link_edge_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the initial graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pos = nx.nx_agraph.graphviz_layout(a_graph_cleaned, prog=\"twopi\", args=\"\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw(a_graph_cleaned, pos, node_size=10, alpha=0.5, node_color=\"blue\", with_labels=False)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to tree topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ChatGPT\n",
    "from collections import deque\n",
    "\n",
    "def graph_to_tree_bfs(graph, root_node):\n",
    "    tree = nx.Graph()\n",
    "    visited = set()\n",
    "    queue = deque([root_node])\n",
    "\n",
    "    while queue:\n",
    "        current_node = queue.popleft()\n",
    "        visited.add(current_node)\n",
    "        tree.add_node(current_node, **graph.nodes[current_node])\n",
    "\n",
    "        for neighbor in graph.neighbors(current_node):\n",
    "            if neighbor not in visited:\n",
    "                tree.add_edge(current_node, neighbor)\n",
    "                queue.append(neighbor)\n",
    "                visited.add(neighbor)\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "def graph_to_directed_tree_bfs(graph, root_node):\n",
    "    tree = nx.DiGraph()\n",
    "    visited = set()\n",
    "    queue = deque([root_node])\n",
    "\n",
    "    while queue:\n",
    "        current_node = queue.popleft()\n",
    "        visited.add(current_node)\n",
    "        tree.add_node(current_node, **graph.nodes[current_node])\n",
    "\n",
    "        for neighbor in graph.neighbors(current_node):\n",
    "            if neighbor not in visited:\n",
    "                tree.add_edge(current_node, neighbor)\n",
    "                queue.append(neighbor)\n",
    "                visited.add(neighbor)\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert undirected graph to directed tree\n",
    "a_tree = graph_to_tree_bfs(a_graph_cleaned, root_id)\n",
    "a_tree_dir = graph_to_directed_tree_bfs(a_graph_cleaned, root_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pos = nx.nx_agraph.graphviz_layout(a_tree, prog=\"twopi\", args=\"\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw(a_tree, pos, node_size=10, alpha=0.5, node_color=\"blue\", with_labels=False)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate aggregate observations that include the node AND its children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_index = np.asarray(list(a_tree_dir.nodes))\n",
    "node_index = node_index[np.asarray(node_index) != root_id]\n",
    "\n",
    "# generate count dict\n",
    "node_count_dict = dict({})\n",
    "for node in node_index:\n",
    "    z_counts = node_df.loc[node_df[\"node_id\"]==node, \"zfin_counts\"].values[0]\n",
    "    node_count_dict[node] = z_counts\n",
    "    \n",
    "# get DF that contains only the nodes we kept\n",
    "node_df_tree = node_df.copy()\n",
    "keep_indices = np.asarray([i for i in node_df_tree[\"node_id\"] if i in node_index])\n",
    "node_df_tree = node_df_tree.loc[keep_indices, :]\n",
    "node_df_tree.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# get counts that include children\n",
    "for node in node_index:\n",
    "    \n",
    "    # initialize\n",
    "    z_counts = 0\n",
    "    \n",
    "    # get counts from successor nodes\n",
    "    d_nodes = list(nx.descendants(a_tree_dir, node))\n",
    "    nz_counts = 0\n",
    "    for d in d_nodes:\n",
    "        z_counts += node_count_dict[d]\n",
    "        if node_count_dict[d] > 0:\n",
    "            nz_counts += 1\n",
    "        \n",
    "    node_df_tree.loc[node_df_tree[\"node_id\"]==node, \"d_counts\"] = z_counts\n",
    "    node_df_tree.loc[node_df_tree[\"node_id\"]==node, \"n_counts\"] = len(d_nodes)\n",
    "    node_df_tree.loc[node_df_tree[\"node_id\"]==node, \"nz_counts\"] = nz_counts\n",
    "    \n",
    "    \n",
    "x_limit = np.percentile(node_df_tree[\"zfin_counts\"], 95)\n",
    "y_limit = np.percentile(node_df_tree[\"d_counts\"], 95)\n",
    "\n",
    "node_df_tree.loc[:, \"importance_flag\"] = 0\n",
    "i_filter = (node_df_tree[\"zfin_counts\"] >= x_limit) & (node_df_tree[\"d_counts\"] >= y_limit)\n",
    "node_df_tree.loc[i_filter, \"importance_flag\"] = 1\n",
    "node_df_tree.loc[:, \"importance_flag\"] = node_df_tree.loc[:, \"importance_flag\"].astype(str)\n",
    "\n",
    "node_df_tree[\"size_counts\"] = 25 + node_df_tree.loc[:, \"n_counts\"].to_numpy() \n",
    "node_df_tree.loc[node_df_tree[\"size_counts\"] > 500, \"size_counts\"] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(node_df_tree, x=\"zfin_counts\", y=\"d_counts\", color=\"importance_flag\", size=\"size_counts\",\n",
    "                 log_x=True, log_y=True,\n",
    "                 labels={\"zfin_counts\": \"direct zfin observations\", \n",
    "                         \"d_counts\": \"descendant zfin observations\",\n",
    "                         \"importance_flag\": \"importance flag\",\n",
    "                         \"n_counts\": \"number of descendant phenotypes\"},\n",
    "                hover_data={\"Anatomy Name\":True, \"Anatomy ID\":True, \"size_counts\":False, \n",
    "                            \"n_counts\":True, \"importance_flag\": False})\n",
    "\n",
    "fig.update_layout(showlegend=False,\n",
    "    yaxis_title=\"# descendant reports\", xaxis_title=\"# direct reports on zfin\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(os.path.join(fig_path, \"zfin_importance_scatter.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, iterate through genes and calculate the following:\n",
    "\n",
    "1) Total importance across all phenotypes\n",
    "2) TF flag\n",
    "3) Top 3 reported phenotypes by importance\n",
    "4) Effects for those 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through each gene and calculate an aggregate importance score, as well as its top 3 \"most important\" phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "zfin_pheno_node = zfin_pheno_agg1.merge(node_df.loc[:, [\"Anatomy ID\", \"node_id\"]].drop_duplicates(), how=\"left\",\n",
    "                                      left_on=\"structure_ID\", right_on=\"Anatomy ID\").drop(labels=\"Anatomy ID\", axis=1)\n",
    "\n",
    "zfin_pheno_node = zfin_pheno_node.loc[:, [\"gene\", \"structure\", \"structure_ID\", \"phen_type\", \"report_counts\",\n",
    "                                          \"start_hpf\", \"node_id\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# remove entries with unknown staging info\n",
    "# print(zfin_pheno_node.shape)\n",
    "# zfin_pheno_node = zfin_pheno_node.loc[zfin_pheno_node[\"start_hpf\"]>0, :]\n",
    "# print(zfin_pheno_node.shape)\n",
    "\n",
    "\n",
    "gene_index = list(gene_pheno_df[\"gene\"])\n",
    "gene_node_list = []\n",
    "for g, gene in enumerate(tqdm(gene_index)):\n",
    "    \n",
    "    # get nodes for each phenotype\n",
    "    pheno_nodes = zfin_pheno_node.loc[zfin_pheno_node[\"gene\"]==gene, \"node_id\"].to_numpy()\n",
    "    \n",
    "    # get de-duped list of all descendants\n",
    "    d_list = list(np.unique(pheno_nodes))\n",
    "    for d in d_list:\n",
    "        d_list += list(nx.descendants(a_tree_dir, d))\n",
    "    \n",
    "    d_index = np.unique(d_list)\n",
    "    nz_count = 0\n",
    "    for d in d_index:\n",
    "        if node_count_dict[d] > 0:\n",
    "            nz_count += 1\n",
    "            \n",
    "    # add to DF\n",
    "    gene_pheno_df.loc[g, \"importance_score\"] = nz_count\n",
    "    gene_pheno_df.loc[g, \"n_zfin_reports\"] = np.sum(zfin_pheno_node.loc[zfin_pheno_node[\"gene\"]==gene, \"report_counts\"])\n",
    "    \n",
    "    # get importance ranking for each phenotype\n",
    "    nz_count_list = []\n",
    "    dd_nodes = np.unique(pheno_nodes)\n",
    "    for node in dd_nodes:\n",
    "        nz = node_df_tree.loc[node_df_tree[\"node_id\"]==node, \"nz_counts\"].values[0] + 1\n",
    "        nz_count_list.append(nz)\n",
    "        \n",
    "    si = np.argsort(nz_count_list)\n",
    "    \n",
    "    # add info to table\n",
    "    gene_table = zfin_pheno_node.loc[zfin_pheno_node[\"gene\"]==gene, :].reset_index(drop=True)\n",
    "    ranked_node_ids = dd_nodes[si[::-1]]\n",
    "    if len(ranked_node_ids) > 0:\n",
    "        filter0 = gene_table[\"node_id\"]==ranked_node_ids[0]\n",
    "        gene_pheno_df.loc[g, \"phenotype_1\"] = gene_table.loc[filter0, \"structure\"].values[0]\n",
    "        gene_pheno_df.loc[g, \"effect_1\"] = gene_table.loc[filter0, \"phen_type\"].values[0]\n",
    "        gene_pheno_df.loc[g, \"start_hpf_1\"] = gene_table.loc[filter0, \"start_hpf\"].values[0]\n",
    "    else:\n",
    "        gene_pheno_df.loc[g, \"phenotype_1\"] = \"\"\n",
    "        gene_pheno_df.loc[g, \"effect_1\"] = \"\"\n",
    "        gene_pheno_df.loc[g, \"start_hpf_1\"] = np.nan\n",
    "    \n",
    "    if len(ranked_node_ids) > 1:\n",
    "        filter1 = gene_table[\"node_id\"]==ranked_node_ids[1]\n",
    "        gene_pheno_df.loc[g, \"phenotype_2\"] = gene_table.loc[filter1, \"structure\"].values[0]\n",
    "        gene_pheno_df.loc[g, \"effect_2\"] = gene_table.loc[filter1, \"phen_type\"].values[0]\n",
    "        gene_pheno_df.loc[g, \"start_hpf_2\"] = gene_table.loc[filter1, \"start_hpf\"].values[0]\n",
    "    else:\n",
    "        gene_pheno_df.loc[g, \"phenotype_2\"] = \"\"\n",
    "        gene_pheno_df.loc[g, \"effect_2\"] = \"\"\n",
    "        gene_pheno_df.loc[g, \"start_hpf_2\"] = np.nan\n",
    "        \n",
    "    if len(ranked_node_ids) > 2:\n",
    "        filter2 = gene_table[\"node_id\"]==ranked_node_ids[2]\n",
    "        gene_pheno_df.loc[g, \"phenotype_3\"] = gene_table.loc[filter2, \"structure\"].values[0]\n",
    "        gene_pheno_df.loc[g, \"effect_3\"] = gene_table.loc[filter2, \"phen_type\"].values[0]\n",
    "        gene_pheno_df.loc[g, \"start_hpf_3\"] = gene_table.loc[filter2, \"start_hpf\"].values[0]\n",
    "    else:\n",
    "        gene_pheno_df.loc[g, \"phenotype_3\"] = \"\"\n",
    "        gene_pheno_df.loc[g, \"effect_3\"] = \"\"\n",
    "        gene_pheno_df.loc[g, \"start_hpf_3\"] = np.nan\n",
    "        \n",
    "        \n",
    "# remove genes with no phenotype\n",
    "print(gene_pheno_df.shape)\n",
    "gene_pheno_df = gene_pheno_df.loc[gene_pheno_df[\"phenotype_1\"] != \"\", :]\n",
    "print(gene_pheno_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_pheno_df = gene_pheno_df.sort_values(by=[\"TF_flag\", \"importance_score\"], axis=0, ascending=False)\n",
    "gene_pheno_df.reset_index(inplace=True, drop=True)\n",
    "gene_pheno_df.to_csv(os.path.join(built_data_dir, \"zfin_gene_KO_candidates.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_pheno_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
