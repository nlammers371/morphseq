{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmx_image_dir = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/analysis/lmx1b\"\n",
    "lmx_seq_dir = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/sci-PLEX/processed_sci_data/lmx1b_combined_analysis\"\n",
    "\n",
    "# load morph metadata DF\n",
    "morph_df = pd.read_csv(os.path.join(lmx_image_dir, \"embryo_df.csv\"), index_col=0)\n",
    "morph_df.drop(labels=[\"index\"], inplace=True, axis=1)\n",
    "\n",
    "# load hooke latent log counts \n",
    "hooke_latent_df = pd.read_csv(os.path.join(lmx_seq_dir, \"lmx_gene_timepoint_latent_encodings.csv\"), index_col=0)\n",
    "hooke_latent_pos_df = pd.read_csv(os.path.join(lmx_seq_dir, \"lmx_hooke_latent_pos.csv\"), index_col=0)\n",
    "raw_cell_counts_df = pd.read_csv(os.path.join(lmx_seq_dir, \"lmx_all_cell_counts.csv\"), index_col=0)\n",
    "\n",
    "# add embryo names and cell types to latent DF\n",
    "\n",
    "hooke_latent_df.columns = raw_cell_counts_df.index\n",
    "hooke_latent_df[\"embryo\"] = raw_cell_counts_df.columns\n",
    "hooke_latent_df.reset_index(inplace=True)\n",
    "# mapper_dict = dict({})\n",
    "# for c in range(len(hooke_latent_df.columns)):\n",
    "#     mapper_dict[c] = {hooke_latent_df.columns[c] : raw_cell_counts_df.index[c]}\n",
    "\n",
    "# parse metadata from embryo field\n",
    "for r in range(hooke_latent_df.shape[0]):\n",
    "    emb = hooke_latent_df.loc[r, \"embryo\"]\n",
    "    meta_vec = emb.split(\".\")\n",
    "    \n",
    "    hooke_latent_df.loc[r, \"perturbation\"] = meta_vec[0]\n",
    "    hooke_latent_df.loc[r, \"stage_hpf\"] = meta_vec[1]\n",
    "    hooke_latent_df.loc[r, \"temperature\"] = meta_vec[2]\n",
    "    hooke_latent_df.loc[r, \"hash_plate\"] = meta_vec[4]\n",
    "    hash_well_raw  = meta_vec[5]\n",
    "    \n",
    "    if len(hash_well_raw) == 2:\n",
    "        hash_well_new = hash_well_raw[0] + \"0\" + hash_well_raw[1]\n",
    "        hooke_latent_df.loc[r, \"hash_well\"] = hash_well_new\n",
    "    else:\n",
    "        hooke_latent_df.loc[r, \"hash_well\"] = hash_well_raw\n",
    "    \n",
    "# adjust col ordering\n",
    "cols_init = hooke_latent_df.columns.tolist()\n",
    "cols_new = cols_init[-6:] + cols_init[1:-6]\n",
    "\n",
    "hooke_latent_df = hooke_latent_df.loc[:, cols_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP embeddings for the lmx1b images\n",
    "fig = px.scatter_3d(morph_df, x=\"UMAP_00_bio_3\", y=\"UMAP_01_bio_3\", z=\"UMAP_02_bio_3\", color=\"master_perturbation\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(morph_df, x=\"UMAP_00_bio_3\", y=\"UMAP_01_bio_3\", z=\"UMAP_02_bio_3\", color=\"predicted_stage_hpf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit UMAP to latent cell count data\n",
    "n_components = 3\n",
    "reducer = umap.UMAP(n_components=n_components)\n",
    "\n",
    "latent_array = hooke_latent_df.iloc[:, 6:]\n",
    "# scaled_z_mu = StandardScaler().fit_transform(z_mu_array)\n",
    "embedding = reducer.fit_transform(latent_array)\n",
    "\n",
    "# add to the data frame\n",
    "hooke_latent_df[\"UMAP_hooke_00_3\"] = embedding[:, 0]\n",
    "hooke_latent_df[\"UMAP_hooke_01_3\"] = embedding[:, 1]\n",
    "hooke_latent_df[\"UMAP_hooke_02_3\"] = embedding[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(hooke_latent_df, x=\"UMAP_hooke_00_3\", y=\"UMAP_hooke_01_3\", z=\"UMAP_hooke_02_3\", color=\"perturbation\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(hooke_latent_df, x=\"UMAP_hooke_00_3\", y=\"UMAP_hooke_01_3\", z=\"UMAP_hooke_02_3\", color=\"stage_hpf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(hooke_latent_df, x=\"UMAP_hooke_00_3\", y=\"UMAP_hooke_01_3\", z=\"UMAP_hooke_02_3\", color=\"hash_plate\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in metadata to link image and sequencing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/metadata\"\n",
    "\n",
    "# load master experimental log \n",
    "experiment_df = pd.read_csv(os.path.join(metadata_path, \"experiment_metadata.csv\"), index_col=0)\n",
    "morphseq_meta_df = experiment_df.loc[experiment_df[\"has_sci_data\"]==1, :]\n",
    "\n",
    "# load sheets that contain morph-to-seq maps\n",
    "date_vec = morphseq_meta_df[\"start_date\"].astype(str).tolist()\n",
    "hash_plate_vec = morphseq_meta_df[\"hash_plate_number\"].tolist()\n",
    "hash_plate_vec = [\"P\" + f\"{int(h):02}\" for h in hash_plate_vec]\n",
    "# generate list to use for indexing\n",
    "col_id_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "row_letter_list = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "well_name_list = []\n",
    "for r in range(len(row_letter_list)):\n",
    "    for c in range(len(col_id_list)):\n",
    "        well_name = row_letter_list[r] + f\"{col_id_list[c]:02}\"\n",
    "        well_name_list.append(well_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphseq_map_list = []\n",
    "for d, date in enumerate(date_vec):\n",
    "    xl_temp = pd.ExcelFile(os.path.join(metadata_path, \"well_metadata\", date + \"_well_metadata.xlsx\"))\n",
    "    genotype_map = xl_temp.parse(\"genotype\").iloc[:8, 1:13].to_numpy().ravel()\n",
    "    hash_to_image_map = xl_temp.parse(\"hash_to_image_map\").iloc[:8, 1:13].to_numpy().ravel()\n",
    "    age_map = xl_temp.parse(\"start_age_hpf\").iloc[:8, 1:13].to_numpy().ravel()\n",
    "    image_notes_map = xl_temp.parse(\"image_notes\").iloc[:8, 1:13].to_numpy().ravel()\n",
    "    qc_map = xl_temp.parse(\"morph_seq_qc\").iloc[:8, 1:13].to_numpy().ravel()\n",
    "    \n",
    "    # add fields to dataframe\n",
    "    morph_map_df = pd.DataFrame(genotype_map[:, np.newaxis], columns=[\"master_perturbation\"])\n",
    "    morph_map_df[\"hash_plate\"] = hash_plate_vec[d]\n",
    "    morph_map_df[\"experiment_date\"] = date\n",
    "    morph_map_df[\"hash_well\"] = hash_to_image_map\n",
    "    morph_map_df[\"image_well\"] = well_name_list\n",
    "    morph_map_df[\"stage_hpf\"] = age_map\n",
    "    morph_map_df[\"morphseq_qc_flag\"] = qc_map\n",
    "    morph_map_df[\"notes\"] = image_notes_map\n",
    "    \n",
    "    # remove entries with no hash well and clean up variable types/well names\n",
    "    morph_map_df = morph_map_df.loc[~morph_map_df[\"hash_well\"].isnull(), :]\n",
    "    morph_map_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    for row in range(morph_map_df.shape[0]):\n",
    "        hash_well_raw = morph_map_df.loc[row, \"hash_well\"]\n",
    "        if len(hash_well_raw) == 2:\n",
    "            hash_well_new = hash_well_raw[0] + \"0\" + hash_well_raw[1]\n",
    "            morph_map_df.loc[row, \"hash_well\"] = hash_well_new\n",
    "            \n",
    "    \n",
    "    morph_map_df[\"master_perturbation\"] = morph_map_df[\"master_perturbation\"].astype(str)\n",
    "    \n",
    "    morphseq_map_list.append(morph_map_df)\n",
    "    \n",
    "morphseq_df = pd.concat(morphseq_map_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build linked datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = morphseq_df.merge(hooke_latent_df, on=[\"hash_plate\", \"hash_well\"], how=\"left\", copy=False)\n",
    "\n",
    "key = dict({\"uninj\": \"wik\", \"ctrl-inj\": \"wik-ctrl-inj\", \"tbxta\": \"tbxta\", \"lmx1b\":\"lmx1b\"})\n",
    "for row in range(master_df.shape[0]):\n",
    "    seq_lb = master_df.loc[row, \"perturbation\"]\n",
    "    new_lb = key[seq_lb]\n",
    "    master_df.loc[row, \"perturbation\"] = new_lb\n",
    "    \n",
    "# check for inconsistencies\n",
    "# error_indices = np.where(master_df[\"master_perturbation\"] != master_df[\"perturbation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on the morph model data\n",
    "for row in range(morph_df.shape[0]):\n",
    "    meta_vec = morph_df.loc[row, \"snip_id\"].split(\"_\")\n",
    "    morph_df.loc[row, \"image_well\"] = meta_vec[1]\n",
    "morph_df[\"experiment_date\"] = morph_df[\"experiment_date\"].astype(str)\n",
    "    \n",
    "master_df = master_df.merge(morph_df, on=[\"image_well\", \"experiment_date\"], how=\"left\", copy=False)\n",
    "# master_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop problematic entries, rename variables and drop extraneous variables\n",
    "master_df_clean = master_df.loc[~master_df[\"master_perturbation_y\"].isnull(), :] # removes one 8/30 entry missing from images (\"H03\")\n",
    "master_df_clean = master_df_clean.loc[master_df_clean[\"morphseq_qc_flag\"]==0, :]\n",
    "\n",
    "master_df_clean.rename({\"master_perturbation_x\" : \"master_perturbation\", \"stage_hpf_x\": \"stage_hpf\"}, inplace=True, axis=1)\n",
    "master_df_clean.drop([\"master_perturbation_y\", \"stage_hpf_y\"], inplace=True, axis=1)\n",
    "master_df_clean.reset_index(inplace=True, drop=True)\n",
    "master_df_clean.to_csv(os.path.join(lmx_image_dir, \"lmx_morphseq_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with predicting morphology from sequence space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "n_train = 100\n",
    "np.random.seed(154)\n",
    "option_vec = range(master_df_clean.shape[0])\n",
    "train_indices = np.random.choice(option_vec, n_train, replace=False)\n",
    "test_indices = np.asarray([i for i in option_vec if i not in train_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = master_df_clean.loc[train_indices, [\"UMAP_00_bio_3\", \"UMAP_01_bio_3\", \"UMAP_02_bio_3\"]]\n",
    "Y_test = master_df_clean.loc[test_indices, [\"UMAP_00_bio_3\", \"UMAP_01_bio_3\", \"UMAP_02_bio_3\"]]\n",
    "\n",
    "X_train = master_df_clean.loc[train_indices, [\"UMAP_hooke_00_3\", \"UMAP_hooke_01_3\", \"UMAP_hooke_02_3\"]]\n",
    "X_test = master_df_clean.loc[test_indices, [\"UMAP_hooke_00_3\", \"UMAP_hooke_01_3\", \"UMAP_hooke_02_3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(random_state=1, max_iter=5000)\n",
    "regr.fit(X_train, Y_train)\n",
    "regr.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pd = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.reset_index(inplace=True, drop=True)\n",
    "Y_test_arr = Y_test.to_numpy()\n",
    "pert_id_test = master_df_clean.loc[test_indices,\"master_perturbation\"].to_numpy()\n",
    "color_dict = dict({\"lmx1b\" : \"lightskyblue\", \"wik\":\"gray\", \"wik-ctrl-inj\":\"black\", \"tbxta\":\"seagreen\"})\n",
    "color_vec = [color_dict[p] for p in pert_id_test]\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for r in range(Y_test.shape[0]):\n",
    "    data = np.concatenate((Y_test_arr[r, :].reshape((1,3)), Y_test_pd[r, :].reshape((1,3))), axis=0)\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(x=data[:, 0], y=data[:, 1], z=data[:, 2], mode=\"lines+markers\", \n",
    "                               line=dict(color=\"black\"), marker=dict(size=1)))\n",
    "    \n",
    "fig.add_trace(go.Scatter3d(x=Y_test_arr[:, 0], y=Y_test_arr[:, 1], z=Y_test_arr[:, 2], mode=\"markers\", \n",
    "                         marker=dict(color=color_vec, size=5)))\n",
    "fig.add_trace(go.Scatter3d(x=Y_test_pd[:, 0], y=Y_test_pd[:, 1], z=Y_test_pd[:, 2], mode=\"markers\", \n",
    "                         marker=dict(color=color_vec, size=5, symbol=\"diamond\")))\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try removing tbxta embryos from the datasets to see if intra-cluster prediction can be improved\n",
    "pert_id_train = master_df_clean.loc[train_indices,\"master_perturbation\"].to_numpy()\n",
    "not_tbxta_train = pert_id_train != \"tbxta\"\n",
    "pert_id_test = master_df_clean.loc[test_indices,\"master_perturbation\"].to_numpy()\n",
    "not_tbxta_test = pert_id_test != \"tbxta\"\n",
    "\n",
    "Y_train2 = Y_train.loc[not_tbxta_train]\n",
    "Y_test2 = Y_test.loc[not_tbxta_test]\n",
    "\n",
    "X_train2 = X_train.loc[not_tbxta_train]\n",
    "X_test2 = X_test.loc[not_tbxta_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2 = MLPRegressor(random_state=1, max_iter=5000, hidden_layer_sizes=(500,))\n",
    "regr2.fit(X_train2, Y_train2)\n",
    "reg_score = regr2.score(X_test2, Y_test2)\n",
    "\n",
    "Y_test_pd2 = regr.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_score_test2 = regr2.score(X_test2, Y_test2)\n",
    "reg_score_train2 = regr2.score(X_train2, Y_train2)\n",
    "print(reg_score_test2)\n",
    "print(reg_score_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test2.reset_index(inplace=True, drop=True)\n",
    "Y_test_arr2 = Y_test2.to_numpy()\n",
    "pert_id_test_plot = pert_id_test[not_tbxta_test]\n",
    "color_dict = dict({\"lmx1b\" : \"lightskyblue\", \"wik\":\"gray\", \"wik-ctrl-inj\":\"seagreen\"})\n",
    "color_vec = [color_dict[p] for p in pert_id_test_plot]\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for r in range(Y_test2.shape[0]):\n",
    "    data = np.concatenate((Y_test_arr2[r, :].reshape((1,3)), Y_test_pd2[r, :].reshape((1,3))), axis=0)\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(x=data[:, 0], y=data[:, 1], z=data[:, 2], mode=\"lines+markers\", \n",
    "                               line=dict(color=\"black\"), marker=dict(size=1)))\n",
    "    \n",
    "fig.add_trace(go.Scatter3d(x=Y_test_arr2[:, 0], y=Y_test_arr2[:, 1], z=Y_test_arr2[:, 2], mode=\"markers\", \n",
    "                         marker=dict(color=color_vec, size=5)))\n",
    "fig.add_trace(go.Scatter3d(x=Y_test_pd2[:, 0], y=Y_test_pd2[:, 1], z=Y_test_pd2[:, 2], mode=\"markers\", \n",
    "                         marker=dict(color=color_vec, size=5, symbol=\"diamond\")))\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That went...ok. Let's try some basic clustering stuff next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=15).fit(master_df_clean.loc[:, [\"UMAP_hooke_00_3\", \"UMAP_hooke_01_3\", \"UMAP_hooke_02_3\"]])\n",
    "\n",
    "fig = px.scatter_3d(master_df_clean, x=\"UMAP_hooke_00_3\", y=\"UMAP_hooke_01_3\", z=\"UMAP_hooke_02_3\", color=kmeans.labels_.astype(str))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(master_df_clean, x=\"UMAP_00_bio_3\", y=\"UMAP_01_bio_3\", z=\"UMAP_02_bio_3\", \n",
    "                    color=kmeans.labels_.astype(str))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train multiple models and take the one that performes the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try removing tbxta embryos from the datasets to see if intra-cluster prediction can be improved\n",
    "pert_id_train = master_df_clean.loc[train_indices,\"master_perturbation\"].to_numpy()\n",
    "not_tbxta_train = pert_id_train != \"tbxta\"\n",
    "pert_id_test = master_df_clean.loc[test_indices,\"master_perturbation\"].to_numpy()\n",
    "not_tbxta_test = pert_id_test != \"tbxta\"\n",
    "\n",
    "Y_train3 = Y_train.loc[not_tbxta_train]\n",
    "Y_test3 = Y_test.loc[not_tbxta_test]\n",
    "\n",
    "X_train3 = X_train.loc[not_tbxta_train]\n",
    "X_test3 = X_test.loc[not_tbxta_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state_vec = [1, 2, 3]\n",
    "hl_size_vec = [250, 500, 1000]\n",
    "score_vec = []\n",
    "sz_vec = []\n",
    "rs_vec = []\n",
    "mdl_vec = []\n",
    "for r in random_state_vec:\n",
    "    for sz in hl_size_vec:\n",
    "        regr2 = MLPRegressor(random_state=r, max_iter=5000, hidden_layer_sizes=(sz,))\n",
    "        regr2.fit(X_train3, Y_train3)\n",
    "        reg_score_train = regr2.score(X_train3, Y_train3)\n",
    "        \n",
    "        score_vec.append(reg_score_train)\n",
    "        sz_vec.append(sz)\n",
    "        rs_vec.append(r)\n",
    "        mdl_vec.append(regr2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ind = np.argmax(score_vec)\n",
    "best_score = np.max(score_vec)\n",
    "\n",
    "print(best_ind)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = mdl_vec[best_ind]\n",
    "reg_score_test3 = mdl.score(X_test3, Y_test3)\n",
    "Y_test_pd3 = mdl.predict(X_test3)\n",
    "\n",
    "print(reg_score_test3)\n",
    "\n",
    "sz_vec[best_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if we use the full latent space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract hooke latents\n",
    "hook_latent_array = master_df_clean.loc[:, raw_cell_counts_df.index.tolist()].to_numpy()\n",
    "\n",
    "# remove tbxta\n",
    "pert_id_train = master_df_clean.loc[train_indices,\"master_perturbation\"].to_numpy()\n",
    "not_tbxta_train = pert_id_train != \"tbxta\"\n",
    "pert_id_test = master_df_clean.loc[test_indices,\"master_perturbation\"].to_numpy()\n",
    "not_tbxta_test = pert_id_test != \"tbxta\"\n",
    "\n",
    "# make test and train sets\n",
    "X_train4 = hook_latent_array[train_indices[not_tbxta_train], :]\n",
    "X_test4 = hook_latent_array[test_indices[not_tbxta_test], :]\n",
    "\n",
    "Y_train4 = master_df_clean.loc[train_indices[not_tbxta_train], [\"UMAP_00_bio_3\", \"UMAP_01_bio_3\", \"UMAP_02_bio_3\"]].to_numpy()\n",
    "Y_test4 = master_df_clean.loc[test_indices[not_tbxta_test], [\"UMAP_00_bio_3\", \"UMAP_01_bio_3\", \"UMAP_02_bio_3\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr4 = MLPRegressor(random_state=1, max_iter=5000, hidden_layer_sizes=(500,))\n",
    "regr4.fit(X_train4, Y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_score_train = regr4.score(X_train4, Y_train4)\n",
    "reg_score_test = regr4.score(X_test4, Y_test4)\n",
    "\n",
    "print(reg_score_train)\n",
    "print(reg_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about morph-to-seq?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train5 = X_train3\n",
    "Y_test5 = X_test3\n",
    "\n",
    "X_train5 = Y_train3\n",
    "X_test5 = Y_test3\n",
    "\n",
    "regr5 = MLPRegressor(random_state=1, hidden_layer_sizes=(5000,))\n",
    "regr5.fit(X_train5, Y_train5.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_score_train = regr5.score(X_train5, Y_train5.iloc[:, 0])\n",
    "reg_score_test = regr5.score(X_test5, Y_test5.iloc[:, 0])\n",
    "\n",
    "print(reg_score_train)\n",
    "print(reg_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.loc[master_df_clean[\"image_well\"]==\"D09\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note images with potential \n",
    "qc_list = [\"20230830.E02\", \"20230831.A01\", \"20230831.A06\", \"20230831.B03\", \"20230831.C06\", \n",
    "           \"20230831.D02\", \"20230832.D06\", \"20230831.E06\", \"20230831.F05\", ,\n",
    "           \"20231208.G07\"]\n",
    "code[\"dorsal\", \"dorsal\", \"dorsal\", \"segmentation\", \"dorsal\", \n",
    "     \"saturation\", \"dorsal\", \"saturation\", \"segmentation (bad)\", \"dorsal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note a few particularly severe lmx embryos\n",
    "lmx_list = [\"20230830.A01\", \"20230830.A02\", \"20230830.D02\", \"20230830.E01\", \"20230830.G01\", \n",
    "            \"20230831.A05\", \"20230831.B01\", \"20230831.B05\" , \"20230831.C05\", \"20230831.D01\", \"20230831.H06\",\n",
    "            \"20231207.G02\", \"20231208.A02\", \"20231208.B09\", \"20231208.C08\", \"20231208.D01\"]\n",
    "phenotype = np.asarray([0, 2.5, 2.5, 4.5, 1, 2.5, 4.5, 3, 5, 0.5, 3, 1, 3, 3.5, 3, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ids = [] \n",
    "from_ids = []\n",
    "for i in range(len(lmx_list)):\n",
    "    meta_vec = lmx_list[i].split(\".\")\n",
    "    bool1 = master_df_clean[\"experiment_date\"]==meta_vec[0]\n",
    "    bool2 = master_df_clean[\"image_well\"]==meta_vec[1]\n",
    "    if any(bool1 & bool2):\n",
    "        ref_ids.append(np.where(bool1 & bool2)[0][0])\n",
    "        from_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(master_df_clean, x=\"UMAP_00_bio_3\", y=\"UMAP_01_bio_3\", z=\"UMAP_02_bio_3\", \n",
    "                    color=\"master_perturbation\", opacity=0.2)\n",
    "\n",
    "mdf_sub = master_df_clean.loc[ref_ids, :]\n",
    "mdf_sub[\"phenotype_score\"] = phenotype[np.asarray(from_ids)]\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=mdf_sub.loc[:, \"UMAP_00_bio_3\"], \n",
    "                           y=mdf_sub.loc[:, \"UMAP_01_bio_3\"], \n",
    "                           z=mdf_sub.loc[:, \"UMAP_02_bio_3\"], \n",
    "                          mode=\"markers\", marker=dict(color=phenotype[np.asarray(from_ids)])))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(mdf_sub, x=\"UMAP_00_bio_3\", y=\"UMAP_01_bio_3\", z=\"UMAP_02_bio_3\", \n",
    "                    color=\"snip_id\", opacity=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(master_df_clean, x=\"UMAP_hooke_00_3\", y=\"UMAP_hooke_01_3\", z=\"UMAP_hooke_02_3\", \n",
    "                    color=\"master_perturbation\", opacity=0.2)\n",
    "\n",
    "mdf_sub = master_df_clean.loc[ref_ids, :]\n",
    "mdf_sub[\"phenotype_score\"] = phenotype[np.asarray(from_ids)]\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=mdf_sub.loc[:, \"UMAP_hooke_00_3\"], \n",
    "                           y=mdf_sub.loc[:, \"UMAP_hooke_01_3\"], \n",
    "                           z=mdf_sub.loc[:, \"UMAP_hooke_02_3\"], \n",
    "                          mode=\"markers\", marker=dict(color=phenotype[np.asarray(from_ids)])))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
