{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test FF methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# script to define functions_folder for loading and standardizing fish movies\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/net/trapnell/vol1/home/nlammers/projects/data/morphseq/src\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import (exposure, feature, filters, io, measure,\n",
    "                      morphology, restoration, segmentation, transform,\n",
    "                      util)\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import glob2 as glob\n",
    "# from src.functions.image_utils import doLap\n",
    "# from src.functions.utilities import path_leaf\n",
    "from skimage.transform import resize\n",
    "from aicsimageio import AICSImage\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from parfor import pmap\n",
    "import pandas as pd\n",
    "import time\n",
    "import nd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_flag = False\n",
    "data_root = \"/net/trapnell/vol1/home/nlammers/projects/data/morphseq/\"\n",
    "dir_list = [\"20231206\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "def path_leaf(path):\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)\n",
    "\n",
    "def doLap(image, lap_size=3, blur_size=3):\n",
    "\n",
    "    # YOU SHOULD TUNE THESE VALUES TO SUIT YOUR NEEDS\n",
    "#     kernel_size = 5  # Size of the laplacian window\n",
    "#     blur_size = 5  # How big of a kernal to use for the gaussian blur\n",
    "    # Generally, keeping these two values the same or very close works well\n",
    "    # Also, odd numbers, please...\n",
    "\n",
    "    blurred = cv2.GaussianBlur(image, (blur_size, blur_size), 0)\n",
    "    return cv2.Laplacian(blurred, cv2.CV_64F, ksize=lap_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir_root = os.path.join(data_root, 'raw_image_data', 'YX1') \n",
    "\n",
    "d = 0\n",
    "# initialize dictionary to metadata\n",
    "sub_name = dir_list[d]\n",
    "dir_path = os.path.join(read_dir_root, sub_name, \"\")\n",
    "\n",
    "# Read in  metadata object\n",
    "image_list = sorted(glob.glob(dir_path + \"*.nd2\")) \n",
    "if len(image_list) > 1:\n",
    "    raise Exception(\"Multiple nd2 files found in \" + sub_name + \". Please move extra nd2 files to a subfolder.\" )\n",
    "elif len(image_list) == 0:\n",
    "    raise Exception(\"No nd2 files found in \" + sub_name)\n",
    "\n",
    "# Read in experiment metadata \n",
    "print(f\"Processing {sub_name}...\")\n",
    "\n",
    "imObject= nd2.ND2File(image_list[0])\n",
    "im_shape = imObject.shape\n",
    "n_time_points = im_shape[0]\n",
    "n_wells = im_shape[1]\n",
    "n_z_slices = im_shape[2]\n",
    "print(n_z_slices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "rs_res = np.asarray([5.66, 5.66])\n",
    "\n",
    "# pull dask array\n",
    "im_array_dask = imObject.to_dask()\n",
    "\n",
    "# extract frame times\n",
    "time_int = 10\n",
    "well_int = 1\n",
    "\n",
    "# get image resolution\n",
    "voxel_size = imObject.voxel_size()\n",
    "voxel_yx = np.asarray([voxel_size[1], voxel_size[0]])\n",
    "rs_factor = np.divide(voxel_yx, rs_res)\n",
    "\n",
    "rs_dims_yx = np.round(np.multiply(np.asarray(im_shape[3:]), rs_factor)).astype(int)\n",
    "# resample images to a standardized resolution\n",
    "\n",
    "data_zyx = im_array_dask[time_int, well_int, :, :, :].compute()\n",
    "\n",
    "data_zyx_rs = resize(data_zyx, (data_zyx.shape[0], rs_dims_yx[0], rs_dims_yx[1]), preserve_range=True)\n",
    "# data_zyx_rs = data_zyx_rs.astype(data_zyx.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(data_zyx[12,:, :]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_zyx_rs = resize(data_zyx, (data_zyx.shape[0], rs_dims_yx[0], rs_dims_yx[1]), preserve_range=True)\n",
    "# data_zyx_rs = data_zyx\n",
    "\n",
    "# normalize image to maximize dynamic range\n",
    "px99 = np.percentile(data_zyx, 99)\n",
    "data_zyx_rs = data_zyx_rs / px99\n",
    "data_zyx_rs[data_zyx_rs>1] = 1\n",
    "data_zyx_rs = np.round(data_zyx_rs * 65535).astype(np.uint16)\n",
    "\n",
    "# calculate FF image\n",
    "laps = []\n",
    "laps_d = []\n",
    "for i in range(data_zyx_rs.shape[0]):\n",
    "    laps.append(doLap(data_zyx_rs[i, :, :], lap_size=3, blur_size=3))\n",
    "\n",
    "laps = np.asarray(laps)\n",
    "abs_laps = np.absolute(laps)\n",
    "\n",
    "# calculate full-focus and depth images\n",
    "ff_image = np.zeros(shape=data_zyx_rs[0].shape, dtype=data_zyx_rs.dtype)\n",
    "maxima = abs_laps.max(axis=0)\n",
    "bool_mask = abs_laps == maxima\n",
    "mask = bool_mask.astype(np.uint8)\n",
    "for i in range(data_zyx_rs.shape[0]):\n",
    "    ff_image[np.where(mask[i] == 1)] = data_zyx_rs[i][np.where(mask[i] == 1)]\n",
    "\n",
    "\n",
    "ff_image = 65535 - ff_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.sum(bool_mask, axis=1), axis=1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ff_image)\n",
    "# plt.clim(0, 15000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imsave(\"test.png\", ff_image[500:, :1400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_image.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get paths to data, figures, and latent space outputs\n",
    "overwrite_flag = False\n",
    "data_root = \"/net/trapnell/vol1/home/nlammers/projects/data/morphseq/\"\n",
    "dir_list = [\"20231206\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "read_dir_root = os.path.join(data_root, 'raw_image_data', 'YX1') \n",
    "if write_dir is None:\n",
    "    write_dir = os.path.join(data_root, 'built_image_data', 'YX1') \n",
    "    \n",
    "# handle paths\n",
    "if dir_list is None:\n",
    "    # Get a list of directories\n",
    "    dir_list_raw = sorted(glob.glob(read_dir_root + \"*\"))\n",
    "    dir_list = []\n",
    "    for dd in dir_list_raw:\n",
    "        if os.path.isdir(dd):\n",
    "            dir_list.append(path_leaf(dd))\n",
    "\n",
    "if rs_res is None:\n",
    "    rs_res = np.asarray([5.66, 5.66])\n",
    "\n",
    "# filter for desired directories\n",
    "dir_indices = [d for d in range(len(dir_list)) if \"ignore\" not in dir_list[d]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "os.listdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "last_training = sorted(os.listdir(model_path))[-2]\n",
    "    \n",
    "m_fig_path = os.path.join(model_path, last_training, \"figures\")\n",
    "    \n",
    "# load data frame with results\n",
    "morph_df = pd.read_csv(os.path.join(m_fig_path, \"embryo_stats_df.csv\"), index_col=0)\n",
    "metric_df = pd.read_csv(os.path.join(m_fig_path, \"metric_df.csv\"), index_col=0)\n",
    "meta_df = pd.read_csv(os.path.join(m_fig_path, \"meta_summary_df.csv\"), index_col=0)\n",
    "loss_df = pd.read_csv(os.path.join(model_path, last_training, \"loss_tracker.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "wik_indices = np.where(morph_df[\"master_perturbation\"]==\"wck-AB\")[0]\n",
    "\n",
    "fig = px.scatter(morph_df.iloc[wik_indices], x=\"UMAP_00\", y=\"UMAP_01\", color=\"predicted_stage_hpf\", opacity=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(morph_df.iloc[wik_indices], x=\"UMAP_00_bio\", y=\"UMAP_01_bio\", color=\"predicted_stage_hpf\", \n",
    "                 opacity=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(morph_df.iloc[wik_indices], x=\"UMAP_00_bio\", y=\"UMAP_01_bio\", color=\"train_cat\", \n",
    "                 opacity=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(morph_df.iloc[wik_indices], x=\"UMAP_00_n\", y=\"UMAP_01_n\", color=\"predicted_stage_hpf\", \n",
    "                 opacity=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the imposition of a metric constraint on the biological latent variables, they still quite obviously encode orientational differences. Why?\n",
    "\n",
    "It could be that the model doing a good job with cosine distance, but that this does not translate to the euclidean space that is being read out (and warped in obscure ways) by the UMAP compression.\n",
    "\n",
    "It is also possible that the metric loss is simply outcompeted by other terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "metric_df0 = metric_df.iloc[np.where(metric_df[\"contrast_id\"]==0)]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(x=metric_df0[\"cos_all\"], histnorm=\"probability\", name=\"all latent variables\"))\n",
    "fig.add_trace(go.Histogram(x=metric_df0[\"cos_bio\"], histnorm=\"probability\", name=\"biological partition\"))\n",
    "fig.add_trace(go.Histogram(x=metric_df0[\"cos_nbio\"], histnorm=\"probability\", name=\"non-biological partition\"))\n",
    "fig.update_layout(title=\"Cosine similarity scores between pairs of transformed images\")\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, SOMETHING is being learned such that the distance between transformed versions of the same image look more similar in the biological partition (according to the cosine metric) than in the non-biological one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# I think we need to normalize by number of bio and non-bio variables\n",
    "n_bio = 90\n",
    "n_nbio = 10\n",
    "\n",
    "metric_df0.loc[:, \"euc_all_norm\"] = metric_df0.loc[:, \"euc_all\"] / np.sqrt(n_bio + n_nbio)\n",
    "metric_df0.loc[:, \"euc_bio_norm\"] = metric_df0.loc[:, \"euc_bio\"] / np.sqrt(n_bio)\n",
    "metric_df0.loc[:, \"euc_nbio_norm\"] = metric_df0.loc[:, \"euc_nbio\"] / np.sqrt(n_nbio)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(x=metric_df0[\"euc_all_norm\"], histnorm=\"probability\", name=\"all latent variables\"))\n",
    "fig.add_trace(go.Histogram(x=metric_df0[\"euc_bio_norm\"], histnorm=\"probability\", name=\"biological partition\"))\n",
    "fig.add_trace(go.Histogram(x=metric_df0[\"euc_nbio_norm\"], histnorm=\"probability\", name=\"non-biological partition\"))\n",
    "fig.update_layout(title=\"Average Euclidean distance between pairs of transformed images\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = px.line(loss_df, x=\"epoch\", y=\"ntxent_loss\", color=\"train_cat\", markers=False,\n",
    "             labels={\"ntxent_loss\":\"contrastive loss\"},\n",
    "             log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = px.line(loss_df, x=\"epoch\", y=\"recon_loss\", color=\"train_cat\", markers=False, #, log_y=True,\n",
    "             labels={\"recon_loss\":\"reconstruction loss (MSE)\"},\n",
    "             log_y=True)\n",
    "\n",
    "# fig.update_xaxes(range=[0, 250])\n",
    "fig.update_yaxes(range=[2, 3])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = px.line(loss_df, x=\"epoch\", y=\"reg_loss\", color=\"train_cat\", markers=False, #, log_y=True,\n",
    "             labels={\"reg_loss\":\"Gaussian prior loss (KLD)\"})\n",
    "\n",
    "# fig.update_xaxes(range=[0, 250])\n",
    "# fig.update_yaxes(range=[0, 650])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "gdf3_indices = np.where(morph_df[\"master_perturbation\"]==\"gdf3\")[0]\n",
    "\n",
    "fig = px.scatter(morph_df.iloc[gdf3_indices], x=\"UMAP_00\", y=\"UMAP_01\", color=\"predicted_stage_hpf\", \n",
    "                 opacity=0.5, template=\"plotly\")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=morph_df[\"UMAP_00_bio\"].iloc[wik_indices], y=morph_df[\"UMAP_01_bio\"].iloc[wik_indices],\n",
    "              mode=\"markers\", marker=dict(color=\"blue\", opacity=0.1))\n",
    "             )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
