{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### This notebook fits a reference spline to HF and AB reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "from glob2 import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/\"\n",
    "train_name = \"20241107_ds\"\n",
    "model_name = \"SeqVAE_z100_ne150_sweep_01_block01_iter030\" \n",
    "train_dir = os.path.join(root, \"training_data\", train_name, \"\")\n",
    "output_dir = os.path.join(train_dir, model_name) \n",
    "\n",
    "# get path to model\n",
    "training_path = sorted(glob(os.path.join(output_dir, \"*\")))[-1]\n",
    "training_name = os.path.dirname(training_path)\n",
    "read_path = os.path.join(training_path, \"figures\", \"\")\n",
    "\n",
    "# path to save data\n",
    "out_path = os.path.join(root, \"results\", \"20240310\", \"\")\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# path to figures and data\n",
    "fig_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/slides/morphseq/20250312/morph_metrics/\"\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_df = pd.read_csv(read_path + \"embryo_stats_df.csv\", index_col=0)\n",
    "# umap_df = pd.read_csv(read_path + \"umap_df.csv\", index_col=0)\n",
    "# print(umap_df.shape)\n",
    "# umap_df = umap_df.merge(morph_df.loc[:, [\"snip_id\", \"embryo_id\", \"experiment_time\"]], how=\"left\", on=[\"snip_id\"])\n",
    "# print(umap_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Make 3D UMAP and PCA for hotfish experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_experiments = np.asarray(['20240813_24hpf', '20240813_30hpf', '20240813_36hpf']) #, '20240813_extras'])\n",
    "hf_morph_df = morph_df.loc[np.isin(morph_df[\"experiment_date\"], HF_experiments), :].reset_index()\n",
    "# hf_umap_df = umap_df.loc[np.isin(umap_df[\"experiment_date\"], HF_experiments), :].reset_index()\n",
    "\n",
    "hf_outlier_snips = np.asarray([\"20240813_24hpf_F06_e00_t0000\", \"20240813_36hpf_D03_e00_t0000\", \"20240813_36hpf_C03_e00_t0000\"]) \n",
    "# hf_umap_df = hf_umap_df.loc[~np.isin(hf_umap_df[\"snip_id\"], hf_outlier_snips), :]\n",
    "hf_morph_df = hf_morph_df.loc[~np.isin(hf_morph_df[\"snip_id\"], hf_outlier_snips), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Problem: 28C is our control group, but we don't have stage-matching due to stage shifting\n",
    "**Potential solution:** search for reference embryos from timelapse data that closely overlap with 28C, but which also extend out into later timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_pert_name = \"wt_ab\" # genotype\n",
    "target_stage = 42 # alive through at least this point\n",
    "start_stage = 18\n",
    "\n",
    "embryo_df = morph_df.loc[:, [\"experiment_date\", \"embryo_id\", \"predicted_stage_hpf\", \"short_pert_name\"]].groupby(\n",
    "                        [\"experiment_date\", \"embryo_id\", \"short_pert_name\"])[\"predicted_stage_hpf\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "pert_filter = embryo_df[\"short_pert_name\"] == short_pert_name\n",
    "stage_filter = (embryo_df[\"min\"] <= start_stage) & (embryo_df[\"max\"] >= target_stage)\n",
    "\n",
    "ref_embryo_df = embryo_df.loc[stage_filter & pert_filter, :]\n",
    "# embryo_df.shape\n",
    "\n",
    "# ref_umap_df = umap_df.merge(ref_embryo_df.loc[:, [\"embryo_id\"]], how=\"inner\", on=\"embryo_id\")\n",
    "ref_morph_df = morph_df.merge(ref_embryo_df.loc[:, [\"embryo_id\"]], how=\"inner\", on=\"embryo_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Refit PCA to jus the ref and hotfish data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import re \n",
    "\n",
    "# params\n",
    "n_components = 5\n",
    "z_pattern = \"z_mu_b\"\n",
    "mu_cols = [col for col in ref_morph_df.columns if re.search(z_pattern, col)]\n",
    "pca_cols = [f\"PCA_{p:02}_bio\" for p in range(n_components)]\n",
    "\n",
    "# fit\n",
    "morph_pca = PCA(n_components=n_components)\n",
    "morph_pca.fit(pd.concat([ref_morph_df[mu_cols], hf_morph_df[mu_cols]]))\n",
    "\n",
    "# transform\n",
    "ref_pca_array = morph_pca.transform(ref_morph_df[mu_cols])\n",
    "hf_pca_array = morph_pca.transform(hf_morph_df[mu_cols])\n",
    "\n",
    "ref_pca_df = pd.DataFrame(ref_pca_array, columns=pca_cols)\n",
    "ref_pca_df[[\"snip_id\", \"embryo_id\", \"temperature\", \"timepoint\"]] = ref_morph_df[[\"snip_id\", \"embryo_id\", \"temperature\", \"predicted_stage_hpf\"]].to_numpy()\n",
    "ref_pca_df[\"timepoint\"] = np.floor(ref_pca_df[\"timepoint\"])\n",
    "\n",
    "hf_pca_df = pd.DataFrame(hf_pca_array, columns=pca_cols)\n",
    "hf_pca_df[[\"snip_id\", \"embryo_id\", \"temperature\", \"timepoint\"]] = hf_morph_df[[\"snip_id\", \"embryo_id\", \"temperature\", \"predicted_stage_hpf\"]].to_numpy()\n",
    "hf_pca_df[\"timepoint\"] = np.floor(hf_pca_df[\"timepoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumulative = np.cumsum(morph_pca.explained_variance_ratio_)\n",
    "fig = px.line(x=np.arange(n_components) + 1, y=var_cumulative, markers=True)\n",
    "\n",
    "fig.update_layout(xaxis=dict(title=\"PC number\"),\n",
    "                  yaxis=dict(title=\"total variance explained\"),\n",
    "                  title=\"PCA decomposition of morphVAE latent space\",\n",
    "                 font=dict(\n",
    "                    family=\"Arial, sans-serif\",\n",
    "                    size=18,  # Adjust this value to change the global font size\n",
    "                    color=\"black\"\n",
    "                ))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"morph_pca_var_explained.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Experiment with fitting 3D spline to re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pca_df = pd.concat([ref_pca_df, hf_pca_df.loc[hf_pca_df[\"temperature\"]==28.5, :]], ignore_index=True)\n",
    "# print(hf_pca_df.loc[hf_pca_df[\"temperature\"]==28.5, :].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "One problem I have noticed is that there is a systematic divergence between the reference trajectory and the 28.5C cohort at ~24hpf. This leads to weird results for other temp cohorts at this time point. I want, therefore, to adjust the reference trajectory to \"flow\" closer to my reference embryos. The simplest way I can think of to achive this is to add my 28C embryos to the spline fitting dataset, and assign them high weights to ensure that the model mus fit them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functions.spline_fitting_v2 import spline_fit_wrapper\n",
    "import time\n",
    "import re \n",
    "from tqdm import tqdm \n",
    "\n",
    "alpha = 0.25 # fraction of fitting obs that we want to be from hf. This is ad-hoc currently. \n",
    "emb_vec = fit_pca_df[\"embryo_id\"]\n",
    "hf_flags = np.asarray([1 if \"20240813\" in e else 0 for e in emb_vec])\n",
    "spline_weight_vec = np.ones(hf_flags.shape)\n",
    "spline_weight_vec[hf_flags==1] = alpha * len(hf_flags) / np.sum(hf_flags)\n",
    "spline_weight_vec[hf_flags==0] = (1-alpha) * len(hf_flags) / (len(hf_flags)-np.sum(hf_flags))\n",
    "\n",
    "# pattern = r\"PCA_.*_bio\"\n",
    "# pattern = r\"z_mu_b\"\n",
    "n_boots = 50\n",
    "n_spline_points = 2500\n",
    "boot_size = 1000\n",
    "\n",
    "# fit normal version\n",
    "spline_df_orig = spline_fit_wrapper(fit_pca_df, n_boots=n_boots, n_spline_points=n_spline_points, stage_col=\"timepoint\", \n",
    "                               obs_weights=None, boot_size=boot_size)\n",
    "# fit weighted version\n",
    "spline_df = spline_fit_wrapper(fit_pca_df, n_boots=n_boots, n_spline_points=n_spline_points, stage_col=\"timepoint\", \n",
    "                               obs_weights=spline_weight_vec, boot_size=boot_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dims = np.asarray([0, 1, 2])\n",
    "\n",
    "plot_strings = [pca_cols[p] for p in plot_dims]\n",
    "\n",
    "fig = px.scatter_3d(hf_pca_df, x=plot_strings[0], y=plot_strings[1], z=plot_strings[2], opacity=1,\n",
    "                    color=hf_pca_df[\"temperature\"].astype(float), color_continuous_scale=\"RdBu_r\", hover_data={\"timepoint\"})\n",
    "\n",
    "# fig.update_traces(marker=dict(size=5, showscale=False))\n",
    "\n",
    "fig.add_traces(go.Scatter3d(x=spline_df_orig.loc[:, plot_strings[0]], \n",
    "                            y=spline_df_orig.loc[:, plot_strings[1]], \n",
    "                            z=spline_df_orig.loc[:, plot_strings[2]],\n",
    "                           mode=\"lines\", line=dict(color=\"black\", width=3, dash=\"dash\"), name=\"reference curve\"))\n",
    "\n",
    "fig.add_traces(go.Scatter3d(x=spline_df.loc[:, plot_strings[0]], \n",
    "                            y=spline_df.loc[:, plot_strings[1]], \n",
    "                            z=spline_df.loc[:, plot_strings[2]],\n",
    "                           mode=\"lines\", line=dict(color=\"black\", width=4), name=\"reference curve\"))\n",
    "\n",
    "fig.update_traces(marker=dict(size=10, line=dict(color=\"black\", width=1)))\n",
    "\n",
    "fig.update_layout(width=1200, height=1000,\n",
    "                  scene=dict(xaxis=dict(title=\"morph PC 1\"),\n",
    "                             yaxis=dict(title=\"morph PC 2\"),\n",
    "                             zaxis=dict(title=\"morph PC 3\")),\n",
    "                  # title=\"PCA decomposition of morphVAE latent space\",\n",
    "                 font=dict(\n",
    "                    family=\"Arial, sans-serif\",\n",
    "                    size=16,  # Adjust this value to change the global font size\n",
    "                    color=\"black\"\n",
    "                ),\n",
    "                 coloraxis_colorbar=dict(\n",
    "                    x=1,  # Increase x to move the colorbar rightwards\n",
    "                    y=0.5,   # Center vertically (default is often around 0.5)\n",
    "                    len=0.5  # Adjust the length if needed\n",
    "                ))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"hotfish_pca_with_spline.png\"))\n",
    "fig.write_html(os.path.join(fig_path, \"hotfish_pca_with_spline.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Next, fit a polynomial surface to estimate embryo stages\n",
    "Let's experiment with fitting derivatives so we can utilize experimental clock time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Define a pipeline that first transforms the input and then fits a linear model.\n",
    "degree = 2  # or any degree you choose\n",
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=degree, include_bias=True)),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "\n",
    "frac_to_fit = 0.8\n",
    "X = ref_pca_df[pca_cols].values\n",
    "n_train = int(np.floor(frac_to_fit * X.shape[0]))\n",
    "X_indices = np.arange(X.shape[0])\n",
    "train_indices = np.random.choice(X_indices, n_train, replace=False)\n",
    "test_indices = X_indices[~np.isin(X_indices, train_indices)]\n",
    "\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "\n",
    "y = ref_pca_df[\"timepoint\"].values\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "# Assume X is your (n_samples x N) input array and y is your (n_samples,) target (time).\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pd = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Use surface fit to generate consistent stage predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for hotfish data\n",
    "X_hf = hf_pca_df[pca_cols].values\n",
    "hf_pca_df[\"mdl_stage_hpf\"] = model.predict(X_hf)\n",
    "\n",
    "# now for ref\n",
    "X_ref = ref_pca_df[pca_cols].values\n",
    "ref_pca_df[\"mdl_stage_hpf\"] = model.predict(X_ref)\n",
    "\n",
    "# now for spline\n",
    "X_spline = spline_df[pca_cols].values\n",
    "spline_df[\"mdl_stage_hpf\"] = model.predict(X_spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# interpolate spline data to align with transcriptional spline\n",
    "n_points = 250\n",
    "t_start = 12.9\n",
    "t_stop = 50\n",
    "t_vec = np.linspace(t_start, t_stop, n_points)\n",
    "\n",
    "# set index to be time\n",
    "t_vec_orig = spline_df[\"mdl_stage_hpf\"].to_numpy()\n",
    "\n",
    "# get new PCA values\n",
    "interp = interp1d(t_vec_orig, spline_df[pca_cols].values, axis=0)\n",
    "pca_array_interp = interp(t_vec)\n",
    "\n",
    "# Reindex the dataframe to include the new time points.\n",
    "spline_df_new = pd.DataFrame(pca_array_interp, columns=pca_cols)\n",
    "spline_df_new[\"stage_hpf\"] = t_vec\n",
    "\n",
    "spline_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.scatter(x=t_vec, y=spline_df_new[\"PCA_00_bio\"])\n",
    "# fig.add_traces(go.Scatter(x=t_vec_orig, y=spline_df[\"PCA_00_bio\"]))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_pca_df.to_csv(os.path.join(out_path, \"hf_morph_df.csv\"), index=False)\n",
    "ref_pca_df.to_csv(os.path.join(out_path, \"ab_ref_morph_df.csv\"), index=False)\n",
    "spline_df_new.to_csv(os.path.join(out_path, \"spline_morph_df.csv\"), index=False)\n",
    "spline_df.to_csv(os.path.join(out_path, \"spline_morph_df_full.csv\"), index=False)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, os.path.join(out_path, 'morph_stage_model.joblib'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
