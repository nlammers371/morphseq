{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### This notebook looks at temperature-dependent changes to embryo morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "from glob2 import glob\n",
    "from src.functions.plot_functions import format_3d_plotly, rotate_figure, format_2d_plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embryo_df for our current best model\n",
    "# root = \"/media/nick/hdd02/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/\"\n",
    "\n",
    "root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/\"\n",
    "\n",
    "# path to save data\n",
    "morph_read_path = os.path.join(root, \"results\", \"20250312\", \"morph_latent_space\", \"\")\n",
    "seq_data_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/analyses/crossmodal/hotfish/\"\n",
    "\n",
    "# path to figures and data\n",
    "fig_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/slides/morphseq/20250513/morph_metrics/\"\n",
    "fig_data_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/slides/morphseq/20250513/data/morph_metrics/\"\n",
    "os.makedirs(fig_path, exist_ok=True)\n",
    "os.makedirs(fig_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooke_spline_df = pd.read_csv(os.path.join(seq_data_path, \"hooke_time_trends.csv\"))\n",
    "hooke_ct_df = pd.read_csv(os.path.join(seq_data_path, \"unique_ct_full_germ_layer_nl.csv\"), index_col=0)\n",
    "n_cell_df = pd.read_csv(os.path.join(seq_data_path, \"n_cell_table.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### Build data frame for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt counts to be longform\n",
    "hooke_counts_long = hooke_spline_df.melt(\n",
    "    id_vars=[\"stage_hpf\"],           # keep this column as‑is\n",
    "    var_name=\"cell_type_broad\",      # new name for your old columns\n",
    "    value_name=\"log_count\"           # new name for their values\n",
    ")\n",
    "# hooke_ste_long = hooke_spline_df.melt(\n",
    "#     id_vars=[\"stage_hpf\"],           # keep this column as‑is\n",
    "#     var_name=\"cell_type_broad\",      # new name for your old columns\n",
    "#     value_name=\"log_count\"           # new name for their values\n",
    "# )\n",
    "# create cleaned join key\n",
    "hooke_counts_long['join_key'] = (\n",
    "    hooke_counts_long['cell_type_broad']\n",
    "      .str.replace(r'[-+\\?\\/\\s(),]', '', regex=True)\n",
    "      .str.lower()\n",
    ")\n",
    "\n",
    "# do same for cell type/tissue labels\n",
    "hooke_ct_df['join_key'] = (\n",
    "    hooke_ct_df['cell_type_broad']\n",
    "      .str.replace(r'[-+\\?\\/\\s(),]', '', regex=True)\n",
    "      .str.lower()\n",
    ")\n",
    "\n",
    "hooke_ct_clean = hooke_ct_df.drop_duplicates(subset=[\"join_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooke_counts_lb = hooke_counts_long.drop(labels=[\"cell_type_broad\"], axis=1).merge(hooke_ct_clean, how=\"left\", on=\"join_key\")\n",
    "\n",
    "hooke_counts_lb[\"gl_tissue\"] = (\n",
    "    hooke_counts_lb[\"germ layer\"].astype(str)\n",
    "    + \":\"\n",
    "    + hooke_counts_lb[\"tissue\"].astype(str)\n",
    ")\n",
    "\n",
    "hooke_counts_lb[\"counts\"] = np.exp(hooke_counts_lb[\"log_count\"])\n",
    "hooke_counts_lb = hooke_counts_lb.loc[hooke_counts_lb[\"tissue\"] != \"periderm\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_min = -.1\n",
    "hooke_counts_tissue = hooke_counts_lb.loc[:, [\"stage_hpf\", \"gl_tissue\", \"tissue\", \"germ layer\", \"counts\"]].groupby(\n",
    "                                [\"stage_hpf\", \"gl_tissue\", \"tissue\", \"germ layer\"]).sum().reset_index()\n",
    "\n",
    "hooke_counts_tissue[\"log_counts\"] = np.log(hooke_counts_tissue[\"counts\"])\n",
    "\n",
    "hooke_counts_tissue[\"log_counts_norm\"] = hooke_counts_tissue[\"log_counts\"].copy() \n",
    "hooke_counts_tissue.loc[hooke_counts_tissue[\"log_counts_norm\"] < plot_min, \"log_counts_norm\"] = plot_min\n",
    "hooke_counts_tissue[\"log_counts_norm\"] = hooke_counts_tissue[\"log_counts_norm\"] - plot_min\n",
    "hooke_counts_tissue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheath_filter = [col for col in hooke_spline_df.columns if \"sheath\" in col]\n",
    "sheath_mask = hooke_counts_lb[\"cell_type_broad\"].str.contains(\"sheath\", na=False)\n",
    "hf_subset = hooke_counts_lb.loc[sheath_mask, :]\n",
    "hf_subset[\"count\"] = np.exp(hf_subset[\"log_count\"])\n",
    "\n",
    "fig = px.line(hf_subset, x=\"stage_hpf\", y=\"count\", color=\"cell_type_broad\", range_x=[10, 48] , log_y=True)\n",
    "\n",
    "fig = format_2d_plotly(fig, axis_labels=[\"Hours post-fertilization\", \"Estimated cells per embryo\"], theme=\"light\", \n",
    "                       show_gridlines=False, font_size=22)\n",
    "\n",
    "fig.update_traces(line=dict(width=5))\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"cell type\"\n",
    ")\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"sheath abundance.png\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Now we need to generate a pseudograph to use for the sankey plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(hooke_counts_tissue, x=\"stage_hpf\", y=\"log_counts_norm\", color=\"germ layer\", line_group=\"gl_tissue\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Use JAX to calculate developmental flux magnitude and direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(hooke_counts_tissue[\"log_counts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_grad, params = make_jax_functions(morph_stage_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "from tqdm import tqdm\n",
    "sd_pca_cols = [col +\"_std\" for col in pca_cols]\n",
    "mean_cols = [col + \"_mean\" for col in pca_cols]\n",
    "\n",
    "for row in tqdm(range(hf_cohort_df.shape[0])):\n",
    "    \n",
    "    # mean and variance of each morph coordinate\n",
    "    pca_mu = hf_cohort_df.loc[row, mean_cols].to_numpy() # morph mean\n",
    "    pca_var = np.diag(hf_cohort_df.loc[row, sd_pca_cols].to_numpy()**2) # morph std\n",
    "\n",
    "    # pull point positions (needed for gradient calc)\n",
    "    timepoint = hf_cohort_df.loc[row, \"timepoint\"]\n",
    "    temperature = hf_cohort_df.loc[row, \"temperature\"]\n",
    "    obs_filter = (hf_pca_df[\"timepoint\"]==timepoint) & (hf_pca_df[\"temperature\"]==temperature)\n",
    "    pca_obs = hf_pca_df.loc[obs_filter, pca_cols].values\n",
    "    \n",
    "    # spline knot index\n",
    "    knot_i = hf_cohort_df.loc[row, \"knot_index\"]\n",
    "    pca_ref = spline_df.loc[spline_df[\"knot_index\"]==knot_i, pca_cols].to_numpy() # stage-matched comparison\n",
    "\n",
    "    # get phenotypic distance\n",
    "    hf_cohort_df.loc[row, \"morph_shift\"] = np.sqrt(np.sum((pca_mu - pca_ref)**2))\n",
    "\n",
    "    # record total variance\n",
    "    hf_cohort_df.loc[row, \"total_variance\"] = np.sum(pca_var)\n",
    "    hf_cohort_df.loc[row, \"total_sigma\"] = np.sqrt(np.sum(pca_var))\n",
    "\n",
    "    # use gradient to decompose variance\n",
    "    t_var_vec = []\n",
    "    for o in range(pca_obs.shape[0]):\n",
    "        stage_pd, grad_pd = predict_and_grad(params, pca_obs[o,:][None, :])\n",
    "        grad_u = np.asarray(grad_pd / np.sqrt(np.sum(grad_pd**2)))[0]\n",
    "        t_var_vec.append(grad_u @ pca_var @ grad_u.T)\n",
    "    # var_null = 0\n",
    "    # for n in range(100):\n",
    "    #     rand_u = np.random.permutation(grad_u.copy())\n",
    "    #     var_null += np.dot(rand_u, pca_obs_var)\n",
    "\n",
    "    hf_cohort_df.loc[row, \"stage_variance\"] = np.mean(t_var_vec)\n",
    "    hf_cohort_df.loc[row, \"stage_sigma\"] = np.sqrt(hf_cohort_df.loc[row, \"stage_variance\"])\n",
    "    # hf_cohort_df.loc[row, \"stage_cv\"] = np.divide(hf_cohort_df.loc[row, \"stage_mdl_hpf_mean\"]\n",
    "    \n",
    "    # hf_cohort_df.loc[row, \"stage_variance_null\"] = var_null/100\n",
    "    \n",
    "    hf_cohort_df.loc[row, \"morph_variance\"] = hf_cohort_df.loc[row, \"total_variance\"] - hf_cohort_df.loc[row, \"stage_variance\"]\n",
    "    hf_cohort_df.loc[row, \"morph_sigma\"] = np.sqrt(hf_cohort_df.loc[row, \"morph_variance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.scatter(hf_cohort_df, x=\"temperature\", y=\"morph_shift\", color=\"temperature\")\n",
    "# fig.update_traces(marker=dict(size=8))\n",
    "# fig.show()\n",
    "range_color=[18, 38]\n",
    "var_list = [\"morph_shift\", \"stage_shift_hpf\", \"morph_sigma\", \"mdl_stage_hpf_std\"]\n",
    "err_list = [\"total_sigma\", \"mdl_stage_hpf_std\", \"\", \"\"]\n",
    "ylb_list = [r'morphological shift (δₘ)', 'stage shift (δₜ)', \n",
    "                    'morphological noise (εₘ)', 'stage noise (εₜ)']\n",
    "\n",
    "for i in range(len(var_list)):\n",
    "    var = var_list[i]\n",
    "    err = err_list[i]\n",
    "    ylb = ylb_list[i]\n",
    "\n",
    "    if False:  #len(err) > 0:\n",
    "        fig = px.scatter(hf_cohort_df, x=\"temperature\", y=var, error_y=err,\n",
    "                         color=\"temperature\", symbol=\"timepoint\",color_continuous_scale=colormap, range_color=range_color)\n",
    "        \n",
    "    else:\n",
    "        fig = px.scatter(hf_cohort_df, x=\"temperature\", y=var, \n",
    "                         color=\"temperature\", symbol=\"timepoint\",color_continuous_scale=colormap, range_color=range_color)\n",
    "    \n",
    "    # fig.add_trace(go.Scatter(x=ref_vec, y=ref_vec, mode=\"lines\", line=dict(color=\"white\", width=2.5, dash=\"dash\"), showlegend=False))\n",
    "    \n",
    "    axis_labels = [\"temperature (C)\", ylb]\n",
    "    \n",
    "    fig = format_2d_plotly(fig, marker_size=marker_size, axis_labels=axis_labels, font_size=20)#, show_gridlines=False)\n",
    "\n",
    "    # fig.update_yaxes(title_text=ylb)\n",
    "    # fig.update_traces(error_y=dict(width=3))\n",
    "    \n",
    "    \n",
    "    fig.write_image(fig_path + f\"morph_model_{var}.png\", scale=2)\n",
    "    fig.write_html(fig_path + f\"morph_model_{var}.html\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hf_cohort_df, x=\"mdl_stage_hpf_std\", y=\"morph_sigma\", \n",
    "                         color=\"temperature\", symbol=\"timepoint\",\n",
    "                         color_continuous_scale=colormap, range_color=range_color)\n",
    "    \n",
    "# fig.add_trace(go.Scatter(x=ref_vec, y=ref_vec, mode=\"lines\", line=dict(color=\"white\", width=2.5, dash=\"dash\"), showlegend=False))\n",
    "\n",
    "axis_labels = ['stage noise (εₜ)', 'morphology noise (εₘ)']\n",
    "\n",
    "fig = format_2d_plotly(fig, marker_size=20, axis_labels=axis_labels, font_size=20)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Make 3D plot of averages with error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add error bars using the respective error arrays\n",
    "def add_error_bars(fig, x, y, z, err_x, err_y, err_z):\n",
    "    for xi, yi, zi, ex, ey, ez in zip(x, y, z, err_x, err_y, err_z):\n",
    "        # X error bar: x from xi - ex to xi + ex, constant y and z.\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[xi - ex, xi + ex],\n",
    "            y=[yi, yi],\n",
    "            z=[zi, zi],\n",
    "            mode='lines',\n",
    "            line=dict(color='gray', width=2),\n",
    "            showlegend=False\n",
    "        ))\n",
    "        # Y error bar: y from yi - ey to yi + ey, constant x and z.\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[xi, xi],\n",
    "            y=[yi - ey, yi + ey],\n",
    "            z=[zi, zi],\n",
    "            mode='lines',\n",
    "            line=dict(color='gray', width=2),\n",
    "            showlegend=False\n",
    "        ))\n",
    "        # Z error bar: z from zi - ez to zi + ez, constant x and y.\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[xi, xi],\n",
    "            y=[yi, yi],\n",
    "            z=[zi - ez, zi + ez],\n",
    "            mode='lines',\n",
    "            line=dict(color='gray', width=2),\n",
    "            showlegend=False\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Plot polynomial surface\n",
    "Let's experiment with fitting derivatives so we can utilize experimental clock time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "np.random.seed(42)\n",
    "umap_model = umap.UMAP(n_components=2)\n",
    "\n",
    "# Compute the embedding\n",
    "umap_model.fit(ref_pca_df[pca_cols].values)\n",
    "embedding = umap_model.transform(ref_pca_df[pca_cols].values)\n",
    "hf_embedding = umap_model.transform(hf_pca_df[pca_cols].values)\n",
    "\n",
    "full_embedding = np.vstack((embedding, hf_embedding))\n",
    "full_pca = np.vstack((ref_pca_df[pca_cols].values, hf_pca_df[pca_cols].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.interpolate import griddata\n",
    "# from scipy.spatial import distance_matrix\n",
    "\n",
    "# # Create a grid over the domain of your data.\n",
    "# x=ref_pca_df[pca_cols].to_numpy()[:, 0]\n",
    "# y=ref_pca_df[pca_cols].to_numpy()[:, 1] #full_embedding[:, 1]\n",
    "# z=morph_stage_model.predict(full_pca) \n",
    "\n",
    "# # fig = px.scatter_3d(x=x, y=y, z=z, color=z)\n",
    "# # fig.show()\n",
    "# grid_x = np.linspace(0.9*x.min(), 1.1*x.max(), 100)\n",
    "# grid_y = np.linspace(0.9*y.min(), 1.1*y.max(), 100)\n",
    "# grid_x, grid_y = np.meshgrid(grid_x, grid_y)\n",
    "\n",
    "# xy_long = np.c_[grid_x.ravel()[:, None], grid_y.ravel()[:, None]]\n",
    "# dist_vec = np.min(distance_matrix(xy_long, ref_pca_df[pca_cols].to_numpy()[:, :2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "# Create a grid over the domain of your data.\n",
    "x=full_embedding[:, 0]\n",
    "y=full_embedding[:, 1]\n",
    "z=morph_stage_model.predict(full_pca) \n",
    "\n",
    "# fig = px.scatter_3d(x=x, y=y, z=z, color=z)\n",
    "# fig.show()\n",
    "grid_x = np.linspace(0.9*x.min(), 1.1*x.max(), 100)\n",
    "grid_y = np.linspace(0.9*y.min(), 1.1*y.max(), 100)\n",
    "grid_x, grid_y = np.meshgrid(grid_x, grid_y)\n",
    "\n",
    "xy_long = np.c_[grid_x.ravel()[:, None], grid_y.ravel()[:, None]]\n",
    "dist_vec = np.min(distance_matrix(xy_long, full_embedding), axis=1)\n",
    "# Interpolate the scattered data onto the grid.\n",
    "# grid_z = griddata(points=(x, y), values=z, xi=(grid_x, grid_y), method='cubic')\n",
    "\n",
    "# grid_x.shape\n",
    "# Create the surface plot.\n",
    "# fig = go.Figure(data=[go.Surface(z=grid_z, x=grid_x, y=grid_y)])\n",
    "# fig.update_layout(title=\"3D Surface from Scattered Data\", scene=dict(\n",
    "#                     xaxis_title='X', yaxis_title='Y', zaxis_title='Z'))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "# px.histogram(dist_vec)\n",
    "dist_thresh = 1.5\n",
    "dist_mat = dist_vec.reshape(100, 100)\n",
    "grid_z = griddata(points=(x, y), values=z, xi=(grid_x, grid_y), method='nearest')\n",
    "grid_z_smoothed = gaussian_filter(grid_z, sigma=2, mode=\"nearest\")\n",
    "grid_z_smoothed[dist_mat>dist_thresh] = np.nan\n",
    "\n",
    "hf_pca_df[\"mdl_stage_plot\"] = hf_pca_df[\"mdl_stage_hpf\"].copy() \n",
    "# Create the surface plot.\n",
    "\n",
    "\n",
    "\n",
    "# fig.write_image(os.path.join(fig_path, \"ab_developmental_surface.png\"))\n",
    "# fig.write_html(os.path.join(fig_path, \"ab_developmental_surface.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom_factor = 0.95\n",
    "z_rotation = 275\n",
    "elevation = 10\n",
    "\n",
    "xrange = [-4, 15]\n",
    "yrange = [-5, 15.5]\n",
    "zrange = [60, 10]\n",
    "\n",
    "fig = px.scatter_3d(x=hf_embedding[:, 0], y=hf_embedding[:, 1], z=hf_pca_df[\"mdl_stage_plot\"], color=hf_pca_df[\"temperature\"],\n",
    "                   symbol=hf_pca_df[\"timepoint\"], color_continuous_scale=\"RdBu_r\", range_color=range_color)\n",
    "\n",
    "fig = format_3d_plotly(fig, axis_labels=[\"morph 1\", \"morph 2\", \"stage (hpf)\"], aspectmode=\"cube\", show_gridlines=True)\n",
    "\n",
    "fig.add_trace(go.Surface(z=grid_z_smoothed, x=grid_x, y=grid_y, opacity=0.5, \n",
    "                         colorscale=\"Purples\", showlegend=False, showscale=False))\n",
    "\n",
    "\n",
    "fig.layout.scene.xaxis.range = xrange\n",
    "fig.layout.scene.yaxis.range = yrange\n",
    "fig.layout.scene.zaxis.range = zrange\n",
    "\n",
    "fig = rotate_figure(fig, zoom_factor=zoom_factor, z_rotation=z_rotation, elev_rotation=elevation)\n",
    "\n",
    "# fig.update_layout(\n",
    "#     scene=dict(\n",
    "#         zaxis=dict(\n",
    "#             autorange='reversed'\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(fig_path + f\"morph_surface_dope.png\", scale=2)\n",
    "fig.write_html(fig_path + f\"morph_surface_dope.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lim_vec = np.linspace(12, 48, 50)\n",
    "surf_frame_path = os.path.join(fig_path, \"hf_morph_surf_frames\", \"\")\n",
    "os.makedirs(surf_frame_path, exist_ok=True)\n",
    "\n",
    "for t, t_lim in enumerate(tqdm(t_lim_vec)):\n",
    "\n",
    "    t_filter = hf_pca_df[\"mdl_stage_hpf\"] <= t_lim \n",
    "    if np.sum(t_filter) == 0:\n",
    "        opacity = 0\n",
    "        t_filter = hf_pca_df[\"mdl_stage_hpf\"] <= np.inf\n",
    "    else:\n",
    "        opacity = 1\n",
    "        # t_filter = hf_pca_df[\"mdl_stage_hpf\"] <= t_lim \n",
    "    \n",
    "    fig = px.scatter_3d(x=hf_embedding[t_filter, 0], y=hf_embedding[t_filter, 1], \n",
    "                        z=hf_pca_df.loc[t_filter, \"mdl_stage_plot\"], color=hf_pca_df.loc[t_filter, \"temperature\"], opacity=opacity,\n",
    "                       symbol=hf_pca_df.loc[t_filter, \"timepoint\"], color_continuous_scale=\"RdBu_r\", range_color=range_color)\n",
    "    \n",
    "    fig = format_3d_plotly(fig, axis_labels=[\"morph 1\", \"morph 2\", \"stage (hpf)\"], aspectmode=\"cube\", show_gridlines=True)\n",
    "\n",
    "    fig.layout.scene.xaxis.range = xrange\n",
    "    fig.layout.scene.yaxis.range = yrange\n",
    "    fig.layout.scene.zaxis.range = zrange\n",
    "\n",
    "    fig.add_trace(go.Surface(z=grid_z_smoothed, x=grid_x, y=grid_y, opacity=0.5, \n",
    "                             colorscale=\"Purples\", showlegend=False, showscale=False))\n",
    "    \n",
    "    \n",
    "    fig = rotate_figure(fig, zoom_factor=zoom_factor, z_rotation=z_rotation, elev_rotation=elevation)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         scene=dict(\n",
    "#             zaxis=dict(\n",
    "#                 autorange='reversed'\n",
    "#             )\n",
    "#         )\n",
    "# )\n",
    "    # rotate\n",
    "    \n",
    "    fig = rotate_figure(fig, zoom_factor=zoom_factor, z_rotation=z_rotation, elev_rotation=elevation)\n",
    "    \n",
    "    fig.write_image(os.path.join(surf_frame_path, f\"hotfish_pca_ab_angle{t:02}.png\"), scale=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Calculate mean and standard deviation in embryo morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(hf_pca_df[\"mdl_stage_hpf\"]>48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = [col for col in hf_pca_df.columns if \"PCA\" in col]\n",
    "\n",
    "hf_cohort_df = hf_pca_df.loc[:, [\"timepoint\", \"temperature\", \"mdl_stage_hpf\"] + pca_cols].groupby(\n",
    "                    [\"timepoint\", \"temperature\"]).agg([\"mean\", \"std\"]).reset_index()\n",
    "hf_cohort_df.columns.values\n",
    "hf_cohort_df.columns = ['_'.join(map(str, col)).strip() for col in hf_cohort_df.columns.values]\n",
    "hf_cohort_df.head()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dims = np.asarray([0, 1, 2])\n",
    "mean_pca_cols = [col +\"_mean\" for col in pca_cols]\n",
    "plot_strings = [mean_pca_cols[p] for p in plot_dims]\n",
    "\n",
    "fig = px.scatter_3d(hf_cohort_df, x=plot_strings[0], y=plot_strings[1], z=plot_strings[2], opacity=1,\n",
    "                    color=\"temperature_\", hover_data={\"timepoint_\"})\n",
    "\n",
    "fig.update_traces(marker=dict(size=5, showscale=False))\n",
    "\n",
    "fig.add_traces(go.Scatter3d(x=spline_df[plot_strings[0][:-5]], y=spline_df[plot_strings[1][:-5]], z=spline_df[plot_strings[2][:-5]],\n",
    "                           mode=\"lines\", line=dict(color=\"black\", width=4), name=\"reference curve\"))\n",
    "\n",
    "# fig.add_traces(go.Scatter3d(x=[P2[0]], y=[P2[1]], z=[P2[2]], mode=\"markers\"))\n",
    "\n",
    "# fig.add_traces(se_mesh)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"avg_hotfish_pca_with_spline.png\"))\n",
    "fig.write_html(os.path.join(fig_path, \"avg_hotfish_pca_with_spline.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Use JAX to generate predicted developmental gradients at each point in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Calculate stage and morphological deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stage shift\n",
    "hf_cohort_df[\"stage_hpf_mean\"] = model.predict(hf_cohort_df[mean_pca_cols].values)\n",
    "hf_cohort_df[\"stage_shift_hpf\"] = hf_cohort_df[\"stage_hpf_mean\"] - hf_cohort_df[\"timepoint_\"]\n",
    "\n",
    "predict_and_grad, params = make_jax_functions(morph_stage_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.permutation(grad_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hf_cohort_df, x=\"timepoint_\", y=\"morph_shift\", color=\"temperature_\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hf_cohort_df, x=\"timepoint_\", y=\"stage_shift_hpf\", color=\"temperature_\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hf_cohort_df, x=\"timepoint_\", y=\"morph_variance\", color=\"temperature_\")\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hf_cohort_df, x=\"timepoint_\", y=\"stage_variance\", color=\"temperature_\")\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hf_cohort_df, x=\"timepoint_\", y=\"total_variance\", color=\"temperature_\")\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hf_cohort_df, x=\"morph_variance\", y=\"stage_variance\", color=\"temperature_\", symbol=\"timepoint_\")\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(\n",
    "            height=800,\n",
    "            width=800,\n",
    "            xaxis=dict(range=[0, 1.7]), \n",
    "            yaxis=dict(range=[0, 1.7])\n",
    "        )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hf_cohort_df, x=\"stage_variance_null\", y=\"stage_variance\", color=\"temperature_\", symbol=\"timepoint_\")\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(\n",
    "            height=800,\n",
    "            width=800,\n",
    "            xaxis=dict(range=[0, 0.5]), \n",
    "            yaxis=dict(range=[0, 0.5])\n",
    "        )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(hf_cohort_df, x=\"mdl_stage_hpf_std\", y=\"stage_variance\", color=\"temperature_\", symbol=\"timepoint_\")\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(\n",
    "            height=800,\n",
    "            width=800,\n",
    "            # xaxis=dict(range=[0, 0.5]), \n",
    "            # yaxis=dict(range=[0, 0.5])\n",
    "        )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Make figure showing images for sanity check purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "image_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/training_data/20241107_ds/images/0/\"\n",
    "hf_snip_vec = hf_umap_df[\"snip_id\"].to_numpy()\n",
    "hf_time_vec = hf_umap_df[\"timepoint\"].to_numpy()\n",
    "hf_temp_vec = hf_umap_df[\"temperature\"].to_numpy()\n",
    "image_list = []\n",
    "for snip_id in hf_snip_vec:\n",
    "    im = io.imread(os.path.join(image_path, snip_id + \".jpg\"))\n",
    "    image_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "image_path = os.path.join(fig_path, \"cohort_images\", \"\")\n",
    "os.makedirs(image_path, exist_ok=True)\n",
    "im_shape = image_list[0].shape \n",
    "\n",
    "for time in np.unique(hf_time_vec):\n",
    "    for temp in np.unique(hf_temp_vec):\n",
    "        obs_indices = np.where((hf_time_vec==time) & (hf_temp_vec==temp))[0]\n",
    "        \n",
    "        # fig = go.Figure() # make_subplots(rows=2, cols=4)\n",
    "        \n",
    "        # Add each image to a subplot\n",
    "        top_list = []\n",
    "        bottom_list = []\n",
    "        for i in range(8):\n",
    "            if len(obs_indices) > i:\n",
    "                im = image_list[obs_indices[i]]\n",
    "            else:\n",
    "                im = np.zeros(im_shape, dtype=np.uint8)\n",
    "                \n",
    "            if i < 4:\n",
    "                top_list.append(im)\n",
    "            else:\n",
    "                bottom_list.append(im)\n",
    "\n",
    "        tiled_image = np.block([top_list,\n",
    "                                bottom_list])\n",
    "        \n",
    "        fig = px.imshow(tiled_image, color_continuous_scale=\"gray\", title=f\"{temp:02}C @{time:02}hpf\")\n",
    "\n",
    "        \n",
    "        # Update layout for better display\n",
    "        # fig.update_layout(\n",
    "        #     height=600,\n",
    "        #     width=1200,\n",
    "        #     title_text=\"Multiple Images in Plotly\"\n",
    "        # )\n",
    "        \n",
    "        fig.write_image(image_path + f\"embryo_images_tp{time:02}_temp{temp:02}.png\", engine=\"kaleido\")\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Is it possible to fit to the derivatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get point-over-point differences\n",
    "cols_to_diff = pca_cols + [\"experiment_time\"]\n",
    "diff_cols = [col + \"_diff\" for col in cols_to_diff]\n",
    "dt_cols = [col + \"_dt\" for col in cols_to_diff]\n",
    "ref_umap_df_dt = ref_umap_df.copy()\n",
    "ref_umap_df_dt[diff_cols] = ref_umap_df_dt.groupby('embryo_id')[cols_to_diff].diff()\n",
    "ref_umap_df_dt = ref_umap_df_dt.fillna(method='bfill') \n",
    "\n",
    "# we want to calculate the rate of time changes wrpt \n",
    "ref_umap_df_dt[dt_cols[:-1]] = np.divide(ref_umap_df_dt[diff_cols[-1]].values[:, None], ref_umap_df_dt[diff_cols[:-1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have K measurement points in an N-dimensional space.\n",
    "# D_data: (K, N) array of points.\n",
    "# G_data: (K, N) array of measured gradients at those points.\n",
    "# d: polynomial degree\n",
    "\n",
    "def multiindex_list(N, d):\n",
    "    # Generate list of multi-indices (tuples) for N dimensions up to degree d.\n",
    "    # This is a helper function; many implementations exist.\n",
    "    indices = []\n",
    "    def rec(current, start, remaining):\n",
    "        if remaining == 0:\n",
    "            indices.append(tuple(current))\n",
    "        else:\n",
    "            for i in range(start, N):\n",
    "                new_current = current.copy()\n",
    "                new_current[i] += 1\n",
    "                rec(new_current, i, remaining-1)\n",
    "    # Include all degrees from 0 up to d\n",
    "    for degree in range(d+1):\n",
    "        # Initialize multi-index with zeros\n",
    "        base = [0]*N\n",
    "        # Recursively fill in\n",
    "        rec(base, 0, degree)\n",
    "    return indices\n",
    "\n",
    "def build_A(D_data):\n",
    "    for k in range(len(D_data)):\n",
    "        Dk = D_data[k]  # shape (N,)\n",
    "        for j in range(len(Dk)):\n",
    "            row = []\n",
    "            for alpha in multiindices:\n",
    "                # For the derivative with respect to D_j,\n",
    "                # the coefficient is: alpha[j] * Dk^(alpha - e_j)\n",
    "                # If alpha[j] == 0, this term is zero.\n",
    "                if alpha[j] == 0:\n",
    "                    row.append(0.0)\n",
    "                else:\n",
    "                    # Compute Dk^(alpha - e_j)\n",
    "                    term = 1.0\n",
    "                    for i in range(N):\n",
    "                        exponent = alpha[i] - (1 if i == j else 0)\n",
    "                        term *= Dk[i]**exponent if exponent > 0 else 1.0\n",
    "                    row.append(alpha[j] * term)\n",
    "            A.append(row)\n",
    "            \n",
    "    return np.array(A)\n",
    "\n",
    "def build_b(G_data):\n",
    "    for k in range(G_data.shape[0]):\n",
    "        for j in range(G_data.shape[1]):\n",
    "            b.append(G_data[k, j])\n",
    "            \n",
    "    return np.array(b)\n",
    "\n",
    "def evaluate_polynomial_array(D, multiindices, c):\n",
    "    \"\"\"\n",
    "    Evaluate the polynomial at multiple points.\n",
    "    \n",
    "    Parameters:\n",
    "    - D: numpy array of shape (M, N) where each row is an N-dimensional input.\n",
    "    - multiindices: list of tuples, each tuple being the exponents for one term.\n",
    "    - c: numpy array of coefficients corresponding to each multi-index.\n",
    "    \n",
    "    Returns:\n",
    "    - predictions: numpy array of shape (M,) with the computed polynomial values.\n",
    "    \"\"\"\n",
    "    D = np.asarray(D)  # Ensure D is a numpy array\n",
    "    M, N = D.shape\n",
    "    predictions = np.zeros(M)\n",
    "    \n",
    "    for coeff, alpha in zip(c, multiindices):\n",
    "        # Compute the term D^alpha for each point.\n",
    "        # Convert alpha to an array to enable broadcasting.\n",
    "        alpha_array = np.array(alpha)\n",
    "        # For each point, compute the product of each dimension raised to the corresponding power.\n",
    "        term = coeff * np.prod(D ** alpha_array, axis=1)\n",
    "        predictions += term\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(pca_cols)\n",
    "d = 2  # for example, quadratic polynomial\n",
    "\n",
    "# Get multi-index list for polynomial basis.\n",
    "multiindices = multiindex_list(N, d)\n",
    "num_terms = len(multiindices)\n",
    "\n",
    "# Build design matrix A and measurement vector b.\n",
    "# There will be K * N equations (each derivative component).\n",
    "A = []\n",
    "b = []\n",
    "D_data = ref_umap_df_dt[pca_cols].to_numpy()\n",
    "G_data = ref_umap_df_dt[dt_cols[:-1]].to_numpy()  \n",
    "\n",
    "A = build_A(D_data)\n",
    "b = build_b(G_data)\n",
    "\n",
    "# Solve the least squares problem\n",
    "c, residuals, rank, s = np.linalg.lstsq(A, b, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = evaluate_polynomial_array(D_data, multiindices, c) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = px.scatter(x=ref_umap_df[\"predicted_stage_hpf\"], y=prediction)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
