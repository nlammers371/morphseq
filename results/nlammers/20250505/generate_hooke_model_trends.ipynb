{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Notebook to experiment with porting Hooke model and latent spaces over to python\n",
    "Eventual hope is to write code that can infer latent position and pseudostage for hotfish and other perturbed embryos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import glob2 as glob\n",
    "import patsy\n",
    "\n",
    "# set paths\n",
    "fig_root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/figures/seq_data/PLN/\"\n",
    "\n",
    "\n",
    "# specify which regression to use\n",
    "ccm = \"t_spline_inter2\" #\"t_spline_inter\"\n",
    "\n",
    "fig_folder = os.path.join(fig_root, ccm, \"\")\n",
    "os.makedirs(fig_folder, exist_ok=True)\n",
    "\n",
    "# set path to data\n",
    "hooke_data_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/seq_data/emb_projections/hooke_model_files/\"\n",
    "ccs_data_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/seq_data/emb_projections/ccs_data_cell_type_broad/\"\n",
    "# hooke_data_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/seq_data/emb_projections/hooke_model_test/\"\n",
    "# ccs_data_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/seq_data/emb_projections/ccs_data_test/\"\n",
    "model_path = os.path.join(hooke_data_path, ccm, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Load in metadata, model params, and counts matrice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full counts dataset\n",
    "hooke_counts_long = pd.read_csv(model_path + \"abundance_estimates.csv\", index_col=0)\n",
    "cols = list(hooke_counts_long.columns)\n",
    "cell_ind = cols.index(\"cell_group\")\n",
    "cov_cols = cols[:cell_ind]\n",
    "hooke_counts_df = hooke_counts_long.pivot(index=cov_cols,\n",
    "                                           columns=[\"cell_group\"], values = [\"log_abund\"])\n",
    "hooke_counts_df.columns = ['_'.join(map(str, col)).strip('_') for col in hooke_counts_df.columns.values]\n",
    "hooke_counts_df.reset_index(inplace=True)\n",
    "new_cols = [col.replace(\"log_abund_\", \"\") for col in hooke_counts_df.columns.values]\n",
    "hooke_counts_df.columns = new_cols\n",
    "sort_cols = new_cols[:cell_ind] + sorted(new_cols[cell_ind:], key=str.lower)\n",
    "hooke_counts_df = hooke_counts_df.loc[:, sort_cols]\n",
    "# meta_df = pd.read_csv(ccs_data_path + \"mdl_embryo_metadata.csv\", index_col=0)\n",
    "# meta_df[\"dis_protocol_str\"] = meta_df[\"dis_protocol\"].astype(str)\n",
    "\n",
    "# model formula\n",
    "with open(model_path + \"model_string.txt\", \"r\") as file:\n",
    "    formula_str = file.read()\n",
    "formula_str = \"dummy_response \" + formula_str \n",
    "formula_str = formula_str.replace(\"ns(\", \"cr(\")\n",
    "formula_str = formula_str.replace(\"c(\", \"(\")\n",
    "formula_str = formula_str.replace(\"\\n\", \"\")\n",
    "\n",
    "# load hooke predictions (for comparison purposes)\n",
    "latent_df = pd.read_csv(model_path + \"latents.csv\", index_col=0)\n",
    "time_splines = pd.read_csv(model_path + \"time_splines.csv\")\n",
    "\n",
    "# load hooke model files\n",
    "# b_array = pd.read_csv(model_path + \"B.csv\", index_col=0)\n",
    "cov_array = pd.read_csv(model_path + \"COV.csv\", index_col=0)\n",
    "theta_array = pd.read_csv(model_path + \"Theta.csv\", index_col=0)\n",
    "\n",
    "# latent_df.head()\n",
    "theta_array = theta_array.rename(columns={\"(Intercept)\":\"Intercept\"})\n",
    "cols_from = theta_array.columns\n",
    "cols_from_clean = [col.replace(\" = c\", \"=\") for col in cols_from]\n",
    "theta_array.columns = cols_from_clean\n",
    "\n",
    "time_splines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "# Assume the lookup table has columns: \"timepoint\", \"V1\", \"V2\", \"V3\", \"V4\"\n",
    "# (The actual names might differ; adjust as necessary.)\n",
    "\n",
    "# Define a function to interpolate the spline basis for a new time value.\n",
    "def get_spline_basis(new_time_vec, lookup_df):\n",
    "    # Create an empty dictionary to hold the interpolated values.\n",
    "    out_df = pd.DataFrame(new_time_vec, columns=[\"timepoint\"])\n",
    "    \n",
    "    # Loop through each spline column (skip the \"timepoint\" column).\n",
    "    for col in lookup_df.columns[1:]:\n",
    "        # Create an interpolation function for this column.\n",
    "        f_interp = interp1d(lookup_df[\"timepoint\"], lookup_df[col],\n",
    "                            kind='linear', fill_value=\"extrapolate\")\n",
    "        # Evaluate the interpolation at the new time value.\n",
    "        out_df[col] = f_interp(new_time_vec)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with building covariate matrix with patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covariate_df(formula_str, meta_df, time_splines):\n",
    "    meta_df[\"dummy_response\"] = 0\n",
    "    _, X = patsy.dmatrices(formula_str, meta_df, return_type='dataframe')\n",
    "    col_list = list(X.columns)\n",
    "    cols_to_clean = [col.replace(\"[T.\", \"\") for col in col_list]\n",
    "    cols_to_clean = [col.replace(\"]\", \"\") for col in cols_to_clean]\n",
    "    cols_to_clean = [col.replace(\"[\", \"\") for col in cols_to_clean]\n",
    "    cols_to_clean = [col.replace(\"cr\", \"ns\") for col in cols_to_clean]\n",
    "    cols_to_keep = [col for col in cols_to_clean if col in cols_from_clean]\n",
    "    X.columns = cols_to_clean\n",
    "    X = X.loc[:, cols_to_keep]\n",
    "    \n",
    "    # replace spline cols with lookups (can't get patsy to match ns from R)\n",
    "    spline_cols = [col for col in cols_to_keep if \"ns(\" in col]\n",
    "    spline_vals = get_spline_basis(meta_df.loc[:, \"timepoint\"].to_numpy(), time_splines)\n",
    "    if \"inter\" in ccm:\n",
    "        X.loc[:, spline_cols[:4]] = spline_vals.iloc[:, 1:].to_numpy()\n",
    "        X.loc[:, spline_cols[4:]] = np.multiply(spline_vals.iloc[:, 1:].to_numpy(), X.loc[:, \"dis_protocol\"].to_numpy()[:, None])\n",
    "    else:\n",
    "        X.loc[:, spline_cols] = spline_vals.iloc[:, 1:].to_numpy()\n",
    "\n",
    "    return X, spline_vals.iloc[:, 0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = hooke_counts_df[cov_cols].copy()\n",
    "meta_df.loc[:, \"dummy_response\"] = 0\n",
    "\n",
    "X, splines = get_covariate_df(formula_str, meta_df, time_splines)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that our predictions are consistent with output of Hooke's \"estimate_abundances\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu_python = np.matmul(X, theta_array.T)\n",
    "# mu_python[mu_python < -5] = -5 # looks like Hooke applies a lower bound at log(counts)=-5\n",
    "# python_pd = mu_python.to_numpy().ravel()\n",
    "# hooke_pd = hooke_counts_df.iloc[:, cell_ind:].to_numpy().ravel()\n",
    "#\n",
    "# plot_indices = np.random.choice(range(len(hooke_pd)), 1000)\n",
    "# fig = px.scatter(x=hooke_pd[plot_indices], y=python_pd[plot_indices])\n",
    "#\n",
    "# fig.update_layout(\n",
    "#     xaxis_title=\"Hooke log abundance predictions\",\n",
    "#     yaxis_title=\"Python log abundance predictions\"\n",
    "# )\n",
    "#\n",
    "# fig.update_layout(width=800, height=600)\n",
    "# fig.show()\n",
    "#\n",
    "# fig.write_image(fig_folder + \"python_pd_validation.png\", scale=2)\n",
    "# fig.write_html(fig_folder + \"python_pd_validation.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate mean WT trajectories\n",
    "Let's generate a high-res time trajectory. Look at differences between bead and enzymatic protocols. Average across experiment offsets (does that make sense?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "nt = 250\n",
    "dis_protocol_vals = np.unique(meta_df[\"dis_protocol\"]).tolist()\n",
    "expt_vals = np.unique(meta_df[\"expt\"]).tolist()\n",
    "time_vals = np.linspace(10, 74, nt).tolist()\n",
    "\n",
    "query_df = pd.DataFrame(itertools.product(time_vals, dis_protocol_vals, expt_vals), columns=[\"timepoint\", \"dis_protocol\", \"expt\"])\n",
    "\n",
    "# get covariate matrix\n",
    "X_ref, t_vec = get_covariate_df(formula_str, query_df, time_splines)\n",
    "expt_cols = [col for col in X_ref.columns if \"expt\" in col]\n",
    "# null_expt_filter = np.all(X_ref.loc[:, expt_cols].to_numpy()==0, axis=1)\n",
    "# null_expt_filter = X_ref.loc[:, \"dis_protocol\"]==2\n",
    "# X_ref = X_ref.loc[null_expt_filter, :]\n",
    "expt_array = np.c_[np.zeros((X_ref.shape[0], 1)), X_ref.loc[:, expt_cols].to_numpy()]\n",
    "expt_vec = np.argmax(expt_array, axis=1)\n",
    "expt_names = [\"baseline (bead)\"] + [col.replace(\"expt\", \"\") for col in expt_cols]\n",
    "# t_vec = t_vec[null_expt_filter]\n",
    "# get log abundance predictions\n",
    "\n",
    "hooke_trend_df = np.matmul(X_ref, theta_array.T)\n",
    "# hooke_trend_df.to_csv(\"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/analyses/crossmodal/hotfish/hooke_time_trends.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for baseline\n",
    "\n",
    "enz_filter = (X_ref[\"dis_protocol\"]==1).to_numpy()\n",
    "expt_filter = expt_vec==0\n",
    "\n",
    "hooke_trend_baseline = hooke_trend_df.loc[enz_filter & expt_filter]\n",
    "hooke_trend_baseline[\"stage_hpf\"] = time_vals\n",
    "hooke_trend_baseline.to_csv(\"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/analyses/crossmodal/hotfish/hooke_time_trends.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
