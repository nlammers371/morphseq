{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Sanity checks to ensure that the python-based prediction and projection functions are consistent with Hooke functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.seq.hooke_latent_projections.project_ccs_data import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"/media/nick/hdd02/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/\"\n",
    "root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/\"\n",
    "model_name = \"bead_expt_linear\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Just pasting this chunk directly from the main wrapper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooke_data_path = os.path.join(root, \"seq_data/emb_projections/hooke_model_files\", \"\")\n",
    "ccs_data_path = os.path.join(root, \"seq_data/emb_projections/ccs_data_cell_type_broad\", \"\")\n",
    "model_path = os.path.join(hooke_data_path, model_name, \"\")\n",
    "\n",
    "# make save dir\n",
    "out_dir = os.path.join(root, \"seq_data\", \"emb_projections\", \"latent_projections\", model_name, \"\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# load in model parameters\n",
    "# load full counts dataset\n",
    "hooke_counts_long = pd.read_csv(model_path + \"abundance_estimates.csv\", index_col=0)\n",
    "cols = list(hooke_counts_long.columns)\n",
    "cell_ind = cols.index(\"cell_group\")\n",
    "cov_cols = cols[:cell_ind]\n",
    "hooke_counts_df = hooke_counts_long.pivot(index=cov_cols,\n",
    "                                           columns=[\"cell_group\"], values = [\"log_abund\"])\n",
    "hooke_counts_df.columns = ['_'.join(map(str, col)).strip('_') for col in hooke_counts_df.columns.values]\n",
    "hooke_counts_df.reset_index(inplace=True)\n",
    "new_cols = [col.replace(\"log_abund_\", \"\") for col in hooke_counts_df.columns.values]\n",
    "hooke_counts_df.columns = new_cols\n",
    "sort_cols = new_cols[:cell_ind] + sorted(new_cols[cell_ind:], key=str.lower)\n",
    "hooke_counts_df = hooke_counts_df.loc[:, sort_cols]\n",
    "\n",
    "# make stripped-down metadata df\n",
    "meta_df = hooke_counts_df[cov_cols].copy()\n",
    "meta_df.loc[:, \"dummy_response\"] = 0\n",
    "\n",
    "# load hooke predictions (for comparison purposes)\n",
    "# latent_df = pd.read_csv(model_path + \"latents.csv\", index_col=0)\n",
    "spline_lookup_df = pd.read_csv(model_path + \"time_splines.csv\")\n",
    "\n",
    "# load hooke model files\n",
    "cov_array = pd.read_csv(model_path + \"COV.csv\", index_col=0)\n",
    "beta_array = pd.read_csv(model_path + \"B.csv\", index_col=0).T\n",
    "\n",
    "# latent_df.head()\n",
    "beta_array = beta_array.rename(columns={\"(Intercept)\":\"Intercept\"})\n",
    "cols_from = beta_array.columns\n",
    "cols_from_clean = [col.replace(\" = c\", \"=\") for col in cols_from]\n",
    "beta_array.columns = cols_from_clean\n",
    "beta_array.head()\n",
    "\n",
    "# model formula\n",
    "with open(model_path + \"model_string.txt\", \"r\") as file:\n",
    "    formula_str = file.read().strip()\n",
    "model_desc = patsy.ModelDesc.from_formula(formula_str)\n",
    "# Extract covariate names from the right-hand side terms.\n",
    "cov_factors = []\n",
    "for term in model_desc.rhs_termlist:\n",
    "    for factor in term.factors:\n",
    "        # factor is a EvalFactor, convert it to string.\n",
    "        cov_factors.append(str(factor).replace(\"EvalFactor('\",\"\").replace(\"')\",\"\"))\n",
    "cov_factors = np.unique([cov for cov in cov_factors if \"ns(\" not in cov]).tolist()\n",
    "\n",
    "# load in full counts table and metadata used for model inference\n",
    "mdl_counts_df = pd.read_csv(model_path + \"mdl_counts_table.csv\", index_col=0).T\n",
    "mdl_meta_df = pd.read_csv(model_path + \"mdl_embryo_metadata.csv\", index_col=0)\n",
    "\n",
    "####################\n",
    "# load in ccs table\n",
    "\n",
    "# get list of all ccs tables\n",
    "count_suffix = \"_counts_table.csv\"\n",
    "meta_suffix = \"_metadata.csv\"\n",
    "\n",
    "ccs_path_list = sorted(glob.glob(ccs_data_path + \"*\" + count_suffix))\n",
    "ccs_name_list = [os.path.basename(p).replace(count_suffix, \"\") for p in ccs_path_list]\n",
    "\n",
    "# compile master count and metadata tables\n",
    "mdl_cell_types = mdl_counts_df.columns\n",
    "ccs_df_list = []\n",
    "meta_df_list = []\n",
    "for ccs_name in tqdm(ccs_name_list):\n",
    "    ccs_temp = pd.read_csv(ccs_data_path + ccs_name + count_suffix, index_col=0).T\n",
    "    ccs_temp = ccs_temp.reindex(columns=mdl_cell_types, fill_value=0)\n",
    "    ccs_df_list.append(ccs_temp)\n",
    "    meta_temp = pd.read_csv(ccs_data_path + ccs_name + meta_suffix, index_col=0)\n",
    "    meta_df_list.append(meta_temp)\n",
    "\n",
    "# concatenate\n",
    "ccs_df = pd.concat(ccs_df_list, axis=0).drop_duplicates()\n",
    "meta_df = pd.concat(meta_df_list, axis=0).drop_duplicates()\n",
    "\n",
    "ccs_df = ccs_df.loc[~ccs_df.index.duplicated(keep='first')]\n",
    "meta_df = meta_df.loc[~meta_df.index.duplicated(keep='first')].set_index(\"sample\")\n",
    "\n",
    "meta_df[\"pert_collapsed\"] = meta_df[\"perturbation\"].copy()\n",
    "conv_list = np.asarray([\"ctrl-uninj\", \"reference\", \"novehicle\"])\n",
    "meta_df.loc[np.isin(meta_df[\"pert_collapsed\"], conv_list), \"pert_collapsed\"] = \"ctrl\"\n",
    "\n",
    "# keep only embryos from experiments that were included in model inference\n",
    "exp_vec = mdl_meta_df.loc[:, \"expt\"].unique()\n",
    "exp_filter = np.isin(meta_df[\"expt\"], exp_vec)\n",
    "meta_df = meta_df.loc[exp_filter, :]\n",
    "ccs_df = ccs_df.loc[exp_filter, :]\n",
    "\n",
    "# augment ccs table to incorporate missing cell types\n",
    "# mdl_cell_types = mdl_counts_df.columns\n",
    "# ccs_df = ccs_df.reindex(columns=mdl_cell_types, fill_value=0)\n",
    "\n",
    "# check which ones were included in inference\n",
    "mdl_flags = np.isin(np.asarray(ccs_df.index), np.asarray(mdl_counts_df.index))\n",
    "meta_df[\"inference_flag\"] = mdl_flags\n",
    "\n",
    "# flag experiments that were not included in inference\n",
    "mdl_experiments = np.unique(mdl_meta_df[\"expt\"])\n",
    "oos_vec = ~np.isin(meta_df[\"expt\"], mdl_experiments)\n",
    "meta_df[\"oos_expt_flag\"] = oos_vec\n",
    "\n",
    "####\n",
    "# model parameters\n",
    "####\n",
    "\n",
    "# inverse cov matrix\n",
    "PHI = np.linalg.inv(cov_array)\n",
    "# COV = cov_array.to_numpy()\n",
    "\n",
    "# regression vars\n",
    "THETA = beta_array.copy()\n",
    "\n",
    "# zi0_vec = [0] * COV.shape[0]\n",
    "\n",
    "# covariates\n",
    "cov_col_list = beta_array.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Get mean predictions for log(A) and compare to original Hooke predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seed = hooke_counts_df.drop_duplicates(subset=[\"timepoint\", \"expt\"]).reset_index(drop=True)\n",
    "x_seed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct covarate matrix\n",
    "X_list = []\n",
    "for e in tqdm(range(x_seed.shape[0])):\n",
    "    # get embryo info\n",
    "    # embryo_id = ccs_df.index[embryo_ind]\n",
    "    # raw_counts = ccs_df.loc[embryo_id, :].to_numpy()\n",
    "\n",
    "    cov_dict = dict({cov: x_seed.loc[e, cov] for cov in cov_factors})\n",
    "    stage = x_seed.loc[e, \"timepoint\"]\n",
    "    # size_factor_log = np.log(meta_df.loc[embryo_id, \"Size_Factor\"])\n",
    "\n",
    "    # construct initial covariate vec\n",
    "    X0 = construct_X(stage, cov_dict, cov_col_list=cov_col_list, spline_lookup_df=spline_lookup_df)\n",
    "    # X0.index = [embryo_id]\n",
    "    X_list.append(X0)\n",
    "\n",
    "X = pd.concat(X_list, axis=0, ignore_index=True)\n",
    "# X = X.drop_duplicates(subset=[\"\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate abundance predictions and compare to Hooke output\n",
    "python_pd_df = (X @ THETA.T)\n",
    "cell_cols = python_pd_df.columns.tolist()\n",
    "python_pd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_log_counts = python_pd_df.iloc[:, :].to_numpy().ravel()\n",
    "hooke_log_counts = python_pd_df.loc[:, cell_cols].to_numpy().ravel()\n",
    "\n",
    "fig = px.scatter(x=py_log_counts, y=hooke_log_counts)\n",
    "fig.update_layout(xaxis=dict(title=\"predicted log cell abundances (python)\"), \n",
    "                  yaxis=dict(title=\"predicted log cell abundances (Hooke/R)\"), )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "A related qu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooke_log_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
