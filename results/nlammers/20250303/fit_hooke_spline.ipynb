{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Generate reference wt spline for transcriptional latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.seq.hooke_latent_projections.project_ccs_data import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"/media/nick/hdd02/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/\"\n",
    "root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/\"\n",
    "model_name = \"bead_expt_linear\"\n",
    "\n",
    "# path to save data\n",
    "out_path = os.path.join(root, \"results\", \"20240303\", \"\")\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "fig_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/slides/morphseq/20250312/morphseq_cca/\"\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Load hooke embeddigs and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to hooke projections\n",
    "hooke_model_name = \"bead_expt_linear\"\n",
    "latent_path = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/morphseq/seq_data/emb_projections/latent_projections/\"\n",
    "hooke_model_path = os.path.join(latent_path, hooke_model_name, \"\")\n",
    "\n",
    "# hooke latent encodings\n",
    "seq_df = pd.read_csv(hooke_model_path + \"latent_projections.csv\", index_col=0)\n",
    "seq_df[\"sample\"] = seq_df.index\n",
    "\n",
    "# load metadata\n",
    "meta_df = pd.read_csv(os.path.join(root, \"metadata\", \"seq_embryo_df.csv\"), index_col=0)\n",
    "meta_df = pd.DataFrame(seq_df[\"sample\"]).merge(meta_df, how=\"inner\", on=\"sample\").reset_index(drop=True) #meta_df.loc[np.isin(meta_df[\"sample\"], np.asarray(seq_df.index)), :]\n",
    "\n",
    "# stage predictions\n",
    "time_df = pd.read_csv(hooke_model_path + \"time_predictions.csv\", index_col=0)\n",
    "time_df = pd.DataFrame(seq_df[\"sample\"]).merge(time_df, how=\"inner\", left_on=\"sample\", right_index=True)\n",
    "\n",
    "seq_df = seq_df.drop(labels=[\"sample\"], axis=1)\n",
    "meta_df = meta_df.merge(time_df.loc[:, [\"pseudostage\"]], left_on=\"sample\", right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Drop Gene 3 and filter for time of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 250\n",
    "t_start = 12.5\n",
    "t_stop = 50\n",
    "t_vec = np.linspace(t_start-5, t_stop+5, n_points)\n",
    "\n",
    "# seq_df = seq_df.reset_index() \n",
    "\n",
    "# apply filters\n",
    "stage_filter = ((meta_df[\"pseudostage\"] >=t_start) & (meta_df[\"pseudostage\"] <=t_stop)).to_numpy()\n",
    "expt_filter = (meta_df[\"expt\"] != \"GENE3\").to_numpy()\n",
    "hf_filter = (meta_df[\"expt\"] == \"hotfish2\").to_numpy()\n",
    "\n",
    "ref_meta_df = meta_df.loc[stage_filter & expt_filter & ~hf_filter, :]\n",
    "ref_seq_df = seq_df[stage_filter & expt_filter & ~hf_filter]\n",
    "\n",
    "hf_meta_df = meta_df.loc[stage_filter & expt_filter & hf_filter, :]\n",
    "hf_seq_df = seq_df[stage_filter & expt_filter & hf_filter]\n",
    "\n",
    "seq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Fit PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# initialize and fit\n",
    "n_components = 100\n",
    "seq_pca = PCA(n_components=n_components)\n",
    "seq_pca.fit(pd.concat([ref_seq_df, hf_seq_df]))\n",
    "ref_pca_array = seq_pca.transform(ref_seq_df)\n",
    "hf_pca_array = seq_pca.transform(hf_seq_df)\n",
    "\n",
    "# create data frame \n",
    "pca_cols = [f\"PCA_{n:02}\" for n in range(n_components)]\n",
    "ref_pca_df = pd.DataFrame(ref_pca_array, columns=pca_cols, index=ref_seq_df.index)\n",
    "hf_pca_df = pd.DataFrame(hf_pca_array, columns=pca_cols, index=hf_seq_df.index)\n",
    "hf_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_seq_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumulative = np.cumsum(seq_pca.explained_variance_ratio_)\n",
    "fig = px.line(x=np.arange(n_components), y=var_cumulative, markers=True)\n",
    "\n",
    "fig.update_layout(xaxis=dict(title=\"PC number\"),\n",
    "                  yaxis=dict(title=\"total variance explained\"),\n",
    "                  title=\"PCA decomposition of Hooke latent space\",\n",
    "                 font=dict(\n",
    "                    family=\"Arial, sans-serif\",\n",
    "                    size=18,  # Adjust this value to change the global font size\n",
    "                    color=\"black\"\n",
    "                ))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"seq_pca_var_explained.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Fit reference spline to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functions.spline_fitting_v2 import spline_fit_wrapper\n",
    "\n",
    "n_boots = 50\n",
    "n_spline_points = 2500\n",
    "norm_factor = 10\n",
    "\n",
    "ref_pca_df_fit = ref_pca_df.copy()\n",
    "ref_pca_df_fit[pca_cols] = ref_pca_df_fit[pca_cols] / norm_factor \n",
    "ref_pca_df_fit[\"predicted_stage_hpf\"] = ref_meta_df[\"pseudostage\"].to_numpy()\n",
    "\n",
    "spline_df = spline_fit_wrapper(ref_pca_df_fit, fit_cols=pca_cols, n_boots=n_boots, n_spline_points=n_spline_points, \n",
    "                               bandwidth=0.5, angle_penalty_exp=0.05, time_window=5)\n",
    "\n",
    "spline_df = spline_df * norm_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dims = np.asarray([0, 1, 2]) + 2\n",
    "plot_strings = [pca_cols[p] for p in plot_dims]\n",
    "\n",
    "fig = px.scatter_3d(hf_pca_df, x=plot_strings[0], y=plot_strings[1], z=plot_strings[2], opacity=1,\n",
    "                    color=hf_meta_df[\"temp\"])\n",
    "# fig = px.scatter_3d(ref_pca_df, x=plot_strings[0], y=plot_strings[1], z=plot_strings[2], opacity=1,\n",
    "#                     color=ref_meta_df[\"temp\"])\n",
    "\n",
    "fig.update_traces(marker=dict(size=5, showscale=False))\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        aspectmode='data'\n",
    "        # Alternatively, you can use 'cube' to force equal scaling:\n",
    "        # aspectmode='cube'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_traces(go.Scatter3d(x=spline_df.loc[:, plot_strings[0]], \n",
    "                            y=spline_df.loc[:, plot_strings[1]], \n",
    "                            z=spline_df.loc[:, plot_strings[2]],\n",
    "                           mode=\"lines\", line=dict(color=\"darkblue\", width=4), name=\"reference curve\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define a pipeline that first transforms the input and then fits a linear model.\n",
    "degree = 2  # or any degree you choose\n",
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=degree, include_bias=True)),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "\n",
    "frac_to_fit = 0.95\n",
    "X = ref_pca_df[pca_cols].values\n",
    "n_train = int(np.floor(frac_to_fit * X.shape[0]))\n",
    "X_indices = np.arange(X.shape[0])\n",
    "train_indices = np.random.choice(X_indices, n_train, replace=False)\n",
    "test_indices = X_indices[~np.isin(X_indices, train_indices)]\n",
    "\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "\n",
    "y = ref_pca_df_fit[\"predicted_stage_hpf\"].values\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "# Assume X is your (n_samples x N) input array and y is your (n_samples,) target (time).\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pd = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Use surface to generate stage estimates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spline = spline_df[pca_cols].values\n",
    "spline_df[\"mdl_stage_hpf\"] = model.predict(X_spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "t_vec = np.linspace(t_start, t_stop, n_points)\n",
    "\n",
    "# set index to be time\n",
    "t_vec_orig = spline_df[\"mdl_stage_hpf\"].to_numpy()\n",
    "\n",
    "# get new PCA values\n",
    "interp = interp1d(t_vec_orig, spline_df[pca_cols].values, axis=0)\n",
    "pca_array_interp = interp(t_vec)\n",
    "\n",
    "# Reindex the dataframe to include the new time points.\n",
    "spline_df_new = pd.DataFrame(pca_array_interp, columns=pca_cols)\n",
    "spline_df_new[\"stage_hpf\"] = t_vec\n",
    "\n",
    "spline_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(spline_df_new, x=plot_strings[0], y=plot_strings[1], z=plot_strings[2], opacity=1,\n",
    "                    color=\"stage_hpf\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_pca_df.to_csv(os.path.join(out_path, \"hf_seq_df.csv\"))\n",
    "ref_pca_df.to_csv(os.path.join(out_path, \"wt_ref_seq_df.csv\"))\n",
    "spline_df_new.to_csv(os.path.join(out_path, \"spline_seq_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
