import os
import shutil
import torch.nn.functional as F
import torch
import yaml


def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):
    torch.save(state, filename)
    if is_best:
        shutil.copyfile(filename, 'model_best.pth.tar')


def save_config_file(model_checkpoints_folder, args):
    if not os.path.exists(model_checkpoints_folder):
        os.makedirs(model_checkpoints_folder)
        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:
            yaml.dump(args, outfile, default_flow_style=False)


def accuracy(output, target, topk=(1,)):
    """Computes the accuracy over the k top predictions for the specified values of k"""
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)

        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))

        res = []
        for k in topk:
            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size))
        return res

# This function calculates contrastive loss as cross entropy of cosine differences between transformed pairs of images
def contrastive_loss(features, device, temperature=1, n_views=2):

    batch_size = features.shape[0]

    labels = torch.cat([torch.arange(batch_size) for i in range(n_views)], dim=0)
    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()
    labels = labels.to(device)

    # Normalize each latent vector. This simplifies the process of calculating cosie differences
    features = F.normalize(features, dim=1)

    # Due to above normalization, sim matrix entries are same as cosine differences
    similarity_matrix = torch.matmul(features, features.T)
    # assert similarity_matrix.shape == (
    #     n_views * batch_size, n_views * batch_size)
    # assert similarity_matrix.shape == labels.shape

    # discard the main diagonal, since this is the comparison of image with itself
    mask = torch.eye(labels.shape[0], dtype=torch.bool).to(device)
    labels = labels[~mask].view(labels.shape[0], -1)
    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)
    # assert similarity_matrix.shape == labels.shape

    # select and combine multiple positives
    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)

    # select only the negatives the negatives
    negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)

    # Construct logits matrix with positive examples as firs column
    logits = torch.cat([positives, negatives], dim=1)

    # These labels tell the cross-entropy function that the positive example for each row is in the first column (col=0)
    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(device)

    # Apply temperature parameter
    logits = logits / temperature

    # initialize cross entropy loss
    loss_fun = torch.nn.CrossEntropyLoss()

    loss = loss_fun(logits, labels)

    return loss